<html xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops"><head><title>Concurrency and Asynchrony</title><link href="epub.css" rel="stylesheet" type="text/css"/>
<meta content="urn:uuid:3330d66d-9080-4595-aa6c-b8113bd76e5a" name="Adept.expected.resource"/></head><body data-type="book"><section data-nutshell-tab="Concurrency and Asynchrony" data-pdf-bookmark="Chapter 14. Concurrency and Asynchrony" data-type="chapter" epub:type="chapter"><div class="chapter" id="concurrency_and_asynchron">
<h1><span class="label">Chapter 14. </span>Concurrency and Asynchrony</h1>
<p><a contenteditable="false" data-primary="concurrency and asynchrony" data-type="indexterm" id="ch14.html0"/>Most applications need to deal with more than one thing happening at a time (<em>concurrency</em>). In this chapter, we start with the essential prerequisites, namely the basics of threading and tasks, and then describe in detail the principles of asynchrony and C#’s asynchronous functions.</p>
<p>In <a data-type="xref" href="ch21.html#advanced_threadin">Chapter 21</a>, we revisit multithreading in greater detail, and in <a data-type="xref" href="ch22.html#parallel_programming-id00071">Chapter 22</a>, we cover the related topic of parallel programming.</p>
<section data-pdf-bookmark="Introduction" data-type="sect1"><div class="sect1" id="introduction">
<h1>Introduction</h1>
<p><a contenteditable="false" data-primary="concurrency and asynchrony" data-secondary="common concurrency scenarios" data-type="indexterm" id="id3641"/>Following are the most common concurrency scenarios:</p>
<dl>
<dt>Writing a responsive user interface</dt>
<dd>In Windows Presentation Foundation (WPF), mobile, and Windows Forms applications, you must run time-consuming tasks concurrently with the code that runs your user interface to maintain responsiveness.</dd>
<dt>Allowing requests to process simultaneously</dt>
<dd>On a server, client requests can arrive concurrently and so must be handled in parallel to maintain scalability. If you use ASP.NET Core or Web API, the runtime does this for you automatically. However, you still need to be aware of shared state (for instance, the effect of using static variables for caching).</dd>
<dt>Parallel programming</dt>
<dd>Code that performs intensive calculations can execute faster on multicore/multiprocessor computers if the workload is divided between cores (<a data-type="xref" href="ch22.html#parallel_programming-id00071">Chapter 22</a> is dedicated to this).</dd>
<dt>Speculative execution</dt>
<dd>On multicore machines, you can sometimes improve performance by predicting something that might need to be done and then doing it ahead of time. LINQPad uses this technique to speed up the creation of new queries. A <span class="keep-together">variation</span> is to run a number of different algorithms in parallel that all solve the same task. Whichever one finishes first “wins”—this is effective when you can’t know ahead of time which algorithm will execute fastest.</dd>
</dl>
<p>The general mechanism by which a program can simultaneously execute code is called <em>multithreading</em>. Multithreading is supported by both the CLR and operating system, and is a fundamental concept in concurrency. Understanding the basics of threading, and in particular the effects of threads on <em>shared state</em>, is therefore <span class="keep-together">essential</span>.</p>
</div></section>
<section data-pdf-bookmark="Threading" data-type="sect1"><div class="sect1" id="threading">
<h1>Threading</h1>
<p><a contenteditable="false" data-primary="concurrency and asynchrony" data-secondary="threading" data-type="indexterm" id="ch14.html1"/><a contenteditable="false" data-primary="threading" data-type="indexterm" id="ch14.html2"/>A <a contenteditable="false" data-primary="threads" data-secondary="defined" data-type="indexterm" id="id3642"/><em>thread</em> is an execution path that can proceed independently of others.</p>
<p>Each thread runs within an operating system process, which provides an isolated environment in which a program runs. <a contenteditable="false" data-primary="single-threaded program" data-type="indexterm" id="id3643"/>With a <em>single-threaded</em> program, just one thread runs in the process’s isolated environment, and so that thread has exclusive access to it. <a contenteditable="false" data-primary="multithreaded program" data-type="indexterm" id="id3644"/>With a <em>multithreaded</em> program, multiple threads run in a single process, sharing the same execution environment (memory, in particular). This, in part, is why multithreading is useful: one thread can fetch data in the background, for instance, while another thread displays the data as it arrives. <a contenteditable="false" data-primary="shared state" data-type="indexterm" id="id3645"/>This data is referred to as <em>shared state</em>.</p>
<section data-pdf-bookmark="Creating a Thread" data-type="sect2"><div class="sect2" id="creating_a_thread">
<h2>Creating a Thread</h2>
<p><a contenteditable="false" data-primary="threading" data-secondary="creating a thread" data-type="indexterm" id="ch14.html3"/>A <em>client</em> program (Console, WPF, UWP, or Windows Forms) starts in a single thread that’s created automatically by the OS (the “main” thread). Here it lives out its life as a single-threaded application, unless you do otherwise, by creating more threads (directly or indirectly).<sup><a data-type="noteref" href="ch14.html#ch01fn14" id="ch01fn14-marker">1</a></sup></p>
<p><a contenteditable="false" data-primary="Thread..." data-secondary="Thread object" data-type="indexterm" id="id3646"/>You can create and start a new thread by instantiating a <code>Thread</code> object and calling its <code>Start</code> method. <a contenteditable="false" data-primary="Thread..." data-secondary="ThreadStart delegate" data-type="indexterm" id="id3647"/>The simplest constructor for <code>Thread</code> takes a <code>ThreadStart</code> delegate: a parameterless method indicating where execution should begin. Here’s an example:</p>
<pre data-type="programlisting">// NB: All samples in this chapter assume the following namespace imports:
<strong>using System;</strong>
<strong>using System.Threading;</strong>

Thread t = new Thread (WriteY);          // Kick off a new thread
t.Start();                               // running WriteY()

// Simultaneously, do something on the main thread.
for (int i = 0; i &lt; 1000; i++) Console.Write ("x");

void WriteY()
{
  for (int i = 0; i &lt; 1000; i++) Console.Write ("y");
}

// Typical Output:
xxxxxxxxxxxxxxxxyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyy
xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxyyyyyyyyyyyyy
yyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyy
yyyyyyyyyyyyyxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
...</pre>
<p>The main thread creates a new thread <code>t</code> on which it runs a method that repeatedly prints the character <em>y</em>. Simultaneously, the main thread repeatedly prints the character <em>x</em>, as shown in <a data-type="xref" href="#starting_a_new_thread">Figure 14-1</a>. On a single-core computer, the operating system must allocate “slices” of time to each thread (typically 20 ms in Windows) to simulate concurrency, resulting in repeated blocks of <em>x</em> and <em>y</em>. On a multicore or multiprocessor machine, the two threads can genuinely execute in parallel (subject to competition by other active processes on the computer), although you still get repeated blocks of <em>x</em> and <em>y</em> in this example because of subtleties in the mechanism by which <code>Console</code> handles concurrent requests.</p>
<figure><div class="figure" id="starting_a_new_thread">
<img alt="Starting a new thread" src="assets/cn10_1401.png"/>
<h6><span class="label">Figure 14-1. </span>Starting a new thread</h6>
</div></figure>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p><a contenteditable="false" data-primary="preempted thread" data-type="indexterm" id="id3648"/>A thread is said to be <em>preempted</em> at the points at which its execution is interspersed with the execution of code on another thread. The term often crops up in explaining why something has gone wrong!</p>
</div>
<p>After it’s started, a thread’s <code>IsAlive</code> property returns <code>true</code>, until the point at which the thread ends. A thread ends when the delegate passed to the <code>Thread</code>’s constructor finishes executing. After it’s ended, a thread cannot restart.</p>
<p>Each thread has a <code>Name</code> property that you can set for the benefit of debugging. This is particularly useful in Visual Studio because the thread’s name is displayed in the Threads Window and Debug Location toolbar. You can set a thread’s name just once; attempts to change it later will throw an exception.</p>
<p class="pagebreak-before">The static <code>Thread.CurrentThread</code> property gives you the currently executing thread:<a contenteditable="false" data-primary="" data-startref="ch14.html3" data-type="indexterm" id="id3649"/></p>
<pre data-type="programlisting">Console.WriteLine (Thread.CurrentThread.Name);</pre>
</div></section>
<section data-pdf-bookmark="Join and Sleep" data-type="sect2"><div class="sect2" id="join_and_sleep">
<h2>Join and Sleep</h2>
<p><a contenteditable="false" data-primary="Join method (threading)" data-type="indexterm" id="id3650"/><a contenteditable="false" data-primary="threading" data-secondary="join and sleep" data-type="indexterm" id="id3651"/>You can wait for another thread to end by calling its <code>Join</code> method:</p>
<pre data-type="programlisting">Thread t = new Thread (Go);
t.Start();
t.Join();
Console.WriteLine ("Thread t has ended!");
 
void Go() { for (int i = 0; i &lt; 1000; i++) Console.Write ("y"); }</pre>
<p>This prints “y” 1,000 times, followed by “Thread t has ended!” immediately afterward. You can include a timeout when calling <code>Join</code>, either in milliseconds or as a <code>TimeSpan</code>. It then returns <code>true</code> if the thread ended or <code>false</code> if it timed out.</p>
<p><a contenteditable="false" data-primary="Thread..." data-secondary="Thread.Sleep" data-type="indexterm" id="id3652"/><code>Thread.Sleep</code> pauses the current thread for a specified period:</p>
<pre data-type="programlisting">Thread.Sleep (TimeSpan.FromHours (1));  // Sleep for 1 hour
Thread.Sleep (500);                     // Sleep for 500 milliseconds</pre>
<p><code>Thread.Sleep(0)</code> relinquishes the thread’s current time slice immediately, voluntarily handing over the CPU to other threads. <code>Thread.Yield()</code> does the same thing except that it relinquishes only to threads running on the <em>same</em> processor.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p><code>Sleep(0)</code> or <code>Yield</code> is occasionally useful in production code for advanced performance tweaks. It’s also an excellent diagnostic tool for helping to uncover thread safety issues: if inserting <code>Thread.Yield()</code> anywhere in your code breaks the program, you almost certainly have a bug.</p>
</div>
<p>While waiting on a <code>Sleep</code> or <code>Join</code>, a thread is blocked.</p>
</div></section>
<section data-pdf-bookmark="Blocking" data-type="sect2"><div class="sect2" id="blocking">
<h2>Blocking</h2>
<p><a contenteditable="false" data-primary="blocking" data-secondary="threads" data-type="indexterm" id="id3653"/><a contenteditable="false" data-primary="threading" data-secondary="blocking" data-type="indexterm" id="id3654"/>A thread is deemed <em>blocked</em> when its execution is paused for some reason, such as when <code>Sleep</code>ing or waiting for another to end via <code>Join</code>. A blocked thread immediately <em>yields</em> its processor time slice, and from then on it consumes no processor time until its blocking condition is satisfied. You can test for a thread being blocked via its <code>ThreadState</code> property:</p>
<pre data-type="programlisting">bool blocked = (someThread.ThreadState &amp; ThreadState.WaitSleepJoin) != 0;</pre>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p><code>ThreadState</code> is a flags enum, combining three “layers” of data in a bitwise fashion. Most values, however, are redundant, unused, or deprecated. The following extension method strips a <code>ThreadState</code> to one of four useful values: <code>Unstarted</code>, <span class="keep-together"><code>Running</code></span>, <code>WaitSleepJoin</code>, and <code>Stopped</code>:</p>
<pre data-type="programlisting">public static ThreadState Simplify (this ThreadState ts)
{
  return ts &amp; (ThreadState.Unstarted |
               ThreadState.WaitSleepJoin |
               ThreadState.Stopped);
}</pre>
<p>The <code>ThreadState</code> property is useful for diagnostic purposes but unsuitable for synchronization, because a thread’s state can change in between testing <code>ThreadState</code> and acting on that information.</p>
</div>
<p>When a thread blocks or unblocks, the OS performs a <em>context switch</em>. This incurs a small overhead, typically one or two microseconds.</p>
<section data-pdf-bookmark="I/O-bound versus compute-bound" data-type="sect3"><div class="sect3" id="isoliduso_bound_versus_compute_bound">
<h3>I/O-bound versus compute-bound</h3>
<p><a contenteditable="false" data-primary="threading" data-secondary="I/O bound versus compute-bound operations" data-type="indexterm" id="id3655"/>An operation that spends most of its time <em>waiting</em> for something to happen is called <em>I/O-bound</em>—an example is downloading a web page or calling <code>Console.ReadLine</code>. (I/O-bound operations typically involve input or output, but this is not a hard requirement: <code>Thread.Sleep</code> is also deemed I/O-bound.) In contrast, an operation that spends most of its time performing CPU-intensive work is called <em>compute-bound</em>.</p>
</div></section>
<section data-pdf-bookmark="Blocking versus spinning" data-type="sect3"><div class="sect3" id="blocking_versus_spinning">
<h3>Blocking versus spinning</h3>
<p><a contenteditable="false" data-primary="blocking" data-secondary="spinning versus" data-type="indexterm" id="id3656"/><a contenteditable="false" data-primary="spinning, blocking versus" data-type="indexterm" id="id3657"/><a contenteditable="false" data-primary="threading" data-secondary="blocking versus spinning" data-type="indexterm" id="id3658"/>An I/O-bound operation works in one of two ways: it either waits <em>synchronously</em> on the current thread until the operation is complete (such as <code>Console.ReadLine</code>, <code>Thread.Sleep</code>, or <code>Thread.Join</code>), or it operates <em>asynchronously</em>, firing a callback when the operation finishes in the future (more on this later).</p>
<p>I/O-bound operations that wait synchronously spend most of their time blocking a thread. They can also “spin” in a loop periodically:</p>
<pre data-type="programlisting">while (DateTime.Now &lt; nextStartTime)
  Thread.Sleep (100);</pre>
<p>Leaving aside that there are better ways to do this (such as timers or signaling constructs), another option is that a thread can spin continuously:</p>
<pre data-type="programlisting">while (DateTime.Now &lt; nextStartTime);</pre>
<p>In general, this is very wasteful on processor time: as far as the CLR and OS are concerned, the thread is performing an important calculation and thus is allocated resources accordingly. In effect, we’ve turned what should be an I/O-bound operation into a compute-bound operation.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>There are a couple of nuances with regard to spinning versus blocking. First, spinning <em>very briefly</em> can be effective when you expect a condition to be satisfied soon (perhaps within a few microseconds) because it avoids the overhead and latency of a context switch. .NET provides special methods and classes to assist—see the online supplement <a href="http://albahari.com/threading">“SpinLock and SpinWait”</a>.</p>
<p>Second, blocking does not incur a <em>zero</em> cost. This is because each thread ties up around 1 MB of memory for as long as it lives and causes an ongoing administrative overhead for the CLR and OS. For this reason, blocking can be troublesome in the context of heavily I/O-bound programs that need to handle hundreds or thousands of concurrent operations. Instead, such programs need to use a callback-based approach, rescinding their thread entirely while waiting. This is (in part) the purpose of the asynchronous patterns that we discuss later.</p>
</div>
</div></section>
</div></section>
<section data-pdf-bookmark="Local Versus Shared State" data-type="sect2"><div class="sect2" id="local_versus_shared_state">
<h2>Local Versus Shared State</h2>
<p><a contenteditable="false" data-primary="threading" data-secondary="local versus shared state" data-type="indexterm" id="ch14.html4"/>The CLR assigns each thread its own memory stack so that local variables are kept separate. In the next example, we define a method with a local variable and then call the method simultaneously on the main thread and a newly created thread:</p>
<pre data-type="programlisting">new Thread (Go).Start();      // Call Go() on a new thread
Go();                         // Call Go() on the main thread
 
void Go()
{
  // Declare and use a local variable - 'cycles'
  for (int cycles = 0; cycles &lt; 5; cycles++) Console.Write ('?');
}</pre>
<p>A separate copy of the <code>cycles</code> variable is created on each thread’s memory stack, and so the output is, predictably, 10 question marks.</p>
<p>Threads share data if they have a common reference to the same object or variable:</p>
<pre data-type="programlisting"><strong>bool _done = false;</strong>

new Thread (Go).Start();
Go();

void Go()
{
   if (!<strong>_done</strong>) { <strong>_done = true</strong>; Console.WriteLine ("Done"); }
}</pre>
<p>Both threads share the <code>_done</code> variable, so “Done” is printed once instead of twice.</p>
<p>Local variables captured by a lambda expression can also be shared:</p>
<pre data-type="programlisting">bool done = false;
ThreadStart action = () =&gt;
{
  if (!done) { done = true; Console.WriteLine ("Done"); }
};
new Thread (action).Start();
action();</pre>
<p>More commonly, though, fields are used to share data between threads. In the following example, both threads call <code>Go()</code> on the same <code>ThreadTest</code> instance, so they share the same <code>_done</code> field:</p>
<pre data-type="programlisting">var tt = new ThreadTest();
new Thread (tt.Go).Start();
tt.Go();

class ThreadTest 
{
  bool _done;

  public void Go()
  {
    if (!_done) { _done = true; Console.WriteLine ("Done"); }
  }
}</pre>
<p>Static fields offer another way to share data between threads:</p>
<pre data-type="programlisting">class ThreadTest 
{
  static bool _done;    // Static fields are shared between all threads
                        // in the same process.
  static void Main()
  {
    new Thread (Go).Start();
    Go();
  }
 
  static void Go()
  {
    if (!_done) { _done = true; Console.WriteLine ("Done"); }
  }
}</pre>
<p>All four examples illustrate another key concept: that of thread safety (or rather, lack of it!). The output is actually indeterminate: it’s possible (though unlikely) that “Done” could be printed twice. If, however, we swap the order of statements in the <code>Go</code> method, the odds of “Done” being printed twice go up dramatically:</p>
<pre data-type="programlisting">static void Go()
{
  if (!_done) { Console.WriteLine ("Done"); _done = true; }
}</pre>
<p>The problem is that one thread can be evaluating the if statement at exactly the same time as the other thread is executing the <code>WriteLine</code> statement—before it’s had a chance to set <code>done</code> to <code>true</code>.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p><a contenteditable="false" data-primary="shared writable state" data-type="indexterm" id="id3659"/>Our example illustrates one of many ways that <em>shared writable state</em> can introduce the kind of intermittent errors for which multithreading is notorious. Next, we look at how to fix our program by locking; however, it’s better to avoid shared state altogether where possible. We see later how asynchronous programming patterns help with this.<a contenteditable="false" data-primary="" data-startref="ch14.html4" data-type="indexterm" id="id3660"/></p>
</div>
</div></section>
<section data-pdf-bookmark="Locking and Thread Safety" data-type="sect2"><div class="sect2" id="locking_and_thread_safety">
<h2>Locking and Thread Safety</h2>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>Locking and thread safety are large topics. For a full discussion, see <a data-type="xref" href="ch21.html#exclusive_locking">“Exclusive Locking”</a> and <a data-type="xref" href="ch21.html#locking_and_thread_safet">“Locking and Thread Safety”</a>.</p>
</div>
<p>We can fix the previous example by obtaining an <em>exclusive lock</em> while reading and writing to the shared field. C# provides the <code>lock</code> statement for just this purpose:</p>
<pre data-type="programlisting">class ThreadSafe 
{
  static bool _done;
  static readonly object _locker = new object();
 
  static void Main()
  {
    new Thread (Go).Start();
    Go();
  }
 
  static void Go()
  {
    <strong>lock (_locker)</strong>
    <strong>{</strong>
      if (!_done) { Console.WriteLine ("Done"); _done = true; }
    <strong>}</strong>
  }
}</pre>
<p>When two threads simultaneously contend a lock (which can be upon any reference-type object; in this case, <code>_locker</code>), one thread waits, or blocks, until the lock becomes available. In this case, it ensures that only one thread can enter its code block at a time, and “Done” will be printed just once. <a contenteditable="false" data-primary="locking" data-secondary="thread safety and" data-type="indexterm" id="id3661"/><a contenteditable="false" data-primary="thread-safe code" data-type="indexterm" id="id3662"/><a contenteditable="false" data-primary="threading" data-secondary="locking and thread safety" data-type="indexterm" id="id3663"/>Code that’s protected in such a manner—from indeterminacy in a multithreaded context—is called <em>thread safe</em>.</p>
<div data-type="warning" epub:type="warning"><h6>Warning</h6>
<p><a contenteditable="false" data-primary="x++ (incrementing)" data-type="indexterm" id="id3664"/>Even the act of autoincrementing a variable is not thread safe: the expression <code>x++</code> executes on the underlying processor as distinct read-increment-write operations. So, if two threads execute <code>x++</code> at once outside a lock, the variable can end up getting incremented once rather than twice (or worse, <code>x</code> could be <em>torn</em>, ending up with a bitwise mixture of old and new content, under certain conditions).</p>
</div>
<p>Locking is not a silver bullet for thread safety—it’s easy to forget to lock around accessing a field, and locking can create problems of its own (such as deadlocking).</p>
<p>A good example of when you might use locking is around accessing a shared in-memory cache for frequently accessed database objects in an ASP.NET application. This kind of application is simple to get right, and there’s no chance of deadlocking. We give an example in <a data-type="xref" href="ch21.html#thread_safety_in_application_servers">“Thread Safety in Application Servers”</a>.</p>
</div></section>
<section data-pdf-bookmark="Passing Data to a Thread" data-type="sect2"><div class="sect2" id="passing_data_to_a_thread">
<h2>Passing Data to a Thread</h2>
<p><a contenteditable="false" data-primary="threading" data-secondary="passing data to a thread" data-type="indexterm" id="ch14.html5"/>Sometimes, you’ll want to pass arguments to the thread’s startup method. The easiest way to do this is with a lambda expression that calls the method with the desired arguments:</p>
<pre data-type="programlisting">Thread t = new Thread ( <strong>() =&gt; Print ("Hello from t!")</strong> );
t.Start();

void Print (string message) =&gt; Console.WriteLine (message);</pre>
<p>With this approach, you can pass in any number of arguments to the method. You can even wrap the entire implementation in a multistatement lambda:</p>
<pre data-type="programlisting">new Thread (() =&gt;
{
  Console.WriteLine ("I'm running on another thread!");
  Console.WriteLine ("This is so easy!");
}).Start();</pre>
<p>An alternative (and less flexible) technique is to pass an argument into <code>Thread</code>’s <code>Start</code> method:</p>
<pre data-type="programlisting">Thread t = new Thread (Print);
t.Start <strong>("Hello from t!")</strong>;

void Print (object messageObj)
{
  string message = (string) messageObj;   // We need to cast here
  Console.WriteLine (message);
}</pre>
<p>This works because <code>Thread</code>’s constructor is overloaded to accept either of two <span class="keep-together">delegates</span>:</p>
<pre data-type="programlisting">public delegate void ThreadStart();
public delegate void ParameterizedThreadStart (object obj);</pre>
<section data-pdf-bookmark="Lambda expressions and captured variables" data-type="sect3"><div class="sect3" id="lambda_expressions_and_captured_variabl">
<h3>Lambda expressions and captured variables</h3>
<p><a contenteditable="false" data-primary="captured variables" data-type="indexterm" id="id3665"/><a contenteditable="false" data-primary="lambda expressions" data-secondary="captured variables and" data-type="indexterm" id="id3666"/><a contenteditable="false" data-primary="threading" data-secondary="lambda expressions and captured variables" data-type="indexterm" id="id3667"/>As we saw, a lambda expression is the most convenient and powerful way to pass data to a thread. However, you must be careful about accidentally modifying <em>captured variables</em> after starting the thread. For instance, consider the following:</p>
<pre data-type="programlisting">for (int i = 0; i &lt; 10; i++)
  new Thread (() =&gt; Console.Write (i)).Start();</pre>
<p>The output is nondeterministic! Here’s a typical result:</p>
<pre data-type="programlisting">0223557799</pre>
<p>The problem is that the <code>i</code> variable refers to the <em>same</em> memory location throughout the loop’s lifetime. Therefore, each thread calls <code>Console.Write</code> on a variable whose value can change as it is running! The solution is to use a temporary variable as <span class="keep-together">follows</span>:</p>
<pre data-type="programlisting">for (int i = 0; i &lt; 10; i++)
{
  int temp = i;
  new Thread (() =&gt; Console.Write (temp)).Start();
}</pre>
<p>Each of the digits 0 to 9 is then written exactly once. (The <em>ordering</em> is still undefined because threads can start at indeterminate times.)</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>This is analogous to the problem we described in <a data-type="xref" href="ch08.html#captured_variables">“Captured Variables”</a>. The problem is just as much about C#’s rules for capturing variables in <code>for</code> loops as it is about multithreading.</p>
</div>
<p>Variable <code>temp</code> is now local to each loop iteration. Therefore, each thread captures a different memory location and there’s no problem. We can illustrate the problem in the earlier code more simply with the following example:</p>
<pre data-type="programlisting">string text = "t1";
Thread t1 = new Thread ( () =&gt; Console.WriteLine (text) );

text = "t2";
Thread t2 = new Thread ( () =&gt; Console.WriteLine (text) );

t1.Start(); t2.Start();</pre>
<p>Because both lambda expressions capture the same text variable, <code>t2</code> is printed twice.<a contenteditable="false" data-primary="" data-startref="ch14.html5" data-type="indexterm" id="id3668"/></p>
</div></section>
</div></section>
<section data-pdf-bookmark="Exception Handling" data-type="sect2"><div class="sect2" id="exception_handling">
<h2>Exception Handling</h2>
<p><a contenteditable="false" data-primary="exception handling" data-secondary="threading and" data-type="indexterm" id="id3669"/><a contenteditable="false" data-primary="threading" data-secondary="exception handling" data-type="indexterm" id="id3670"/>Any <code>try</code>/<code>catch</code>/<code>finally</code> blocks in effect when a thread is created are of no relevance to the thread when it starts executing. Consider the following program:</p>
<pre data-type="programlisting">try
{
  new Thread (Go).Start();
}
catch (Exception ex)
{
  // We'll never get here!
  Console.WriteLine ("Exception!");
}

void Go() { throw null; }   // Throws a NullReferenceException</pre>
<p>The <code>try</code>/<code>catch</code> statement in this example is ineffective, and the newly created thread will be encumbered with an unhandled <code>NullReferenceException</code>. This behavior makes sense when you consider that each thread has an independent execution path.</p>
<p>The remedy is to move the exception handler into the <code>Go</code> method:</p>
<pre data-type="programlisting">new Thread (Go).Start();

void Go()
{
  try
  {
    ...
    throw null;    // The NullReferenceException will get caught below
    ...
  }
  catch (Exception ex)
  {
    // Typically log the exception and/or signal another thread
    // that we've come unstuck
    ...
  }
}</pre>
<p>You need an exception handler on all thread entry methods in production applications—just as you do (usually at a higher level, in the execution stack) on your main thread. An unhandled exception causes the whole application to shut down—with an ugly dialog box!</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>In writing such exception handling blocks, rarely would you <em>ignore</em> the error: typically, you’d log the details of the exception. For a client application, you might display a dialog box allowing the user to automatically submit those details to your web server. You then might choose to restart the application, because it’s possible that an unexpected exception might leave your program in an invalid state.</p>
</div>
<section data-pdf-bookmark="Centralized exception handling" data-type="sect3"><div class="sect3" id="centralized_exception_handling">
<h3>Centralized exception handling</h3>
<p><a contenteditable="false" data-primary="Application.DispatcherUnhandledException" data-type="indexterm" id="id3671"/><a contenteditable="false" data-primary="Application.ThreadException" data-type="indexterm" id="id3672"/><a contenteditable="false" data-primary="centralized exception handling" data-type="indexterm" id="id3673"/><a contenteditable="false" data-primary="exception handling" data-secondary="centralized" data-type="indexterm" id="id3674"/>In WPF, UWP, and Windows Forms applications, you can subscribe to “global” exception handling events, <code>Application.DispatcherUnhandledException</code> and <code>Application.ThreadException</code>, respectively. These fire after an unhandled exception in any part of your program that’s called via the message loop (this amounts to all code that runs on the main thread while the <code>Application</code> is active). This is useful as a backstop for logging and reporting bugs (although it won’t fire for unhandled exceptions on worker threads that you create). Handling these events prevents the program from shutting down, although you may choose to restart the application to avoid the potential corruption of state that can follow from (or that led to) the unhandled exception.</p>
</div></section>
</div></section>
<section data-pdf-bookmark="Foreground Versus Background Threads" data-type="sect2"><div class="sect2" id="foreground_versus_background_threads">
<h2>Foreground Versus Background Threads</h2>
<p><a contenteditable="false" data-primary="background threads" data-type="indexterm" id="id3675"/><a contenteditable="false" data-primary="foreground threads" data-type="indexterm" id="id3676"/><a contenteditable="false" data-primary="threading" data-secondary="foreground versus background threads" data-type="indexterm" id="id3677"/>By default, threads you create explicitly are <em>foreground threads</em>. Foreground threads keep the application alive for as long as any one of them is running, whereas <em>background threads</em> do not. After all foreground threads finish, the application ends, and any background threads still running abruptly terminate.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>A thread’s foreground/background status has no relation to its <em>priority</em> (allocation of execution time).</p>
</div>
<p>You can query or change a thread’s background status using its <code>IsBackground</code> <span class="keep-together">property</span>:</p>
<pre data-type="programlisting">static void Main (string[] args)
{
  Thread worker = new Thread ( () =&gt; Console.ReadLine() );
  if (args.Length &gt; 0) worker.IsBackground = true;
  worker.Start();
}</pre>
<p>If this program is called with no arguments, the worker thread assumes foreground status and will wait on the <code>ReadLine</code> statement for the user to press Enter. Meanwhile, the main thread exits, but the application keeps running because a foreground thread is still alive. On the other hand, if an argument is passed to <code>Main()</code>, the worker is assigned background status, and the program exits almost immediately as the main thread ends (terminating the <code>ReadLine</code>).</p>
<p>When a process terminates in this manner, any <code>finally</code> blocks in the execution stack of background threads are circumvented. If your program employs <code>finally</code> (or <code>using</code>) blocks to perform cleanup work such as deleting temporary files, you can avoid this by explicitly waiting out such background threads upon exiting an application, either by joining the thread or with a signaling construct (see <a data-type="xref" href="#signaling">“Signaling”</a>). In either case, you should specify a timeout, so you can abandon a renegade thread should it refuse to finish; otherwise your application will fail to close without the user having to enlist help from the Task Manager (or on Unix, the <code>kill</code> command).</p>
<p>Foreground threads don’t require this treatment, but you must take care to avoid bugs that could cause the thread not to end. A common cause for applications failing to exit properly is the presence of active foreground threads.</p>
</div></section>
<section data-pdf-bookmark="Thread Priority" data-type="sect2"><div class="sect2" id="thread_priority">
<h2>Thread Priority</h2>
<p><a contenteditable="false" data-primary="Priority property" data-type="indexterm" id="id3678"/><a contenteditable="false" data-primary="threading" data-secondary="Priority property" data-type="indexterm" id="id3679"/>A thread’s <code>Priority</code> property determines how much execution time it is allotted relative to other active threads in the OS, on the following scale:</p>
<pre data-type="programlisting">enum ThreadPriority { Lowest, BelowNormal, Normal, AboveNormal, Highest }</pre>
<p>This becomes relevant when multiple threads are simultaneously active. You need to take care when elevating a thread’s priority because it can starve other threads. If you want a thread to have higher priority than threads in <em>other</em> processes, you must also elevate the process priority using the <a contenteditable="false" data-primary="Process class" data-type="indexterm" id="id3680"/><a contenteditable="false" data-primary="System..." data-secondary="System.Diagnostics" data-type="indexterm" id="id3681"/><code>Process</code> class in <code>System.Diagnostics</code>:</p>
<pre data-type="programlisting">using Process p = Process.GetCurrentProcess();
p.PriorityClass = ProcessPriorityClass.High;</pre>
<p>This can work well for non-UI processes that do minimal work and need low latency (the ability to respond very quickly) in the work they do. With compute-hungry applications (particularly those with a user interface), elevating process priority can starve other processes, slowing down the entire computer.</p>
</div></section>
<section data-pdf-bookmark="Signaling" data-type="sect2"><div class="sect2" id="signaling">
<h2>Signaling</h2>
<p><a contenteditable="false" data-primary="signaling" data-secondary="threading" data-type="indexterm" id="id3682"/><a contenteditable="false" data-primary="threading" data-secondary="signaling" data-type="indexterm" id="id3683"/>Sometimes, you need a thread to wait until receiving notification(s) from other thread(s). This is called <em>signaling</em>. The simplest signaling construct is <code>ManualReset​Event</code>. Calling <code>WaitOne</code> on a <code>ManualResetEvent</code> blocks the current thread until another thread “opens” the signal by calling <code>Set</code>. In the following example, we start up a thread that waits on a <code>ManualResetEvent</code>. It remains blocked for two seconds until the main thread <em>signals</em> it:</p>
<pre data-type="programlisting">var signal = new ManualResetEvent (false);

new Thread (() =&gt;
{
  Console.WriteLine ("Waiting for signal...");
  <strong>signal.WaitOne();</strong>
  signal.Dispose();
  Console.WriteLine ("Got signal!");
}).Start();

Thread.Sleep(2000);
<strong>signal.Set();</strong>        // “Open” the signal</pre>
<p>After calling <code>Set</code>, the signal remains open; you can close it again by calling <code>Reset</code>.</p>
<p><code>ManualResetEvent</code> is one of several signaling constructs provided by the CLR; we cover all of them in detail in <a data-type="xref" href="ch21.html#advanced_threadin">Chapter 21</a>.</p>
</div></section>
<section data-pdf-bookmark="Threading in Rich Client Applications" data-type="sect2"><div class="sect2" id="threading_in_rich_client_applications">
<h2>Threading in Rich Client Applications</h2>
<p><a contenteditable="false" data-primary="rich-client applications" data-secondary="threading in" data-type="indexterm" id="ch14.html6"/><a contenteditable="false" data-primary="threading" data-secondary="in rich-client applications" data-type="indexterm" id="ch14.html7"/>In WPF, UWP, and Windows Forms applications, executing long-running operations on the main thread makes the application unresponsive because the main thread also processes the message loop that performs rendering and handles keyboard and mouse events.</p>
<p>A popular approach is to start up “worker” threads for time-consuming operations. The code on a worker thread runs a time-consuming operation and then updates the UI when complete. However, all rich client applications have a threading model whereby UI elements and controls can be accessed only from the thread that created them (typically the main UI thread). Violating this causes either unpredictable behavior or an exception to be thrown.</p>
<p>Hence when you want to update the UI from a worker thread, you must forward the request to the UI thread (the technical term is <em>marshal</em>). The low-level way to do this is as follows (later, we discuss other solutions that build on these):</p>
<ul>
<li><p>In WPF, call <code>BeginInvoke</code> or <code>Invoke</code> on the element’s <code>Dispatcher</code> object.</p></li>
<li><p>In UWP apps, call <code>RunAsync</code> or <code>Invoke</code> on the <code>Dispatcher</code> object.</p></li>
<li><p>In Windows Forms, call <code>BeginInvoke</code> or <code>Invoke</code> on the control.</p></li>
</ul>
<p>All of these methods accept a delegate referencing the method you want to run. <code>BeginInvoke/RunAsync</code> work by enqueuing the delegate to the UI thread’s <em>message queue</em> (the same queue that handles keyboard, mouse, and timer events). <code>Invoke</code> does the same thing but then blocks until the message has been read and processed by the UI thread. Because of this, <code>Invoke</code> lets you get a return value back from the method. If you don’t need a return value, <code>BeginInvoke</code>/<code>RunAsync</code> are preferable in that they don’t block the caller and don’t introduce the possibility of deadlock (see <a data-type="xref" href="ch21.html#deadlocks">“Deadlocks”</a>).</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>You can imagine that when you call <code>Application.Run</code>, the following pseudo-code executes:</p>
<pre data-type="programlisting">while (!<em>thisApplication.Ended</em>)
{
<em>  wait for something to appear in message queue</em>
<em>  Got something: what kind of message is it?</em>
<em>    Keyboard/mouse message -&gt; fire an event handler</em>
<em>    User</em> <strong>BeginInvoke</strong><em> message -&gt; execute delegate</em>
<em>    User <strong>Invoke</strong> message -&gt; execute delegate &amp; post result</em>
}</pre>
<p>It’s this kind of loop that enables a worker thread to marshal a delegate for execution onto the UI thread.</p>
</div>
<p>To demonstrate, suppose that we have a WPF window that contains a text box called <code>txtMessage</code>, whose content we want a worker thread to update after performing a time-consuming task (which we will simulate by calling <code>Thread.Sleep</code>). Here’s how we’d do it:</p>
<pre data-type="programlisting">partial class MyWindow : Window
{
  public MyWindow()
  {
    InitializeComponent();
    new Thread (Work).Start();
  }

  void Work()
  {
    Thread.Sleep (5000);           // Simulate time-consuming task
    UpdateMessage ("The answer");
  }

  void UpdateMessage (string message)
  {
    Action action = () =&gt; txtMessage.Text = message;
    <strong>Dispatcher.BeginInvoke (action);</strong>
  }
}</pre>
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="multiple_ui_threads">
<h1>Multiple UI Threads</h1>
<p><a contenteditable="false" data-primary="threading" data-secondary="multiple UI threads" data-type="indexterm" id="id3684"/><a contenteditable="false" data-primary="UI (user interface)" data-secondary="multiple UI threads" data-type="indexterm" id="id3685"/><a contenteditable="false" data-primary="user interface (UI)" data-secondary="multiple UI threads" data-type="indexterm" id="id3686"/>It’s possible to have multiple UI threads if they each own different windows. The main scenario is when you have an application with multiple top-level windows, often called a <em>Single Document Interface</em> (SDI) application, such as Microsoft Word. Each SDI window typically shows itself as a separate “application” on the taskbar and is mostly isolated, functionally, from other SDI windows. By giving each such window its own UI thread, each window can be made more responsive with respect to the others.</p>
</div></aside>
<p>Running this results in a responsive window appearing immediately. Five seconds later, it updates the textbox. The code is similar for Windows Forms, except that we call the (<code>Form</code>’s) <code>BeginInvoke</code> method instead:<a contenteditable="false" data-primary="" data-startref="ch14.html7" data-type="indexterm" id="id3687"/><a contenteditable="false" data-primary="" data-startref="ch14.html6" data-type="indexterm" id="id3688"/></p>
<pre data-type="programlisting">  void UpdateMessage (string message)
  {
    Action action = () =&gt; txtMessage.Text = message;
    <strong>this.BeginInvoke (action);</strong>
  <strong>}</strong></pre>
</div></section>
<section data-pdf-bookmark="Synchronization Contexts" data-type="sect2"><div class="sect2" id="synchronization_contexts">
<h2>Synchronization Contexts</h2>
<p><a contenteditable="false" data-primary="SynchronizationContext class" data-type="indexterm" id="id3689"/><a contenteditable="false" data-primary="System..." data-secondary="System.ComponentModel" data-type="indexterm" id="id3690"/><a contenteditable="false" data-primary="threading" data-secondary="synchronization contexts" data-type="indexterm" id="id3691"/>In the <code>System.ComponentModel</code> namespace, there’s a class called <code>SynchronizationContext</code>, which enables the generalization of thread marshaling.</p>
<p>The rich-client APIs for mobile and desktop (UWP, WPF, and Windows Forms) each define and instantiate <code>SynchronizationContext</code> subclasses, which you can obtain via the static property <code>SynchronizationContext.Current</code> (while running on a UI thread). Capturing this property lets you later “post” to UI controls from a worker thread:</p>
<pre data-type="programlisting">partial class MyWindow : Window
{
  <strong>SynchronizationContext _uiSyncContext;</strong>

  public MyWindow()
  {
    InitializeComponent();
    // Capture the synchronization context for the current UI thread:
    <strong>_uiSyncContext = SynchronizationContext.Current;</strong>
    new Thread (Work).Start();
  }

  void Work()
  {
    Thread.Sleep (5000);           // Simulate time-consuming task
    UpdateMessage ("The answer");
  }

  void UpdateMessage (string message)
  {
    // Marshal the delegate to the UI thread:
    <strong>_uiSyncContext.Post (_ =&gt; txtMessage.Text = message, null);</strong>
  }
}</pre>
<p>This is useful because the same technique works with all rich-client user interface APIs.</p>
<p>Calling <code>Post</code> is equivalent to calling <code>BeginInvoke</code> on a <code>Dispatcher</code> or <code>Control</code>; there’s also a <code>Send</code> method that is equivalent to <code>Invoke</code>.</p>
</div></section>
<section data-pdf-bookmark="The Thread Pool" data-type="sect2"><div class="sect2" id="the_thread_pool">
<h2>The Thread Pool</h2>
<p><a contenteditable="false" data-primary="thread pool" data-type="indexterm" id="id3692"/><a contenteditable="false" data-primary="threading" data-secondary="thread pool" data-type="indexterm" id="id3693"/>Whenever you start a thread, a few hundred microseconds are spent organizing such things as a fresh local variable stack. The <em>thread pool</em> cuts this overhead by having a pool of pre-created recyclable threads. Thread pooling is essential for efficient parallel programming and fine-grained concurrency; it allows short operations to run without being overwhelmed with the overhead of thread startup.</p>
<p>There are a few things to be wary of when using pooled threads:</p>
<ul>
<li><p>You cannot set the <code>Name</code> of a pooled thread, making debugging more difficult (although you can attach a description when debugging in Visual Studio’s Threads window).</p></li>
<li><p>Pooled threads are always <em>background threads</em>.</p></li>
<li><p>Blocking pooled threads can degrade performance (see <a data-type="xref" href="#hygiene_in_the_thread_pool">“Hygiene in the thread pool”</a>).</p></li>
</ul>
<p>You are free to change the priority of a pooled thread—it will be restored to normal when released back to the pool.</p>
<p>You can determine whether you’re currently executing on a pooled thread via the property <code>Thread.CurrentThread.IsThreadPoolThread</code>.</p>
<section data-pdf-bookmark="Entering the thread pool" data-type="sect3"><div class="sect3" id="entering_the_thread_pool">
<h3>Entering the thread pool</h3>
<p><a contenteditable="false" data-primary="thread pool" data-secondary="entering" data-type="indexterm" id="id3694"/>The easiest way to explicitly run something on a pooled thread is to use <code>Task.Run</code> (we cover this in more detail in the following section):</p>
<pre data-type="programlisting">// Task is in System.Threading.Tasks
Task.Run (() =&gt; Console.WriteLine ("Hello from the thread pool"));</pre>
<p>Because tasks didn’t exist prior to .NET Framework 4.0, a common alternative is to call <code>ThreadPool.QueueUserWorkItem</code>:</p>
<pre data-type="programlisting">ThreadPool.QueueUserWorkItem (notUsed =&gt; Console.WriteLine ("Hello"));</pre>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>The following use the thread pool implicitly:</p>
<ul>
<li><p>ASP.NET Core and Web API application servers</p></li>
<li><p><code>System.Timers.Timer</code> and <code>System.Threading.Timer</code></p></li>
<li><p>The parallel programming constructs that we describe in <a data-type="xref" href="ch22.html#parallel_programming-id00071">Chapter 22</a></p></li>
<li><p>The (legacy) <code>BackgroundWorker</code> class</p></li>
</ul>
</div>
</div></section>
<section data-pdf-bookmark="Hygiene in the thread pool" data-type="sect3"><div class="sect3" id="hygiene_in_the_thread_pool">
<h3>Hygiene in the thread pool</h3>
<p><a contenteditable="false" data-primary="oversubscription" data-type="indexterm" id="id3695"/><a contenteditable="false" data-primary="thread pool" data-secondary="hygiene in" data-type="indexterm" id="id3696"/>The thread pool serves another function, which is to ensure that a temporary excess of compute-bound work does not cause CPU <em>oversubscription</em>. Oversubscription is the condition of there being more active threads than CPU cores, with the OS having to time-slice threads. Oversubscription hurts performance because time-slicing requires expensive context switches and can invalidate the CPU caches that have become essential in delivering performance to modern processors.</p>
<p>The CLR prevents oversubscription in the thread pool by queuing tasks and throttling their startup. It begins by running as many concurrent tasks as there are hardware cores, and then tunes the level of concurrency via a hill-climbing algorithm, continually adjusting the workload in a particular direction. If throughput improves, it continues in the same direction (otherwise it reverses). This ensures that it always tracks the optimal performance curve—even in the face of competing process activity on the computer.</p>
<p>The CLR’s strategy works best if two conditions are met:</p>
<ul>
<li><p>Work items are mostly short-running (&lt; 250 ms, or ideally &lt; 100 ms) so that the CLR has plenty of opportunities to measure and adjust.</p></li>
<li><p>Jobs that spend most of their time blocked do not dominate the pool.</p></li>
</ul>
<p>Blocking is troublesome because it gives the CLR the false idea that it’s loading up the CPU. The CLR is smart enough to detect and compensate (by injecting more threads into the pool), although this can make the pool vulnerable to subsequent oversubscription. It also can introduce latency because the CLR throttles the rate at which it injects new threads, particularly early in an application’s life (more so on client operating systems where it favors lower resource consumption).</p>
<p>Maintaining good hygiene in the thread pool is particularly relevant when you want to fully utilize the CPU (e.g., via the parallel programming APIs in <a data-type="xref" href="ch22.html#parallel_programming-id00071">Chapter 22</a>).<a contenteditable="false" data-primary="" data-startref="ch14.html2" data-type="indexterm" id="id3697"/><a contenteditable="false" data-primary="" data-startref="ch14.html1" data-type="indexterm" id="id3698"/></p>
</div></section>
</div></section>
</div></section>
<section class="pagebreak-before" data-pdf-bookmark="Tasks" data-type="sect1"><div class="sect1" id="tasks">
<h1 class="less_space">Tasks</h1>
<p><a contenteditable="false" data-primary="concurrency and asynchrony" data-secondary="tasks" data-type="indexterm" id="ch14.html8"/><a contenteditable="false" data-primary="tasks" data-type="indexterm" id="ch14.html9"/>A <a contenteditable="false" data-primary="threading" data-secondary="limitations of" data-type="indexterm" id="id3699"/>thread is a low-level tool for creating concurrency, and as such, it has limitations, particularly the following:</p>
<ul>
<li><p>Although it’s easy to pass data into a thread that you start, there’s no easy way to get a “return value” back from a thread that you <code>Join</code>. You need to set up some kind of shared field. And if the operation throws an exception, catching and propagating that exception is equally painful.</p></li>
<li><p>You can’t tell a thread to start something else when it’s finished; instead you must <code>Join</code> it (blocking your own thread in the process).</p></li>
</ul>
<p>These limitations discourage fine-grained concurrency; in other words, they make it difficult to compose larger concurrent operations by combining smaller ones (something essential for the asynchronous programming that we look at in following sections). This in turn leads to greater reliance on manual synchronization (locking, signaling, and so on) and the problems that go with it.</p>
<p>The direct use of threads also has performance implications that we discussed in <a data-type="xref" href="#the_thread_pool">“The Thread Pool”</a>. And should you need to run hundreds or thousands of concurrent I/O-bound operations, a thread-based approach consumes hundreds or thousands of megabytes of memory purely in thread overhead.</p>
<p><a contenteditable="false" data-primary="Task..." data-secondary="Task class" data-type="indexterm" id="id3700"/>The <code>Task</code> class helps with all of these problems. Compared to a thread, a <code>Task</code> is higher-level abstraction—it represents a concurrent operation that might or might not be backed by a thread. Tasks are <em>compositional</em> (you can chain them together through the use of <em>continuations</em>). They can use the <em>thread pool</em> to lessen startup latency, and with a <code>TaskCompletionSource</code>, they can employ a callback approach that avoids threads altogether while waiting on I/O-bound operations.</p>
<p>The <code>Task</code> types were introduced in Framework 4.0 as part of the parallel programming library. However, they have since been enhanced (through the use of <em>awaiters</em>) to play equally well in more general concurrency scenarios and are backing types for C#’s asynchronous functions.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>In this section, we ignore the features of tasks that are aimed specifically at parallel programming; we cover them instead in <a data-type="xref" href="ch22.html#parallel_programming-id00071">Chapter 22</a>.</p>
</div>
<section data-pdf-bookmark="Starting a Task" data-type="sect2"><div class="sect2" id="starting_a_task">
<h2>Starting a Task</h2>
<p><a contenteditable="false" data-primary="System..." data-secondary="System.Threading.Tasks" data-type="indexterm" id="id3701"/><a contenteditable="false" data-primary="Task..." data-secondary="Task.Run" data-type="indexterm" id="id3702"/>The <a contenteditable="false" data-primary="tasks" data-secondary="starting a task" data-type="indexterm" id="ch14.html10"/>easiest way to start a <code>Task</code> backed by a thread is with the static method <code>Task.Run</code> (the <code>Task</code> class is in the <code>System.Threading.Tasks</code> namespace). Simply pass in an <code>Action</code> delegate:</p>
<pre data-type="programlisting">Task.Run (() =&gt; Console.WriteLine ("Foo"));</pre>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>Tasks use pooled threads by default, which are background threads. This means that when the main thread ends, so do any tasks that you create. Hence, to run these examples from a console application, you must block the main thread after starting the task (for instance, by <code>Wait</code>ing the task or by calling <code>Console.ReadLine</code>):</p>
<pre data-type="programlisting">Task.Run (() =&gt; Console.WriteLine ("Foo"));
Console.ReadLine();</pre>
<p>In the book’s LINQPad companion samples, <code>Console.ReadLine</code> is omitted because the LINQPad process keeps background threads alive.</p>
</div>
<p>Calling <code>Task.Run</code> in this manner is similar to starting a thread as follows (except for the thread pooling implications that we discuss shortly):</p>
<pre data-type="programlisting">new Thread (() =&gt; Console.WriteLine ("Foo")).Start();</pre>
<p><code>Task.Run</code> returns a <code>Task</code> object that we can use to monitor its progress, rather like a <code>Thread</code> object. (Notice, however, that we didn’t call <code>Start</code> after calling <code>Task.Run</code> because this method creates “hot” tasks; you can instead use <code>Task</code>’s constructor to create “cold” tasks, although this is rarely done in practice.)</p>
<p>You can track a task’s execution status via its <code>Status</code> property.</p>
<section data-pdf-bookmark="Wait" data-type="sect3"><div class="sect3" id="wait">
<h3>Wait</h3>
<p><a contenteditable="false" data-primary="tasks" data-secondary="Wait method" data-type="indexterm" id="id3703"/><a contenteditable="false" data-primary="Wait method" data-type="indexterm" id="id3704"/>Calling <code>Wait</code> on a task blocks until it completes and is the equivalent of calling <code>Join</code> on a thread:</p>
<pre data-type="programlisting">Task task = Task.Run (() =&gt;
{
  Thread.Sleep (2000);
  Console.WriteLine ("Foo");
});
Console.WriteLine (task.IsCompleted);  // False
task.Wait();  // Blocks until task is complete</pre>
<p><code>Wait</code> lets you optionally specify a timeout and a cancellation token to end the wait early (see <a data-type="xref" href="#cancellation">“Cancellation”</a>).</p>
</div></section>
<section data-pdf-bookmark="Long-running tasks" data-type="sect3"><div class="sect3" id="long_running_tasks">
<h3>Long-running tasks</h3>
<p><a contenteditable="false" data-primary="tasks" data-secondary="long-running" data-type="indexterm" id="id3705"/>By default, the CLR runs tasks on pooled threads, which is ideal for short-running compute-bound work. For longer-running and blocking operations (such as our preceding example), you can prevent use of a pooled thread as follows:</p>
<pre data-type="programlisting">Task task = Task.Factory.StartNew (() =&gt; ...,
                                   <strong>TaskCreationOptions.LongRunning</strong>);</pre>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>Running <em>one</em> long-running task on a pooled thread won’t cause trouble; it’s when you run multiple long-running tasks in parallel (particularly ones that block) that performance can suffer. <a contenteditable="false" data-primary="Task..." data-secondary="TaskCreationOptions.LongRunning" data-type="indexterm" id="id3706"/>And in that case, there are usually better solutions than <code>TaskCreationOptions.LongRunning</code>:</p>
<ul>
<li><p>If the tasks are I/O bound, <code>TaskCompletionSource</code> and <em>asynchronous functions</em> let you implement concurrency with callbacks (continuations) instead of threads.</p></li>
<li><p>If the tasks are compute bound, a <em>producer/consumer queue</em> lets you throttle the concurrency for those tasks, avoiding starvation for other threads and processes (see <a data-type="xref" href="ch22.html#writing_a_producersolidusconsumer_queue">“Writing a Producer/Consumer Queue”</a>).<a contenteditable="false" data-primary="" data-startref="ch14.html10" data-type="indexterm" id="id3707"/></p></li>
</ul>
</div>
</div></section>
</div></section>
<section data-pdf-bookmark="Returning Values" data-type="sect2"><div class="sect2" id="returning_values">
<h2>Returning Values</h2>
<p><a contenteditable="false" data-primary="Task..." data-secondary="Task&lt;TResult&gt;" data-type="indexterm" id="id3708"/><a contenteditable="false" data-primary="tasks" data-secondary="returning values" data-type="indexterm" id="id3709"/><code>Task</code> has a generic subclass called <code>Task&lt;TResult&gt;</code>, which allows a task to emit a return value. You can obtain a <code>Task&lt;TResult&gt;</code> by calling <code>Task.Run</code> with a <code>Func​&lt;TRe⁠sult&gt;</code> delegate (or a compatible lambda expression) instead of an <code>Action</code>:</p>
<pre data-type="programlisting">Task&lt;int&gt; task = Task.Run (() =&gt; { Console.WriteLine ("Foo"); <strong>return 3</strong>; });
// ...</pre>
<p>You can obtain the result later by querying the <code>Result</code> property. If the task hasn’t yet finished, accessing this property will block the current thread until the task finishes:</p>
<pre data-type="programlisting">int result = task.Result;      // Blocks if not already finished
Console.WriteLine (result);    // 3</pre>
<p>In the following example, we create a task that uses LINQ to count the number of prime numbers in the first three million (+2) integers:</p>
<pre data-type="programlisting">Task&lt;int&gt; primeNumberTask = Task.Run (() =&gt;
  Enumerable.Range (2, 3000000).Count (n =&gt; 
    Enumerable.Range (2, (int)Math.Sqrt(n)-1).All (i =&gt; n % i &gt; 0)));

Console.WriteLine ("Task running...");
Console.WriteLine ("The answer is " + primeNumberTask.Result);</pre>
<p>This writes “Task running...” and then a few seconds later writes the answer of 216816.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p><code>Task&lt;TResult&gt;</code> can be thought of as a “future,” in that it encapsulates a <code>Result</code> that becomes available later in time.</p>
</div>
</div></section>
<section data-pdf-bookmark="Exceptions" data-type="sect2"><div class="sect2" id="exceptions">
<h2>Exceptions</h2>
<p><a contenteditable="false" data-primary="exceptions" data-secondary="tasks and" data-type="indexterm" id="id3710"/><a contenteditable="false" data-primary="tasks" data-secondary="exceptions" data-type="indexterm" id="id3711"/>Unlike with threads, tasks conveniently propagate exceptions. So, if the code in your task throws an unhandled exception (in other words, if your task <em>faults</em>), that exception is automatically rethrown to whoever calls <code>Wait()</code>—or accesses the <code>Result</code> property of a <code>Task&lt;TResult&gt;</code>:</p>
<pre data-type="programlisting">// Start a Task that throws a NullReferenceException:
Task task = Task.Run (() =&gt; { throw null; });
try 
{
  task.Wait();
}
catch (AggregateException aex)
{
  if (aex.InnerException is NullReferenceException)
    Console.WriteLine ("Null!");
  else
    throw;
}</pre>
<p><a contenteditable="false" data-primary="AggregateException class" data-type="indexterm" id="id3712"/>(The CLR wraps the exception in an <code>AggregateException</code> in order to play well with parallel programming scenarios; we discuss this in <a data-type="xref" href="ch22.html#parallel_programming-id00071">Chapter 22</a>.)</p>
<p>You can test for a faulted task without rethrowing the exception via the <code>IsFaulted</code> and <code>IsCanceled</code> properties of the <code>Task</code>. If both properties return false, no error occurred; if <code>IsCanceled</code> is true, an <code>OperationCanceledException</code> was thrown for that task (see <a data-type="xref" href="ch22.html#cancellation-id00006">“Cancellation”</a>); if <code>IsFaulted</code> is true, another type of exception was thrown, and the <code>Exception</code> property will indicate the error.</p>
<section data-pdf-bookmark="Exceptions and autonomous tasks" data-type="sect3"><div class="sect3" id="exceptions_and_autonomous_tasks">
<h3>Exceptions and autonomous tasks</h3>
<p><a contenteditable="false" data-primary="autonomous tasks" data-type="indexterm" id="id3713"/><a contenteditable="false" data-primary="exceptions" data-secondary="autonomous tasks and" data-type="indexterm" id="id3714"/><a contenteditable="false" data-primary="tasks" data-secondary="exceptions and autonomous tasks" data-type="indexterm" id="id3715"/>With autonomous “set-and-forget” tasks (those for which you don’t rendezvous via <code>Wait()</code> or <code>Result</code>, or a continuation that does the same), it’s good practice to explicitly exception-handle the task code to avoid silent failure, just as you would with a thread.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>Ignoring exceptions is fine when an exception solely indicates a failure to obtain a result that you’re no longer interested in. For example, if a user cancels a request to download a web page, we wouldn’t care if it turns out that the web page didn’t exist.</p>
<p>Ignoring exceptions is problematic when an exception indicates a bug in your program, for two reasons:</p>
<ul>
<li><p>The bug may have left your program in an invalid state.</p></li>
<li><p>More exceptions may occur later as a result of the bug, and failure to log the initial error can make diagnosis <span class="keep-together">difficult</span>.</p></li>
</ul>
</div>
<p><a contenteditable="false" data-primary="Task..." data-secondary="TaskScheduler.UnobservedTaskException" data-type="indexterm" id="id3716"/>You can subscribe to unobserved exceptions at a global level via the static event <code>TaskScheduler.UnobservedTaskException</code>; handling this event and logging the error can make good sense.</p>
<p>There are a couple of interesting nuances on what counts as unobserved:</p>
<ul>
<li><p>Tasks waited upon with a timeout will generate an unobserved exception if the fault occurs <em>after</em> the timeout interval.</p></li>
<li><p>The act of checking a task’s <code>Exception</code> property after it has faulted makes the exception “observed.”</p></li>
</ul>
</div></section>
</div></section>
<section data-pdf-bookmark="Continuations" data-type="sect2"><div class="sect2" id="continuations">
<h2>Continuations</h2>
<p><a contenteditable="false" data-primary="continuations" data-secondary="tasks and" data-type="indexterm" id="ch14.html11"/><a contenteditable="false" data-primary="tasks" data-secondary="continuations" data-type="indexterm" id="ch14.html12"/>A continuation says to a task, “When you’ve finished, continue by doing something else.” A continuation is usually implemented by a callback that executes once upon completion of an operation. There are two ways to attach a continuation to a task. The first is particularly significant because it’s used by C#’s asynchronous functions, as you’ll see soon. We can demonstrate it with the prime number counting task that we wrote a short while ago in <a data-type="xref" href="#returning_values">“Returning Values”</a>:</p>
<pre data-type="programlisting">Task&lt;int&gt; primeNumberTask = Task.Run (() =&gt;
  Enumerable.Range (2, 3000000).Count (n =&gt; 
    Enumerable.Range (2, (int)Math.Sqrt(n)-1).All (i =&gt; n % i &gt; 0)));

<strong>var awaiter = primeNumberTask.GetAwaiter();</strong>
awaiter.OnCompleted (() =&gt; 
{
  int result = <strong>awaiter.GetResult();</strong>
  Console.WriteLine (result);       // Writes result
});</pre>
<p>Calling <code>GetAwaiter</code> on the task returns an <em>awaiter</em> object whose <code>OnCompleted</code> method tells the <em>antecedent</em> task (<code>primeNumberTask</code>) to execute a delegate when it finishes (or faults). It’s valid to attach a continuation to an already-completed task, in which case the continuation will be scheduled to execute right away.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>An <em>awaiter</em> is any object that exposes the two methods that we’ve just seen (<code>OnCompleted</code> and <code>GetResult</code>) and a Boolean property called <code>IsCompleted</code>. There’s no interface or base class to unify all of these members (although <code>OnCompleted</code> is part of the interface <code>INotifyCompletion</code>). We explain the significance of the pattern in <a data-type="xref" href="#asynchronous_functions_in_chash">“Asynchronous Functions in C#”</a>.</p>
</div>
<p>If an antecedent task faults, the exception is rethrown when the continuation code calls <code>awaiter.GetResult()</code>. Rather than calling <code>GetResult</code>, we could simply access the <code>Result</code> property of the antecedent. The benefit of calling <code>GetResult</code> is that if the antecedent faults, the exception is <a contenteditable="false" data-primary="AggregateException class" data-type="indexterm" id="id3717"/>thrown directly without being wrapped in <code>AggregateException</code>, allowing for simpler and cleaner <code>catch</code> blocks.</p>
<p>For nongeneric tasks, <code>GetResult()</code> has a void return value. Its useful function is then solely to rethrow exceptions.</p>
<p>If a synchronization context is present, <code>OnCompleted</code> automatically captures it and posts the continuation to that context. This is very useful in rich client applications because it bounces the continuation back to the UI thread. In writing libraries, however, it’s not usually desirable because the relatively expensive UI-thread-bounce should occur just once upon leaving the library rather than between method calls. Hence, you can defeat it by using the <code>ConfigureAwait</code> method:</p>
<pre data-type="programlisting">var awaiter = primeNumberTask.ConfigureAwait (false).GetAwaiter();</pre>
<p>If no synchronization context is present—or you use <code>ConfigureAwait(false)</code>—the continuation will (in general) execute on a pooled thread.</p>
<p>The other way to attach a continuation is by calling the task’s <code>ContinueWith</code> method:</p>
<pre data-type="programlisting">primeNumberTask.ContinueWith (antecedent =&gt; 
{
  int result = antecedent.Result;
  Console.WriteLine (result);          // Writes 123
});</pre>
<p><code>ContinueWith</code> itself returns a <code>Task</code>, which is useful if you want to attach further continuations. However, you must deal directly with <code>AggregateException</code> if the task faults, and write extra code to marshal the continuation in UI applications (see <a data-type="xref" href="ch22.html#task_schedulers">“Task Schedulers”</a>). And in non-UI contexts, you must specify <code>TaskContinuationOptions.ExecuteSynchronously</code> if you want the continuation to execute on the same thread; otherwise it will bounce to the thread pool. <code>ContinueWith</code> is particularly useful in parallel programming scenarios; we cover it in detail in <a data-type="xref" href="ch22.html#parallel_programming-id00071">Chapter 22</a>.<a contenteditable="false" data-primary="" data-startref="ch14.html12" data-type="indexterm" id="id3718"/><a contenteditable="false" data-primary="" data-startref="ch14.html11" data-type="indexterm" id="id3719"/></p>
</div></section>
<section data-pdf-bookmark="TaskCompletionSource" data-type="sect2"><div class="sect2" id="taskcompletionsource">
<h2>TaskCompletionSource</h2>
<p><a contenteditable="false" data-primary="Task..." data-secondary="TaskCompletionSource" data-type="indexterm" id="ch14.html13"/><a contenteditable="false" data-primary="tasks" data-secondary="TaskCompletionSource" data-type="indexterm" id="ch14.html14"/>We’ve seen how <code>Task.Run</code> creates a task that runs a delegate on a pooled (or non-pooled) thread. Another way to create a task is with <code>TaskCompletionSource</code>.</p>
<p><code>TaskCompletionSource</code> lets you create a task out of any operation that completes in the future. It works by giving you a “slave” task that you manually drive—by indicating when the operation finishes or faults. This is ideal for I/O-bound work: you get all the benefits of tasks (with their ability to propagate return values, exceptions, and continuations) without blocking a thread for the duration of the operation.</p>
<p>To use <code>TaskCompletionSource</code>, you simply instantiate the class. It exposes a <code>Task</code> property that returns a task upon which you can wait and attach continuations—just as with any other task. The task, however, is controlled entirely by the <code>Task​Com⁠pletionSource</code> object via the following methods:</p>
<pre data-type="programlisting">public class TaskCompletionSource&lt;TResult&gt;
{
  public void SetResult (TResult result);
  public void SetException (Exception exception);
  public void SetCanceled();

  public bool TrySetResult (TResult result);
  public bool TrySetException (Exception exception);
  public bool TrySetCanceled();
  public bool TrySetCanceled (CancellationToken cancellationToken);
  ...
}</pre>
<p>Calling any of these methods <em>signals</em> the task, putting it into a completed, faulted, or canceled state (we cover the latter in the section <a data-type="xref" href="#cancellation">“Cancellation”</a>). You’re supposed to call one of these methods exactly once: if called again, <code>Set​Re⁠sult</code>, <code>SetException</code>, or <code>SetCanceled</code> will throw an exception, whereas the <code>Try*</code> methods return <code>false</code>.</p>
<p>The following example prints 42 after waiting for five seconds:</p>
<pre data-type="programlisting">var tcs = new TaskCompletionSource&lt;int&gt;();

new Thread (() =&gt; { Thread.Sleep (5000); tcs.SetResult (42); })
  { IsBackground = true }
  .Start();

Task&lt;int&gt; task = tcs.Task;         // Our "slave" task.
Console.WriteLine (task.Result);   // 42</pre>
<p>With <code>TaskCompletionSource</code>, we can write our own <code>Run</code> method:</p>
<pre data-type="programlisting">Task&lt;TResult&gt; Run&lt;TResult&gt; (Func&lt;TResult&gt; function)
{
  var tcs = new TaskCompletionSource&lt;TResult&gt;();
  new Thread (() =&gt; 
  {
    try { <strong>tcs.SetResult (function())</strong>; }
    catch (Exception ex) { <strong>tcs.SetException (ex);</strong> }
  }).Start();
  return tcs.Task;
}
...
Task&lt;int&gt; task = Run (() =&gt; { Thread.Sleep (5000); return 42; });</pre>
<p><a contenteditable="false" data-primary="Task..." data-secondary="Task.Factory.StartNew" data-type="indexterm" id="id3720"/><a contenteditable="false" data-primary="Task..." data-secondary="TaskCreationOptions.LongRunning" data-type="indexterm" id="id3721"/>Calling this method is equivalent to calling <code>Task.Factory.StartNew</code> with the <code>TaskCreationOptions.LongRunning</code> option to request a nonpooled thread.</p>
<p>The real power of <code>TaskCompletionSource</code> is in creating tasks that don’t tie up threads. For instance, consider a task that waits for five seconds and then returns the number 42. We can write this without a thread by using the <code>Timer</code> class, which, with the help of the CLR (and in turn, the OS), fires an event in <em>x</em> milliseconds (we revisit timers in <a data-type="xref" href="ch21.html#advanced_threadin">Chapter 21</a>):</p>
<pre data-type="programlisting">Task&lt;int&gt; GetAnswerToLife()
{
  var tcs = new TaskCompletionSource&lt;int&gt;();
  // Create a timer that fires once in 5000 ms:
  var timer = new System.Timers.Timer (5000) { AutoReset = false };
  timer.Elapsed += delegate { timer.Dispose(); tcs.SetResult (42); };
  timer.Start();
  return tcs.Task;
}</pre>
<p>Hence, our method returns a task that completes five seconds later, with a result of 42. By attaching a continuation to the task, we can write its result without blocking <em>any</em> thread:</p>
<pre data-type="programlisting">var awaiter = GetAnswerToLife().GetAwaiter();
awaiter.OnCompleted (() =&gt; Console.WriteLine (awaiter.GetResult()));</pre>
<p>We could make this more useful and turn it into a general-purpose <code>Delay</code> method by parameterizing the delay time and getting rid of the return value. This means having it return a <code>Task</code> instead of a <code>Task&lt;int&gt;</code>. However, there’s no nongeneric version of <code>TaskCompletionSource</code>, which means we can’t directly create a nongeneric <code>Task</code>. The workaround is simple: because <code>Task&lt;TResult&gt;</code> derives from <code>Task</code>, we create a <code>TaskCompletionSource&lt;<em>anything</em>&gt;</code> and then implicitly convert the <code>Task&lt;<em>anything</em>&gt;</code> that it gives you into a <code>Task</code>, like this:</p>
<pre data-type="programlisting">var tcs = new TaskCompletionSource&lt;object&gt;();
Task task = tcs.Task;</pre>
<p>Now we can write our general-purpose <code>Delay</code> method:</p>
<pre data-type="programlisting">Task Delay (int milliseconds)
{
  var tcs = new TaskCompletionSource&lt;object&gt;();
  var timer = new System.Timers.Timer (milliseconds) { AutoReset = false };
  timer.Elapsed += delegate { timer.Dispose(); <strong>tcs.SetResult (null)</strong>; };
  timer.Start();
  return tcs.Task;
}</pre>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>.NET 5 introduces a nongeneric <code>TaskCompletionSource</code>, so if you’re targeting .NET 5 or above, you can substitute <code>TaskCompletionSource&lt;object&gt;</code> for <code>TaskCompletionSource</code>.</p>
</div>
<p>Here’s how we can use it to write “42” after five seconds:</p>
<pre data-type="programlisting">Delay (5000).GetAwaiter().OnCompleted (() =&gt; Console.WriteLine (42));</pre>
<p>Our use of <code>TaskCompletionSource</code> without a thread means that a thread is engaged only when the continuation starts, five seconds later. We can demonstrate this by starting 10,000 of these operations at once without error or excessive resource <span class="keep-together">consumption</span>:</p>
<pre data-type="programlisting">for (int i = 0; i &lt; 10000; i++)
  Delay (5000).GetAwaiter().OnCompleted (() =&gt; Console.WriteLine (42));</pre>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>Timers fire their callbacks on pooled threads, so after five seconds, the thread pool will receive 10,000 requests to call <code>SetResult(null)</code> on a <code>TaskCompletionSource</code>. If the requests arrive faster than they can be processed, the thread pool will respond by enqueuing and then processing them at the optimum level of parallelism for the CPU. This is ideal if the thread-bound jobs are short running, which is true in this case: the thread-bound job is merely the call to <code>SetResult</code> plus either the action of posting the continuation to the synchronization context (in a UI application) or otherwise the continuation itself (<code>Console.WriteLine(42)</code>).<a contenteditable="false" data-primary="" data-startref="ch14.html14" data-type="indexterm" id="id3722"/><a contenteditable="false" data-primary="" data-startref="ch14.html13" data-type="indexterm" id="id3723"/></p>
</div>
</div></section>
<section data-pdf-bookmark="Task.Delay" data-type="sect2"><div class="sect2" id="taskdotdelay">
<h2>Task.Delay</h2>
<p><a contenteditable="false" data-primary="Task..." data-secondary="Task.Delay" data-type="indexterm" id="id3724"/>The <code>Delay</code> method that we just wrote is sufficiently useful that it’s available as a static method on the <code>Task</code> class:</p>
<pre data-type="programlisting"><strong>Task.Delay</strong> (5000).GetAwaiter().OnCompleted (() =&gt; Console.WriteLine (42));</pre>
<p>or:</p>
<pre data-type="programlisting"><strong>Task.Delay</strong> (5000).ContinueWith (ant =&gt; Console.WriteLine (42));</pre>
<p><code>Task.Delay</code> is the <em>asynchronous</em> equivalent of <code>Thread.Sleep</code>.<a contenteditable="false" data-primary="" data-startref="ch14.html9" data-type="indexterm" id="id3725"/><a contenteditable="false" data-primary="" data-startref="ch14.html8" data-type="indexterm" id="id3726"/></p>
</div></section>
</div></section>
<section data-pdf-bookmark="Principles of Asynchrony" data-type="sect1"><div class="sect1" id="principles_of_asynchrony">
<h1>Principles of Asynchrony</h1>
<p><a contenteditable="false" data-primary="asynchrony" data-type="indexterm" id="ch14.html15"/><a contenteditable="false" data-primary="asynchrony" data-secondary="principles of" data-type="indexterm" id="ch14.html16"/><a contenteditable="false" data-primary="concurrency and asynchrony" data-secondary="principles of asynchrony" data-type="indexterm" id="ch14.html17"/>In demonstrating <code>TaskCompletionSource</code>, we ended up writing <em>asynchronous</em> methods. In this section, we define exactly what asynchronous operations are and explain how this leads to asynchronous programming.</p>
<section data-pdf-bookmark="Synchronous Versus Asynchronous Operations" data-type="sect2"><div class="sect2" id="synchronous_versus_asynchronous_operati">
<h2>Synchronous Versus Asynchronous Operations</h2>
<p><a contenteditable="false" data-primary="asynchrony" data-secondary="synchronous versus asynchronous operations" data-type="indexterm" id="id3727"/>A <em>synchronous operation</em> does its work <em>before</em> returning to the caller.</p>
<p>An <em>asynchronous operation</em> can do (most or all of) its work <em>after</em> returning to the caller.</p>
<p>The majority of methods that you write and call are synchronous. An example is <code>List&lt;T&gt;.Add</code>, or <code>Console.WriteLine</code>, or <code>Thread.Sleep</code>. Asynchronous methods are less common and initiate <em>concurrency</em>, because work continues in parallel to the caller. Asynchronous methods typically return quickly (or immediately) to the caller; thus, they are also called <em>nonblocking methods</em>.</p>
<p>Most of the asynchronous methods that we’ve seen so far can be described as general-purpose methods:</p>
<ul>
<li><p><code>Thread.Start</code></p></li>
<li><p><code>Task.Run</code></p></li>
<li><p>Methods that attach continuations to tasks</p></li>
</ul>
<p>In addition, some of the methods that we discussed in <a data-type="xref" href="#synchronization_contexts">“Synchronization Contexts”</a> (<code>Dispatcher.BeginInvoke</code>, <code>Control.BeginInvoke</code>, and <code>SynchronizationContext.Post</code>) are asynchronous, as are the methods that we wrote in <a data-type="xref" href="#taskcompletionsource">“TaskCompletionSource”</a>, including <code>Delay</code>.</p>
</div></section>
<section data-pdf-bookmark="What Is Asynchronous Programming?" data-type="sect2"><div class="sect2" id="what_is_asynchronous_programmingquestio">
<h2>What Is Asynchronous Programming?</h2>
<p><a contenteditable="false" data-primary="asynchronous programming" data-secondary="principles" data-type="indexterm" id="id3728"/><a contenteditable="false" data-primary="asynchrony" data-secondary="asynchronous programming principles" data-type="indexterm" id="id3729"/>The principle of asynchronous programming is that you write long-running (or potentially long-running) functions asynchronously. This is in contrast to the conventional approach of writing long-running functions synchronously, and then calling those functions from a new thread or task to introduce concurrency as required.</p>
<p>The difference with the asynchronous approach is that concurrency is initiated <em>inside</em> the long-running function rather than from <em>outside</em> the function. This has two benefits:</p>
<ul>
<li><p>I/O-bound concurrency can be implemented without tying up threads (as we demonstrate in <a data-type="xref" href="#taskcompletionsource">“TaskCompletionSource”</a>), improving scalability and efficiency.</p></li>
<li><p>Rich-client applications end up with less code on worker threads, simplifying thread safety.</p></li>
</ul>
<p>This, in turn, leads to two distinct uses for asynchronous programming. The first is writing (typically server-side) applications that deal efficiently with a lot of concurrent I/O. The challenge here is not thread <em>safety</em> (because there’s usually minimal shared state) but thread <em>efficiency</em>; in particular, not consuming a thread per network request. So, in this context, it’s only I/O-bound operations that benefit from asynchrony.</p>
<p>The second use is to simplify thread-safety in rich-client applications. This is particularly relevant as a program grows in size, because to deal with complexity, we typically refactor larger methods into smaller ones, resulting in chains of methods that call one another (<em>call graphs</em>).</p>
<p><a contenteditable="false" data-primary="asynchronous call graph" data-type="indexterm" id="id3730"/><a contenteditable="false" data-primary="call graph" data-type="indexterm" id="id3731"/>With a traditional <em>synchronous</em> call graph, if any operation within the graph is long-running, we must run the entire call graph on a worker thread to maintain a responsive UI. Hence, we end up with a single concurrent operation that spans many methods (<em>coarse-grained concurrency</em>), and this requires considering thread-safety for every method in the graph.</p>
<p>With an <em>asynchronous</em> call graph, we need not start a thread until it’s actually needed, typically low in the graph (or not at all in the case of I/O-bound operations). All other methods can run entirely on the UI thread, with much-simplified thread safety. <a contenteditable="false" data-primary="fine-grained concurrency" data-type="indexterm" id="id3732"/>This results in <em>fine-grained concurrency</em>—a sequence of small concurrent operations, between which execution bounces to the UI thread.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>To benefit from this, both I/O- and compute-bound operations need to be written asynchronously; a good rule of thumb is to include anything that might take longer than 50 ms.</p>
<p>(On the flipside, <em>excessively</em> fine-grained asynchrony can hurt performance, because asynchronous operations incur an overhead—see <a data-type="xref" href="#optimizations">“Optimizations”</a>.)</p>
</div>
<p>In this chapter, we focus mostly on the rich-client scenario, which is the more complex of the two. In <a data-type="xref" href="ch16.html#networking-id00041">Chapter 16</a>, we give two examples that illustrate the I/O-bound scenario (see <a data-type="xref" href="ch16.html#concurrency_with_tcp">“Concurrency with TCP”</a> and <a data-type="xref" href="ch16.html#writing_an_http_server">“Writing an HTTP Server”</a>).</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>The UWP framework encourages asynchronous programming to the point where synchronous versions of some long-running methods are either not exposed or throw exceptions. Instead, you must call asynchronous methods that return tasks (or objects that can be converted into tasks via the <code>AsTask</code> extension method).</p>
</div>
</div></section>
<section data-pdf-bookmark="Asynchronous Programming and Continuations" data-type="sect2"><div class="sect2" id="asynchronous_programming_and_continuati">
<h2>Asynchronous Programming and Continuations</h2>
<p><a contenteditable="false" data-primary="asynchronous programming" data-secondary="continuations and" data-type="indexterm" id="id3733"/><a contenteditable="false" data-primary="continuations" data-secondary="asynchronous programming and" data-type="indexterm" id="id3734"/><a contenteditable="false" data-primary="tasks" data-secondary="asynchronous programming and" data-type="indexterm" id="id3735"/>Tasks are ideally suited to asynchronous programming, because they support continuations, which are essential for asynchrony (consider the <code>Delay</code> method that we wrote in <a data-type="xref" href="#taskcompletionsource">“TaskCompletionSource”</a>). In writing <code>Delay</code>, we used <code>TaskCompletionSource</code>, which is a standard way to implement “bottom-level” I/O-bound asynchronous methods.</p>
<p><a contenteditable="false" data-primary="Task..." data-secondary="Task.Run" data-type="indexterm" id="id3736"/>For compute-bound methods, we use <code>Task.Run</code> to initiate thread-bound concurrency. Simply by returning the task to the caller, we create an asynchronous method. What distinguishes asynchronous programming is that we aim to do so lower in the call graph so that in rich-client applications, higher-level methods can remain on the UI thread and access controls and shared state without thread-safety issues. To illustrate, consider the following method that computes and counts prime numbers, using all available cores (we discuss <code>ParallelEnumerable</code> in <a data-type="xref" href="ch22.html#parallel_programming-id00071">Chapter 22</a>):</p>
<pre data-type="programlisting">int GetPrimesCount (int start, int count)
{
  return
    ParallelEnumerable.Range (start, count).Count (n =&gt; 
      Enumerable.Range (2, (int)Math.Sqrt(n)-1).All (i =&gt; n % i &gt; 0));
}</pre>
<p>The details of how this works are unimportant; what matters is that it can take a while to run. We can demonstrate this by writing another method to call it:</p>
<pre data-type="programlisting">void DisplayPrimeCounts()
{
  for (int i = 0; i &lt; 10; i++)
    Console.WriteLine (GetPrimesCount (i*1000000 + 2, 1000000) +
      " primes between " + (i*1000000) + " and " + ((i+1)*1000000-1));
  Console.WriteLine ("Done!");
}</pre>
<p>Here’s the output:</p>
<pre data-type="programlisting">78498 primes between 0 and 999999
70435 primes between 1000000 and 1999999
67883 primes between 2000000 and 2999999
66330 primes between 3000000 and 3999999
65367 primes between 4000000 and 4999999
64336 primes between 5000000 and 5999999
63799 primes between 6000000 and 6999999
63129 primes between 7000000 and 7999999
62712 primes between 8000000 and 8999999
62090 primes between 9000000 and 9999999</pre>
<p><a contenteditable="false" data-primary="synchronous call graph" data-type="indexterm" id="id3737"/>Now we have a <em>call graph</em>, with <code>DisplayPrimeCounts</code> calling <code>GetPrimesCount</code>. The former uses <code>Console.WriteLine</code> for simplicity, although in reality it would more likely be updating UI controls in a rich-client application, as we demonstrate later. We can initiate coarse-grained concurrency for this call graph as follows:</p>
<pre data-type="programlisting">Task.Run (() =&gt; DisplayPrimeCounts());</pre>
<p>With a fine-grained asynchronous approach, we instead start by writing an asynchronous version of <code>GetPrimesCount</code>:</p>
<pre data-type="programlisting"><strong>Task&lt;int&gt;</strong> GetPrimesCount<strong>Async</strong> (int start, int count)
{
  return Task.Run (() =&gt;
    ParallelEnumerable.Range (start, count).Count (n =&gt; 
      Enumerable.Range (2, (int) Math.Sqrt(n)-1).All (i =&gt; n % i &gt; 0)));
}</pre>
</div></section>
<section data-pdf-bookmark="Why Language Support Is Important" data-type="sect2"><div class="sect2" id="why_language_support_is_important">
<h2>Why Language Support Is Important</h2>
<p><a contenteditable="false" data-primary="asynchrony" data-secondary="language support and" data-type="indexterm" id="ch14.html18"/>Now we must modify <code>DisplayPrimeCounts</code> so that it calls <code>GetPrimesCount<strong>Async</strong></code>. This is where C#’s <code>await</code> and <code>async</code> keywords come into play, because to do so otherwise is trickier than it sounds. If we simply modify the loop as follows:</p>
<pre data-type="programlisting">for (int i = 0; i &lt; 10; i++)
{
  var awaiter = GetPrimesCountAsync (i*1000000 + 2, 1000000).GetAwaiter();
  awaiter.OnCompleted (() =&gt;
    Console.WriteLine (awaiter.GetResult() + " primes between... "));
}
Console.WriteLine ("Done");</pre>
<p>the loop will rapidly spin through 10 iterations (the methods being nonblocking), and all 10 operations will execute in parallel (followed by a premature “Done”).</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>Executing these tasks in parallel is undesirable in this case because their internal implementations are already parallelized; it will only make us wait longer to see the first results (and muck up the ordering).</p>
<p>There is a much more common reason, however, for needing to <em>serialize</em> the execution of tasks, which is that Task B depends on the result of Task A. For example, in fetching a web page, a DNS lookup must precede the HTTP request.</p>
</div>
<p>To get them running sequentially, we must trigger the next loop iteration from the continuation itself. This means eliminating the <code>for</code> loop and resorting to a recursive call in the continuation:</p>
<pre data-type="programlisting">void DisplayPrimeCounts()
{
  DisplayPrimeCountsFrom (0);
}

void DisplayPrimeCountsFrom (int i)
{
  var awaiter = GetPrimesCountAsync (i*1000000 + 2, 1000000).GetAwaiter();
  awaiter.OnCompleted (() =&gt; 
  {
    Console.WriteLine (awaiter.GetResult() + " primes between...");
    if (++i &lt; 10) DisplayPrimeCountsFrom (i);
    else Console.WriteLine ("Done");
  });
}</pre>
<p>It gets even worse if we want to make <code>DisplayPrimesCount</code> <em>itself</em> asynchronous, returning a task that it signals upon completion. <a contenteditable="false" data-primary="Task..." data-secondary="TaskCompletionSource" data-type="indexterm" id="id3738"/>To accomplish this requires creating a <code>TaskCompletionSource</code>:</p>
<pre data-type="programlisting">Task DisplayPrimeCountsAsync()
{
  var machine = new PrimesStateMachine();
  machine.DisplayPrimeCountsFrom (0);
  return machine.Task;
}

class PrimesStateMachine
{
  <strong>TaskCompletionSource&lt;object&gt; _tcs = new TaskCompletionSource&lt;object&gt;();</strong>
  <strong>public Task Task { get { return _tcs.Task; } }</strong>

  public void DisplayPrimeCountsFrom (int i)
  {
    var awaiter = GetPrimesCountAsync (i*1000000+2, 1000000).GetAwaiter();
    awaiter.OnCompleted (() =&gt; 
    {
      Console.WriteLine (awaiter.GetResult());
      if (++i &lt; 10) DisplayPrimeCountsFrom (i);
      else { Console.WriteLine ("Done"); <strong>_tcs.SetResult (null); }</strong>
    });
  }
}</pre>
<p>Fortunately, C#’s <em>asynchronous functions</em> do all of this work for us. With the <code>async</code> and <code>await</code> keywords, we need only write this:</p>
<pre data-type="programlisting"><strong>async</strong> Task DisplayPrimeCountsAsync()
{
  for (int i = 0; i &lt; 10; i++)
    Console.WriteLine (<strong>await</strong> GetPrimesCountAsync (i*1000000 + 2, 1000000) +
      " primes between " + (i*1000000) + " and " + ((i+1)*1000000-1));
  Console.WriteLine ("Done!");
}</pre>
<p>Consequently, <code>async</code> and <code>await</code> are essential for implementing asynchrony without excessive complexity. Let’s now see how these keywords work.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>Another way of looking at the problem is that imperative looping constructs (<code>for</code>, <code>foreach</code>, and so on) do not mix well with continuations, because they rely on the <em>current local state</em> of the method (“How many more times is this loop going to run?”).</p>
<p>Although the <code>async</code> and <code>await</code> keywords offer one solution, it’s sometimes possible to solve it in another way by replacing the imperative looping constructs with the <em>functional</em> equivalent (in other words, LINQ queries). This is the basis of <em>Reactive Extensions</em> (Rx) and can be a good option when you want to execute query operators over the result—or combine multiple sequences. The price to pay is that to prevent blocking, Rx operates over <em>push</em>-based sequences, which can be conceptually tricky<a contenteditable="false" data-primary="" data-startref="ch14.html18" data-type="indexterm" id="id3739"/>.<a contenteditable="false" data-primary="" data-startref="ch14.html17" data-type="indexterm" id="id3740"/><a contenteditable="false" data-primary="" data-startref="ch14.html16" data-type="indexterm" id="id3741"/><a contenteditable="false" data-primary="" data-startref="ch14.html15" data-type="indexterm" id="id3742"/></p>
</div>
</div></section>
</div></section>
<section data-pdf-bookmark="Asynchronous Functions in C#" data-type="sect1"><div class="sect1" id="asynchronous_functions_in_chash">
<h1>Asynchronous Functions in C#</h1>
<p><a contenteditable="false" data-primary="asynchronous functions" data-type="indexterm" id="ch14.html19"/><a contenteditable="false" data-primary="asynchrony" data-secondary="asynchronous functions in C#" data-type="indexterm" id="ch14.html20"/>The <code>async</code> and <code>await</code> keywords let you write asynchronous code that has the same structure and simplicity as synchronous code while eliminating the “plumbing” of asynchronous programming.</p>
<section data-pdf-bookmark="Awaiting" data-type="sect2"><div class="sect2" id="awaiting">
<h2>Awaiting</h2>
<p><a contenteditable="false" data-primary="asynchronous functions" data-secondary="awaiting" data-type="indexterm" id="ch14.html21"/><a contenteditable="false" data-primary="await expressions" data-type="indexterm" id="ch14.html22"/>The <code>await</code> keyword simplifies the attaching of continuations. Starting with a basic scenario, the compiler expands this:</p>
<pre data-type="programlisting">var <em>result</em> = <strong>await</strong> <em>expression</em>;
<em>statement(s)</em>;</pre>
<p>into something functionally similar to this:</p>
<pre data-type="programlisting">var awaiter = <em>expression</em>.GetAwaiter();
awaiter.OnCompleted (() =&gt; 
{
  var <em>result</em> = awaiter.GetResult();
  <em>statement(s)</em>;
});</pre>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>The compiler also emits code to short-circuit the continuation in case of synchronous completion (see <a data-type="xref" href="#optimizations">“Optimizations”</a>) and to handle various nuances that we pick up in later sections.</p>
</div>
<p>To demonstrate, let’s revisit the asynchronous method that we wrote previously that computes and counts prime numbers:</p>
<pre data-type="programlisting"><strong>Task&lt;int&gt;</strong> GetPrimesCountAsync (int start, int count)
{
  return Task.Run (() =&gt;
    ParallelEnumerable.Range (start, count).Count (n =&gt; 
      Enumerable.Range (2, (int)Math.Sqrt(n)-1).All (i =&gt; n % i &gt; 0)));
}</pre>
<p>With the <code>await</code> keyword, we can call it as follows:</p>
<pre data-type="programlisting">int result = <strong>await</strong> GetPrimesCountAsync (2, 1000000);
Console.WriteLine (result);</pre>
<p>To compile, we need to add the <code>async</code> modifier to the containing method:</p>
<pre data-type="programlisting"><strong>async</strong> void DisplayPrimesCount()
{
  int result = <strong>await</strong> GetPrimesCountAsync (2, 1000000);
  Console.WriteLine (result);
}</pre>
<p>The <code>async</code> modifier instructs the compiler to treat <code>await</code> as a keyword rather than an identifier should an ambiguity arise within that method (this ensures that code written prior to C# 5 that might use <code>await</code> as an identifier will still compile without error). The <code>async</code> modifier can be applied only to methods (and lambda expressions) that return <code>void</code> or (as you’ll see later) a <code>Task</code> or <code>Task&lt;TResult&gt;</code>.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>The <code>async</code> modifier is similar to the <code>unsafe</code> modifier in that it has no effect on a method’s signature or public metadata; it affects only what happens <em>inside</em> the method. For this reason, it makes no sense to use <code>async</code> in an interface. However it is legal, for instance, to introduce <code>async</code> when overriding a non-<code>async</code> virtual method, as long as you keep the signature the same.</p>
</div>
<p><a contenteditable="false" data-primary="asynchronous functions" data-secondary="defined" data-type="indexterm" id="id3743"/>Methods with the <code>async</code> modifier are called <em>asynchronous functions</em>, because they themselves are typically asynchronous. To see why, let’s look at how execution proceeds through an asynchronous function.</p>
<p>Upon encountering an <code>await</code> expression, execution (normally) returns to the caller—rather like with <code>yield return</code> in an iterator. But before returning, the runtime attaches a continuation to the awaited task, ensuring that when the task completes, execution jumps back into the method and continues where it left off. If the task faults, its exception is rethrown, otherwise its return value is assigned to the <code>await</code> expression. We can summarize everything we just said by looking at the logical expansion of the asynchronous method we just examined:</p>
<pre data-type="programlisting">void DisplayPrimesCount()
{
  var awaiter = GetPrimesCountAsync (2, 1000000).GetAwaiter();
  awaiter.OnCompleted (() =&gt;    
  {
    int result = awaiter.GetResult();
    Console.WriteLine (result);
  });
}</pre>
<p>The expression upon which you <code>await</code> is typically a task; however, any object with a <code>GetAwaiter</code> method that returns an <em>awaiter</em> (implementing <code>INotifyCompletion.OnCompleted</code> and with an appropriately typed <code>GetResult</code> method and a <code>bool IsCompleted</code> property) will satisfy the compiler.</p>
<p>Notice that our <code>await</code> expression evaluates to an <code>int</code> type; this is because the expression that we awaited was a <code>Task&lt;int&gt;</code> (whose <code>GetAwaiter().GetResult()</code> method returns an <code>int</code>).</p> 
<p>Awaiting a nongeneric task is legal and generates a void expression:</p>
<pre data-type="programlisting">await Task.Delay (5000);
Console.WriteLine ("Five seconds passed!");</pre>
<section data-pdf-bookmark="Capturing local state" data-type="sect3"><div class="sect3" id="capturing_local_state">
<h3>Capturing local state</h3>
<p><a contenteditable="false" data-primary="await expressions" data-secondary="capturing local state" data-type="indexterm" id="id3744"/>The real power of <code>await</code> expressions is that they can appear almost anywhere in code. Specifically, an <code>await</code> expression can appear in place of any expression (within an asynchronous function) except for inside a <code>lock</code> statement or <code>unsafe</code> context.</p>
<p>In the following example, we <code>await</code> inside a loop:</p>
<pre data-type="programlisting">async void DisplayPrimeCounts()
{
  for (int i = 0; i &lt; 10; i++)
    Console.WriteLine (<strong>await</strong> GetPrimesCountAsync (i*1000000+2, 1000000));
}</pre>
<p>Upon first executing <code>GetPrimesCountAsync</code>, execution returns to the caller by virtue of the <code>await</code> expression. When the method completes (or faults), execution resumes where it left off, with the values of local variables and loop counters preserved.</p>
<p>Without the <code>await</code> keyword, the simplest equivalent might be the example we wrote in <a data-type="xref" href="#why_language_support_is_important">“Why Language Support Is Important”</a>. The compiler, however, takes the more general strategy of refactoring such methods into state machines (rather like it does with iterators).</p>
<p>The compiler relies on continuations (via the awaiter pattern) to resume execution after an <code>await</code> expression. This means that if running on the UI thread of a rich client application, the synchronization context ensures execution resumes on the same thread. Otherwise, execution resumes on whatever thread the task finished on. The change of thread does not affect the order of execution and is of little consequence unless you’re somehow relying on thread affinity, perhaps through the use of thread-local storage (see <a data-type="xref" href="ch21.html#thread_local_storage">“Thread-Local Storage”</a>). It’s like touring a city and hailing taxis to get from one destination to another. With a synchronization context, you’ll always get the same taxi; with no synchronization context, you’ll usually get a different taxi each time. In either case, though, the journey is the same.</p>
</div></section>
<section data-pdf-bookmark="Awaiting in a UI" data-type="sect3"><div class="sect3" id="awaiting_in_a_ui">
<h3>Awaiting in a UI</h3>
<p><a contenteditable="false" data-primary="await expressions" data-secondary="awaiting in a UI" data-type="indexterm" id="ch14.html23"/><a contenteditable="false" data-primary="UI (user interface)" data-secondary="awaiting in" data-type="indexterm" id="ch14.html24"/><a contenteditable="false" data-primary="user interface (UI)" data-secondary="awaiting in" data-type="indexterm" id="ch14.html25"/>We can demonstrate asynchronous functions in a more practical context by writing a simple UI that remains responsive while calling a compute-bound method. Let’s begin with a synchronous solution:</p>
<pre data-type="programlisting">class TestUI : Window
{
  Button _button = new Button { Content = "Go" };
  TextBlock _results = new TextBlock();
    
  public TestUI()
  {
    var panel = new StackPanel();
    panel.Children.Add (_button);
    panel.Children.Add (_results);
    Content = panel;
    _button.Click += (sender, args) =&gt; Go();
  }
    
  void Go()
  {
    for (int i = 1; i &lt; 5; i++)
      _results.Text += GetPrimesCount (i * 1000000, 1000000) +
        " primes between " + (i*1000000) + " and " + ((i+1)*1000000-1) +
        Environment.NewLine;
  }
    
  int GetPrimesCount (int start, int count)
  {
    return ParallelEnumerable.Range (start, count).Count (n =&gt; 
      Enumerable.Range (2, (int) Math.Sqrt(n)-1).All (i =&gt; n % i &gt; 0));
  }
}</pre>
<p>Upon pressing the “Go” button, the application becomes unresponsive for the time it takes to execute the compute-bound code. There are two steps in asynchronizing this; the first is to switch to the asynchronous version of <code>GetPrimesCount</code> that we used in previous examples:</p>
<pre class="pagebreak-before" data-type="programlisting"><strong>Task&lt;</strong>int<strong>&gt;</strong> GetPrimesCount<strong>Async</strong> (int start, int count)
{
  return <strong>Task.Run (() =&gt;</strong>
    ParallelEnumerable.Range (start, count).Count (n =&gt; 
      Enumerable.Range (2, (int) Math.Sqrt(n)-1).All (i =&gt; n % i &gt; 0))<strong>)</strong>;
}</pre>
<p>The second step is to modify <code>Go</code> to call <code>GetPrimesCountAsync</code>:</p>
<pre data-type="programlisting"><strong>async</strong> void Go()
{
  <strong>_button.IsEnabled = false;</strong>
  for (int i = 1; i &lt; 5; i++)
    _results.Text += <strong>await</strong> GetPrimesCount<strong>Async</strong> (i * 1000000, 1000000) +
      " primes between " + (i*1000000) + " and " + ((i+1)*1000000-1) +
      Environment.NewLine;
  <strong>_button.IsEnabled = true;</strong>
}</pre>
<p>This illustrates the simplicity of programming with asynchronous functions: you program as you would synchronously but call asynchronous functions instead of blocking functions and <code>await</code> them. Only the code within <code>GetPrimesCountAsync</code> runs on a worker thread; the code in <code>Go</code> “leases” time on the UI thread. We could say that <code>Go</code> executes <em>pseudo-concurrently</em> to the message loop (in that its execution is interspersed with other events that the UI thread processes). With this pseudo-concurrency, the only point at which preemption can occur is during an <code>await</code>. <a contenteditable="false" data-primary="reentrancy" data-type="indexterm" id="id3745"/>This simplifies thread safety: in our case, the only problem that this could cause is <em>reentrancy</em> (clicking the button again while it’s running, which we prevent by disabling the button). True concurrency occurs lower in the call stack, inside code called by <code>Task.Run</code>. To benefit from this model, truly concurrent code prevents accessing shared state or UI controls.</p>
<p>To give another example, suppose that instead of calculating prime numbers, we want to download several web pages and sum their lengths. .NET exposes numerous task-returning asynchronous methods, <a contenteditable="false" data-primary="System..." data-secondary="System.Net" data-type="indexterm" id="id3746"/>one of which is the <code>WebClient</code> class in <span class="keep-together"><code>System.Net</code></span>. <a contenteditable="false" data-primary="DownloadDataTaskAsync" data-type="indexterm" id="id3747"/>The <code>DownloadDataTaskAsync</code> method asynchronously downloads a URI to a byte array, returning a <code>Task&lt;byte[]&gt;</code>, so by awaiting it, we get a <code>byte[]</code>. Let’s now rewrite our <code>Go</code> method:</p>
<pre data-type="programlisting"><strong>async</strong> void Go() 
{
  _button.IsEnabled = false;
  string[] urls = "www.albahari.com www.oreilly.com www.linqpad.net".Split();
  int totalLength = 0;
  try
  {
    foreach (string url in urls)
    {
      var uri = new Uri ("http://" + url);
      byte[] data = <strong>await new WebClient().DownloadDataTaskAsync (uri);</strong>
      _results.Text += "Length of " + url + " is " + data.Length +
                       Environment.NewLine;
      totalLength += data.Length;
    }
    _results.Text += "Total length: " + totalLength;
  }
  catch (WebException ex)
  {
    _results.Text += "Error: " + ex.Message;
  }
  finally { _button.IsEnabled = true; }
}</pre>
<p>Again, this mirrors how we’d write it synchronously—including the use of <code>catch</code> and <code>finally</code> blocks. Even though execution returns to the caller after the first <code>await</code>, the <code>finally</code> block does not execute until the method has logically completed (by virtue of all its code executing—or an early <code>return</code> or unhandled exception).</p>
<p>It can be helpful to consider exactly what’s happening underneath. First, we need to revisit the pseudo-code that runs the message loop on the UI thread:</p>
<pre data-type="programlisting"><em>Set synchronization context for this thread to WPF sync context</em>
while (!<em>thisApplication.Ended</em>)
{
<em>  wait for something to appear in message queue</em>
<em>  Got something: what kind of message is it?</em>
<em>    Keyboard/mouse message -&gt; fire an event handler</em>
<em>    User <strong>BeginInvoke/Invoke</strong> message -&gt; execute delegate</em>
}</pre>
<p>Event handlers that we attach to UI elements execute via this message loop. When our <code>Go</code> method runs, execution proceeds as far as the <code>await</code> expression and then returns to the message loop (freeing the UI to respond to further events). However, the compiler’s expansion of <code>await</code> ensures that before returning, a continuation is set up such that execution resumes where it left off upon completion of the task. And because we awaited on a UI thread, the continuation posts to the synchronization context, which executes it via the message loop, keeping our entire <code>Go</code> method executing pseudo-concurrently on the UI thread. True (I/O-bound) concurrency occurs within the implementation of <code>DownloadDataTaskAsync</code>.<a contenteditable="false" data-primary="" data-startref="ch14.html25" data-type="indexterm" id="id3748"/><a contenteditable="false" data-primary="" data-startref="ch14.html24" data-type="indexterm" id="id3749"/><a contenteditable="false" data-primary="" data-startref="ch14.html23" data-type="indexterm" id="id3750"/></p>
</div></section>
<section data-pdf-bookmark="Comparison to coarse-grained concurrency" data-type="sect3"><div class="sect3" id="comparison_to_coarse_grained_concurrenc">
<h3>Comparison to coarse-grained concurrency</h3>
<p><a contenteditable="false" data-primary="asynchrony" data-secondary="coarse-grained concurrency versus" data-type="indexterm" id="id3751"/><a contenteditable="false" data-primary="coarse-grained concurrency" data-type="indexterm" id="id3752"/>Asynchronous programming was difficult prior to C# 5, not only because there was no language support, but because the .NET Framework exposed asynchronous functionality through clumsy patterns called the EAP and the APM (see <a data-type="xref" href="#obsolete_patterns">“Obsolete Patterns”</a>) rather than task-returning methods.</p>
<p>The popular workaround was coarse-grained concurrency (in fact, there was even a type called <code>BackgroundWorker</code> to help with that). Returning to our original <em>synchronous</em> example with <code>GetPrimesCount</code>, we can demonstrate coarse-grained asynchrony by modifying the button’s event handler, as follows:</p>
<pre data-type="programlisting">  ...
  _button.Click += (sender, args) =&gt;
  {
    _button.IsEnabled = false;
    Task.Run (() =&gt; Go());
  };</pre>
<p>(We’ve chosen to use <code>Task.Run</code> rather than <code>BackgroundWorker</code> because the latter would do nothing to simplify our particular example.) In either case, the end result is that our entire synchronous call graph (<code>Go</code> plus <code>GetPrimesCount</code>) runs on a worker thread. And because <code>Go</code> updates UI elements, we must now litter our code with <code>Dispatcher.BeginInvoke</code>:</p>
<pre data-type="programlisting">void Go()
{
  for (int i = 1; i &lt; 5; i++)
  {
    int result = GetPrimesCount (i * 1000000, 1000000);
    <strong>Dispatcher.BeginInvoke (new Action (() =&gt;</strong>
      _results.Text += result + " primes between " + (i*1000000) +
      " and " + ((i+1)*1000000-1) + Environment.NewLine));
  }
  <strong>Dispatcher.BeginInvoke (new Action (() =&gt;</strong> _button.IsEnabled = true<strong>));</strong>
}</pre>
<p>Unlike with the asynchronous version, the loop itself runs on a worker thread. This might seem innocuous, and yet, even in this simple case, our use of multithreading has introduced a race condition. (Can you spot it? If not, try running the program: it will almost certainly become apparent.)</p>
<p>Implementing cancellation and progress reporting creates more possibilities for thread-safety errors, as does any additional code in the method. For instance, suppose that the upper limit for the loop is not hardcoded but comes from a method call:</p> 
<pre data-type="programlisting">  for (int i = 1; i &lt; <strong>GetUpperBound()</strong>; i++)</pre>
<p>Now suppose that <code>GetUpperBound()</code> reads the value from a lazily loaded configuration file, which loads from disk upon first call. All of this code now runs on your worker thread, code that’s most likely not thread-safe. This is the danger of starting worker threads high in the call graph.<a contenteditable="false" data-primary="" data-startref="ch14.html22" data-type="indexterm" id="id3753"/><a contenteditable="false" data-primary="" data-startref="ch14.html21" data-type="indexterm" id="id3754"/></p>
</div></section>
</div></section>
<section data-pdf-bookmark="Writing Asynchronous Functions" data-type="sect2"><div class="sect2" id="writing_asynchronous_functions">
<h2>Writing Asynchronous Functions</h2>
<p><a contenteditable="false" data-primary="asynchronous functions" data-secondary="writing" data-type="indexterm" id="ch14.html26"/>With any asynchronous function, you can replace the <code>void</code> return type with a <code>Task</code> to make the method itself <em>usefully</em> asynchronous (and <code>await</code>able). No further changes are required:</p>
<pre data-type="programlisting">async <strong>Task</strong> PrintAnswerToLife()   // We can return Task instead of void
{
  await Task.Delay (5000);
  int answer = 21 * 2;
  Console.WriteLine (answer);  
}</pre>
<p>Notice that we don’t explicitly return a task in the method body. The compiler manufactures the task, which it signals upon completion of the method (or upon an unhandled exception). This makes it easy to create asynchronous call chains:</p>
<pre data-type="programlisting">async Task Go()
{
  await PrintAnswerToLife();
  Console.WriteLine ("Done");
}</pre>
<p>And because we’ve declared <code>Go</code> with a <code>Task</code> return type, <code>Go</code> itself is awaitable.</p>
<p><a contenteditable="false" data-primary="Task..." data-secondary="TaskCompletionSource" data-type="indexterm" id="id3755"/>The compiler expands asynchronous functions that return tasks into code that uses <code>TaskCompletionSource</code> to create a task that it then signals or faults.</p>
<p>Nuances aside, we can expand <code>PrintAnswerToLife</code> into the following functional equivalent:</p>
<pre data-type="programlisting">Task PrintAnswerToLife()
{
  <strong>var tcs = new TaskCompletionSource&lt;object&gt;();</strong>
  var awaiter = Task.Delay (5000).GetAwaiter();
  awaiter.OnCompleted (() =&gt;
  {
    try
    {
      awaiter.GetResult();    // Re-throw any exceptions
      int answer = 21 * 2;
      Console.WriteLine (answer);
      <strong>tcs.SetResult (null);</strong>
    }
    catch (Exception ex) { <strong>tcs.SetException (ex);</strong> }
  });
  <strong>return tcs.Task;</strong>
}</pre>
<p>Hence, whenever a task-returning asynchronous method finishes, execution jumps back to whatever awaited it (by virtue of a continuation).</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>In a rich-client scenario, execution bounces at this point back to the UI thread (if it’s not already on the UI thread). Otherwise, it continues on whatever thread the continuation came back on. This means that there’s no latency cost in bubbling up asynchronous call graphs, other than the first “bounce” if it was UI-thread-initiated.</p>
</div>
<section data-pdf-bookmark="Returning Task&lt;TResult&gt;" data-type="sect3"><div class="sect3" id="returning_taskless_thantresultgreater_t">
<h3>Returning Task&lt;TResult&gt;</h3>
<p><a contenteditable="false" data-primary="asynchronous functions" data-secondary="returning Task&lt;TResult&gt;" data-type="indexterm" id="id3756"/><a contenteditable="false" data-primary="Task..." data-secondary="Task&lt;TResult&gt;" data-type="indexterm" id="id3757"/>You can return a <code>Task&lt;TResult&gt;</code> if the method body returns <code>TResult</code>:</p>
<pre data-type="programlisting">async <strong>Task&lt;int&gt;</strong> GetAnswerToLife()
{
  await Task.Delay (5000);
  int answer = 21 * 2;
  return <strong>answer</strong>;    // Method has return type Task&lt;<strong>int</strong>&gt; we return <strong>int</strong>
}</pre>
<p>Internally, this results in the <code>TaskCompletionSource</code> being signaled with a value rather than null. We can demonstrate <code>GetAnswerToLife</code> by calling it from <code>PrintAnswerToLife</code> (which in turn, called from <code>Go</code>):</p>
<pre data-type="programlisting"><strong>async Task</strong> Go()
{
  <strong>await</strong> PrintAnswerToLife();
  Console.WriteLine ("Done");
}

<strong>async Task</strong> PrintAnswerToLife()
{
  int answer = <strong>await</strong> GetAnswerToLife();
  Console.WriteLine (answer);
}

<strong>async Task&lt;</strong>int<strong>&gt;</strong> GetAnswerToLife()
{
  <strong>await</strong> Task.Delay (5000);
  int answer = 21 * 2;
  return answer;
}</pre>
<p>In effect, we’ve refactored our original <code>PrintAnswerToLife</code> into two methods—with the same ease as if we were programming synchronously. The similarity to synchronous programming is intentional; here’s the synchronous equivalent of our call graph, for which calling <code>Go()</code> gives the same result after blocking for five seconds:</p>
<pre data-type="programlisting">void Go()
{
  PrintAnswerToLife();
  Console.WriteLine ("Done");
}

void PrintAnswerToLife()
{
  int answer = GetAnswerToLife();
  Console.WriteLine (answer);
}

int GetAnswerToLife()
{
  Thread.Sleep (5000);
  int answer = 21 * 2;
  return answer;
}</pre>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>This also illustrates the basic principle of how to design with asynchronous functions in C#:</p>
<ol>
<li><p>Write your methods synchronously.</p></li>
<li><p>Replace <em>synchronous</em> method calls with <em>asynchronous</em> method calls, and <code>await</code> them.</p></li>
<li><p>Except for “top-level” methods (typically event handlers for UI controls), upgrade your asynchronous methods’ return types to <code>Task</code> or <code>Task&lt;TResult&gt;</code> so that they’re awaitable.</p></li>
</ol>
</div>
<p><a contenteditable="false" data-primary="Task..." data-secondary="TaskCompletionSource" data-type="indexterm" id="id3758"/>The compiler’s ability to manufacture tasks for asynchronous functions means that for the most part, you need to explicitly instantiate a <code>TaskCompletionSource</code> only in (the relatively rare case of) bottom-level methods that initiate I/O-bound concurrency. (And for methods that initiate compute-bound concurrency, you create the task with <code>Task.Run</code>.)</p>
</div></section>
<section data-pdf-bookmark="Asynchronous call graph execution" data-type="sect3"><div class="sect3" id="asynchronous_call_graph_execution">
<h3>Asynchronous call graph execution</h3>
<p><a contenteditable="false" data-primary="asynchronous functions" data-secondary="asynchronous call graph execution" data-type="indexterm" id="id3759"/><a contenteditable="false" data-primary="call graph" data-type="indexterm" id="id3760"/>To see exactly how this executes, it’s helpful to rearrange our code as follows:</p>
<pre data-type="programlisting">async Task Go()
{
  <strong>var task = PrintAnswerToLife();</strong>
  await task; Console.WriteLine ("Done");
}

async Task PrintAnswerToLife()
{
  <strong>var task = GetAnswerToLife();</strong>
  int answer = await task; Console.WriteLine (answer);
}

async Task&lt;int&gt; GetAnswerToLife()
{
  <strong>var task = Task.Delay (5000);</strong>
  await task; int answer = 21 * 2; return answer;
}</pre>
<p><code>Go</code> calls <code>PrintAnswerToLife</code>, which calls <code>GetAnswerToLife</code>, which calls <code>Delay</code> and then awaits. The <code>await</code> causes execution to return to <code>PrintAnswerToLife</code>, which itself awaits, returning to <code>Go</code>, which also awaits and returns to the caller. All of this happens synchronously, on the thread that called <code>Go</code>; this is the brief <em>synchronous</em> phase of execution.</p>
<p>Five seconds later, the continuation on <code>Delay</code> fires, and execution returns to <code>Get​Ans⁠werToLife</code> on a pooled thread. (If we started on a UI thread, execution now bounces to that thread.) The remaining statements in <code>GetAnswerToLife</code> then run, after which the method’s <code>Task&lt;int&gt;</code> completes with a result of 42 and executes the <span class="keep-together">continuation</span> in <code>PrintAnswerToLife</code>, which executes the remaining statements in that method. The process continues until <code>Go</code>’s task is signaled as complete.</p>
<p>Execution flow matches the synchronous call graph that we showed earlier because we’re following a pattern whereby we <code>await</code> every asynchronous method immediately after calling it. This creates a sequential flow with no parallelism or overlapping execution within the call graph. Each <code>await</code> expression creates a “gap” in execution, after which the program resumes where it left off.</p>
</div></section>
<section data-pdf-bookmark="Parallelism" data-type="sect3"><div class="sect3" id="parallelism">
<h3>Parallelism</h3>
<p><a contenteditable="false" data-primary="asynchronous functions" data-secondary="parallelism" data-type="indexterm" id="id3761"/>Calling an asynchronous method without awaiting it allows the code that follows to execute in parallel. You might have noticed in earlier examples that we had a button whose event handler called <code>Go</code>, as follows:</p>
<pre data-type="programlisting">_button.Click += (sender, args) =&gt; Go();</pre>
<p>Despite <code>Go</code> being an asynchronous method, we didn’t await it, and this is indeed what facilitates the concurrency needed to maintain a responsive UI.</p>
<p>We can use this same principle to run two asynchronous operations in parallel:</p>
<pre data-type="programlisting">var task1 = PrintAnswerToLife();
var task2 = PrintAnswerToLife();
await task1; await task2;</pre>
<p>(By awaiting both operations afterward, we “end” the parallelism at that point. Later, we describe how the <code>WhenAll</code> task combinator helps with this pattern.)</p>
<p>Concurrency created in this manner occurs whether or not the operations are initiated on a UI thread, although there’s a difference in how it occurs. In both cases, we get the same “true” concurrency occurring in the bottom-level operations that initiate it (such as <code>Task.Delay</code> or code farmed to <code>Task.Run</code>). Methods above this in the call stack will be subject to true concurrency only if the operation was initiated without a synchronization context present; otherwise they will be subject to the pseudo-concurrency (and simplified thread safety) that we talked about earlier, whereby the only place at which we can be preempted is an <code>await</code> statement. This lets us, for instance, define a shared field, <code>_x</code>, and increment it in <code>GetAnswerToLife</code> without locking:</p>
<pre data-type="programlisting">async Task&lt;int&gt; GetAnswerToLife()
{
  <strong>_x++;</strong>
  await Task.Delay (5000);
  return 21 * 2;
}</pre>
<p>(We would, though, be unable to assume that <code>_x</code> had the same value before and after the <code>await</code>.)<a contenteditable="false" data-primary="" data-startref="ch14.html26" data-type="indexterm" id="id3762"/></p>
</div></section>
</div></section>
<section data-pdf-bookmark="Asynchronous Lambda Expressions" data-type="sect2"><div class="sect2" id="asynchronous_lambda_expressions">
<h2>Asynchronous Lambda Expressions</h2>
<p><a contenteditable="false" data-primary="asynchronous functions" data-secondary="asynchronous lambda expressions" data-type="indexterm" id="id3763"/><a contenteditable="false" data-primary="asynchronous lambda expressions" data-type="indexterm" id="id3764"/><a contenteditable="false" data-primary="asynchrony" data-secondary="asynchronous lambda expressions" data-type="indexterm" id="id3765"/><a contenteditable="false" data-primary="lambda expressions" data-secondary="asynchronous" data-type="indexterm" id="id3766"/>Just as ordinary <em>named</em> methods can be asynchronous:</p>
<pre data-type="programlisting"><strong>async Task</strong> NamedMethod()
{
  await Task.Delay (1000);
  Console.WriteLine ("Foo");
}</pre>
<p><a contenteditable="false" data-primary="unnamed methods" data-type="indexterm" id="id3767"/>so can <em>unnamed</em> methods (lambda expressions and anonymous methods), if preceded by the <code>async</code> keyword:</p>
<pre data-type="programlisting">Func&lt;<strong>Task</strong>&gt; unnamed = <strong>async</strong> () =&gt;
{
  await Task.Delay (1000);
  Console.WriteLine ("Foo");
};</pre>
<p>We can call and await these in the same way:</p>
<pre data-type="programlisting">await NamedMethod();
await unnamed();</pre>
<p>We can use asynchronous lambda expressions when attaching event handlers:</p>
<pre data-type="programlisting">myButton.Click += <strong>async</strong> (sender, args) =&gt;
{
  await Task.Delay (1000);
  myButton.Content = "Done";
};</pre>
<p>This is more succinct than the following, which has the same effect:</p>
<pre data-type="programlisting">myButton.Click += ButtonHandler;
...
<strong>async</strong> void ButtonHandler (object sender, EventArgs args)
{
  await Task.Delay (1000);
  myButton.Content = "Done";
};</pre>
<p>Asynchronous lambda expressions can also return <code>Task&lt;TResult&gt;</code>:</p>
<pre data-type="programlisting">Func&lt;<strong>Task&lt;int&gt;</strong>&gt; unnamed = async () =&gt;
{
  await Task.Delay (1000);
  return 123;
};
int answer = await unnamed();</pre>
</div></section>
<section data-pdf-bookmark="Asynchronous Streams" data-type="sect2"><div class="sect2" id="asynchronous_stream">
<h2>Asynchronous Streams</h2>
<p><a contenteditable="false" data-primary="asynchronous functions" data-secondary="asynchronous streams" data-type="indexterm" id="ch14.html27"/><a contenteditable="false" data-primary="asynchronous streams" data-type="indexterm" id="ch14.html28"/><a contenteditable="false" data-primary="C# 8" data-primary-sortas="C# 08" data-secondary="asynchronous streams" data-type="indexterm" id="ch14.html29"/>With <code>yield return</code>, you can write an iterator; with <code>await</code>, you can write an asynchronous function. <em>Asynchronous streams</em> (from C# 8) combine these concepts and let you write an iterator that awaits, yielding elements asynchronously. This support builds on the following pair of interfaces, which are asynchronous counterparts to the enumeration interfaces we described in <a data-type="xref" href="ch04.html#enumeration_and_iterators">“Enumeration and Iterators”</a>:</p>
<pre data-type="programlisting">public interface IAsyncEnumerable&lt;out T&gt;
{
  IAsyncEnumerator&lt;T&gt; GetAsyncEnumerator (...);
}

public interface IAsyncEnumerator&lt;out T&gt;: IAsyncDisposable
{
  T Current { get; }
  ValueTask&lt;bool&gt; MoveNextAsync();
}</pre>
<p><code>ValueTask&lt;T&gt;</code> is a struct that wraps <code>Task&lt;T&gt;</code> and is behaviorally similar to <code>Task&lt;T&gt;</code> while enabling more efficient execution when the task completes synchronously (which can happen often when enumerating a sequence). See <a data-type="xref" href="#valuetaskless_thantgreater_than">“ValueTask&lt;T&gt;”</a> for a discussion of differences. <a contenteditable="false" data-primary="IAsyncDisposable" data-type="indexterm" id="id3768"/><code>IAsyncDisposable</code> is an asynchronous version of <code>IDisposable</code>; it provides an opportunity to perform cleanup should you choose to manually implement the interfaces:</p>
<pre data-type="programlisting">public interface IAsyncDisposable
{
  ValueTask DisposeAsync();
}</pre>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>The act of fetching each element from the sequence (<code>MoveNextAsync</code>) is an asynchronous operation, so asynchronous streams are suitable when elements arrive in a piecemeal fashion (such as when processing data from a video stream). In contrast, the following type is more suitable when the sequence <em>as a whole</em> is delayed, but the elements, when they arrive, arrive all together:</p>
<pre data-type="programlisting">Task&lt;IEnumerable&lt;T&gt;&gt;</pre>
</div>
<p>To generate an asynchronous stream, you write a method that combines the principles of iterators and asynchronous methods. In other words, your method should include both <code>yield return</code> and <code>await</code>, <a contenteditable="false" data-primary="IAsyncEnumerable&lt;T&gt;" data-type="indexterm" id="id3769"/>and it should return <code>IAsyncEnumerable&lt;T&gt;</code>:</p>
<pre data-type="programlisting">async <strong>IAsyncEnumerable&lt;int&gt;</strong> RangeAsync (
  int start, int count, int delay)
{
  for (int i = start; i &lt; start + count; i++)
  {
    <strong>await</strong> Task.Delay (delay);
    <strong>yield return</strong> i;
  }
}</pre>
<p>To consume an asynchronous stream, use the <code>await foreach</code> statement:</p>
<pre data-type="programlisting"><strong>await foreach</strong> (var number in RangeAsync (0, 10, 500))
  Console.WriteLine (number);</pre>
<p>Note that data arrives steadily, every 500 milliseconds (or, in real life, as it becomes available). Contrast this to a similar construct using <code>Task&lt;IEnumerable&lt;T&gt;&gt;</code> for which no data is returned until the last piece of data is available:</p>
<pre data-type="programlisting">static async Task&lt;IEnumerable&lt;int&gt;&gt; RangeTaskAsync (int start, int count,
                                                    int delay)
{
  List&lt;int&gt; data = new List&lt;int&gt;();
  for (int i = start; i &lt; start + count; i++)
  {
    await Task.Delay (delay);
    data.Add (i);
  }

  return data;
}</pre>
<p>Here’s how to consume it with the <code>foreach</code> statement:</p>
<pre data-type="programlisting">foreach (var data in await RangeTaskAsync(0, 10, 500))
  Console.WriteLine (data);</pre>
<section data-pdf-bookmark="Querying IAsyncEnumerable&lt;T&gt;" data-type="sect3"><div class="sect3" id="querying_iasyncenumerableless_thantgrea">
<h3>Querying IAsyncEnumerable&lt;T&gt;</h3>
<p><a contenteditable="false" data-primary="asynchronous streams" data-secondary="querying IAsyncEnumerable&lt;T&gt;" data-type="indexterm" id="id3770"/><a contenteditable="false" data-primary="IAsyncEnumerable&lt;T&gt;" data-secondary="querying" data-type="indexterm" id="id3771"/>The <em>System.Linq.Async</em> NuGet package defines LINQ query operators that operate over <code>IAsyncEnumerable&lt;T&gt;</code>, allowing you to write queries much as you would with <code>IEnumerable&lt;T&gt;</code>.</p>
<p>For instance, we can write a LINQ query over the <code>RangeAsync</code> method that we defined in the preceding section, as follows:</p>
<pre data-type="programlisting">IAsyncEnumerable&lt;int&gt; query =
  from i in RangeAsync (0, 10, 500)
  where i % 2 == 0   // Even numbers only.
  select i * 10;     // Multiply by 10.

await foreach (var number in query)
  Console.WriteLine (number);</pre>
<p>This outputs 0, 20, 40, and so on.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>If you’re familiar with Rx, you can benefit from its (more powerful) query operators, too, by calling the <code>ToObservable</code> extension method, which converts an <code>IAsyncEnumerable&lt;T&gt;</code> into an <code>IObservable&lt;T&gt;</code>. A <code>ToAsyncEnumerable</code> extension method is also available, to convert in the reverse direction.</p>
</div>
</div></section>
<section data-pdf-bookmark="IAsyncEnumerable&lt;T&gt; in ASP.Net Core" data-type="sect3"><div class="sect3" id="iasyncenumerableless_thantgreater_than">
<h3>IAsyncEnumerable&lt;T&gt; in ASP.Net Core</h3>
<p><a contenteditable="false" data-primary="asynchronous streams" data-secondary="IAsyncEnumerable&lt;T&gt; in ASP.Net Core" data-type="indexterm" id="id3772"/><a contenteditable="false" data-primary="IAsyncEnumerable&lt;T&gt;" data-secondary="in ASP.Net Core" data-type="indexterm" id="id3773"/>ASP.Net Core controller actions can now return <code>IAsyncEnumerable&lt;T&gt;</code>. Such methods must be marked async. For example:<a contenteditable="false" data-primary="" data-startref="ch14.html29" data-type="indexterm" id="id3774"/><a contenteditable="false" data-primary="" data-startref="ch14.html28" data-type="indexterm" id="id3775"/><a contenteditable="false" data-primary="" data-startref="ch14.html27" data-type="indexterm" id="id3776"/></p>
<pre data-type="programlisting">[HttpGet]
public async IAsyncEnumerable&lt;string&gt; Get()
{
    using var dbContext = new BookContext();
    await foreach (var title in dbContext.Books
                                         .Select(b =&gt; b.Title)
                                         .AsAsyncEnumerable())
       yield return title;
}</pre>
</div></section>
</div></section>
<section data-pdf-bookmark="Asynchronous Methods in WinRT" data-type="sect2"><div class="sect2" id="asynchronous_methods_in_winrt">
<h2>Asynchronous Methods in WinRT</h2>
<p><a contenteditable="false" data-primary="asynchronous functions" data-secondary="asynchronous methods in WinRT" data-type="indexterm" id="id3777"/><a contenteditable="false" data-primary="Windows Runtime (WinRT)" data-secondary="asynchronous methods in" data-type="indexterm" id="id3778"/>If you’re developing UWP applications, you will need to work with the WinRT types defined in the operating system. WinRT’s equivalent of <code>Task</code> is <code>IAsyncAction</code>, and the equivalent of <code>Task&lt;TResult&gt;</code> is <code>IAsyncOperation&lt;TResult&gt;</code>. And for operations that report progress, the equivalents are <code>IAsyncActionWithProgress&lt;TProgress&gt;</code> and <code>IAsyncOperationWithProgress&lt;TResult, TProgress&gt;</code>. They are all defined in the <code>Windows.Foundation</code> namespace.</p>
<p>You can convert from either into a <code>Task</code> or <code>Task&lt;TResult&gt;</code> via the <code>AsTask</code> extension method:</p>
<pre data-type="programlisting">Task&lt;StorageFile&gt; fileTask = KnownFolders.DocumentsLibrary.CreateFileAsync
                             ("test.txt").<strong>AsTask()</strong>;</pre>
<p>Or you can await them directly:</p>
<pre data-type="programlisting">StorageFile file = <strong>await</strong> KnownFolders.DocumentsLibrary.CreateFileAsync
                         ("test.txt");</pre>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>Due to limitations in the COM type system, <code>IAsyncActionWithProgress&lt;TProgress&gt;</code> and <code>IAsyncOperationWithProgress&lt;TResult, TProgress&gt;</code> are not based on <code>IAsyncAction</code> as you might expect. Instead, both inherit from a common base type called <code>IAsyncInfo</code>.</p>
</div>
<p>The <code>AsTask</code> method is also overloaded to accept a cancellation token (see <a data-type="xref" href="#cancellation">“Cancellation”</a>). It can also accept an <code>IProgress&lt;T&gt;</code> object when chained to the <code>WithProgress</code> variants (see <a data-type="xref" href="#progress_reporting">“Progress Reporting”</a>).</p>
</div></section>
<section data-pdf-bookmark="Asynchrony and Synchronization Contexts" data-type="sect2"><div class="sect2" id="asynchrony_and_synchronization_contexts">
<h2>Asynchrony and Synchronization Contexts</h2>
<p><a contenteditable="false" data-primary="asynchronous functions" data-secondary="asynchrony and synchronization contexts" data-type="indexterm" id="id3779"/>We’ve already seen how the presence of a synchronization context is significant in terms of posting continuations. There are a couple of other more subtle ways in which such synchronization contexts come into play with void-returning asynchronous functions. These are not a direct result of C# compiler expansions, but a <span class="keep-together">function</span> of the <code>Async*MethodBuilder</code> types in the <code>System.CompilerServices</code> namespace that the compiler uses in expanding asynchronous functions.</p>
<section data-pdf-bookmark="Exception posting" data-type="sect3"><div class="sect3" id="exception_posting">
<h3>Exception posting</h3>
<p><a contenteditable="false" data-primary="Application.DispatcherUnhandledException" data-type="indexterm" id="id3780"/><a contenteditable="false" data-primary="exception posting" data-type="indexterm" id="id3781"/>It’s common practice in rich-client applications to rely on the central exception handling event (<code>Application.DispatcherUnhandledException</code> in WPF) to process unhandled exceptions thrown on the UI thread. And in ASP.NET Core <span class="keep-together">applications</span>, a custom <code>ExceptionFilterAttribute</code> in the <code>ConfigureServices</code> method of <em>Startup.cs</em> does a similar job. Internally, they work by invoking UI events (or in ASP.NET Core, the pipeline of page-processing methods) in their own <code>try</code>/<code>catch</code> block.</p>
<p>Top-level asynchronous functions complicate this. Consider the following event handler for a button click:</p>
<pre data-type="programlisting"><strong>async</strong> void ButtonClick (object sender, RoutedEventArgs args)
{
  await Task.Delay(1000);
  throw new Exception ("Will this be ignored?");
}</pre>
<p>When the button is clicked and the event handler runs, execution returns normally to the message loop after the <code>await</code> statement, and the exception that’s thrown a second later cannot be caught by the <code>catch</code> block in the message loop.</p>
<p>To mitigate this problem, <code>AsyncVoidMethodBuilder</code> catches unhandled exceptions (in void-returning asynchronous functions) and posts them to the synchronization context if present, ensuring that global exception-handling events still fire.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>The compiler applies this logic only to <em>void</em>-returning asynchronous functions. So, if we changed <code>ButtonClick</code> to return a <code>Task</code> instead of <code>void</code>, the unhandled exception would fault the resultant <code>Task</code>, which would then have nowhere to go (resulting in an <em>unobserved</em> exception).</p>
</div>
<p>An interesting nuance is that it makes no difference whether you throw before or after an <code>await</code>. Thus, in the following example, the exception is posted to the synchronization context (if present) and never to the caller:</p>
<pre data-type="programlisting">async void Foo() { <strong>throw null</strong>; await Task.Delay(1000); }</pre>
<p>(If no synchronization context is present, the exception will propagate on the thread pool, which will terminate the application.)</p>
<p>The reason for the exception not being thrown directly back to the caller is to ensure predictability and consistency. In the following example, the <code>InvalidOperationException</code> will always have the same effect of faulting the resultant <code>Task</code>—regardless of <code><em>someCondition</em></code>:</p>
<pre data-type="programlisting">async Task Foo()
{
  if (<em>someCondition</em>) await Task.Delay (100);
  throw new InvalidOperationException();
}</pre>
<p>Iterators work in a similar way:</p>
<pre data-type="programlisting">IEnumerable&lt;int&gt; Foo() { <strong>throw null</strong>; yield return 123; }</pre>
<p>In this example, an exception is never thrown straight back to the caller: not until the sequence is enumerated is the exception thrown.</p>
</div></section>
<section data-pdf-bookmark="OperationStarted and OperationCompleted" data-type="sect3"><div class="sect3" id="operationstarted_and_operationcompleted">
<h3>OperationStarted and OperationCompleted</h3>
<p><a contenteditable="false" data-primary="OperationCompleted method" data-type="indexterm" id="id3782"/><a contenteditable="false" data-primary="OperationStarted method" data-type="indexterm" id="id3783"/>If a synchronization context is present, void-returning asynchronous functions also call its <code>OperationStarted</code> method upon entering the function, and its <code>OperationCompleted</code> method when the function finishes.</p>
<p>Overriding these methods is useful if writing a custom synchronization context for unit testing void-returning asynchronous methods. This is discussed on <a href="https://oreil.ly/Aol-f">Microsoft’s Parallel Programming blog</a>.</p>
</div></section>
</div></section>
<section data-pdf-bookmark="Optimizations" data-type="sect2"><div class="sect2" id="optimizations">
<h2>Optimizations</h2>
<section data-pdf-bookmark="Completing synchronously" data-type="sect3"><div class="sect3" id="completing_synchronously">
<h3>Completing synchronously</h3>
<p><a contenteditable="false" data-primary="asynchronous functions" data-secondary="synchronous completion" data-type="indexterm" id="ch14.html30"/><a contenteditable="false" data-primary="synchronous completion" data-type="indexterm" id="ch14.html31"/>An <a contenteditable="false" data-primary="asynchronous functions" data-secondary="optimizations" data-type="indexterm" id="ch14.html32"/>asynchronous function can return <em>before</em> awaiting. Consider the following method that caches the downloading of web pages:</p>
<pre data-type="programlisting">static Dictionary&lt;string,string&gt; _cache = new Dictionary&lt;string,string&gt;();

async Task&lt;string&gt; GetWebPageAsync (string uri)
{
  string html;
  if (_cache.TryGetValue (uri, out html)) <strong>return html</strong>;
  return _cache [uri] = 
    <strong>await</strong> new WebClient().DownloadStringTaskAsync (uri);
}</pre>
<p>Should a URI already exist in the cache, execution returns to the caller with no awaiting having occurred, and the method returns an <em>already-signaled</em> task. This is referred to as <em>synchronous completion</em>.</p>
<p>When you await a synchronously completed task, execution does not return to the caller and bounce back via a continuation; instead, it proceeds immediately to the next statement. The compiler implements this optimization by checking the <code>IsCompleted</code> property on the awaiter; in other words, whenever you await</p>
<pre data-type="programlisting">Console.WriteLine (await GetWebPageAsync ("http://oreilly.com"));</pre>
<p>the compiler emits code to short-circuit the continuation in case of synchronization completion:</p>
<pre data-type="programlisting">var awaiter = GetWebPageAsync().GetAwaiter();
<strong>if (awaiter.IsCompleted)</strong>
  <strong>Console.WriteLine (awaiter.GetResult());</strong>
else
  awaiter.OnCompleted (() =&gt; Console.WriteLine (awaiter.GetResult());</pre>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>Awaiting an asynchronous function that returns synchronously still incurs a (very) small overhead—maybe 20 nanoseconds on a 2019-era PC.</p>
<p>In contrast, bouncing to the thread pool introduces the cost of a context switch—perhaps one or two microseconds—and bouncing to a UI message loop, at least 10 times that (much longer if the UI thread is busy).</p>
</div>
<p>It’s even legal to write asynchronous methods that <em>never</em> await, although the compiler will generate a warning:</p>
<pre data-type="programlisting">async Task&lt;string&gt; Foo() { return "abc"; }</pre>
<p>Such methods can be useful when overriding virtual/abstract methods, if your implementation doesn’t happen to need asynchrony. (An example is <code>MemoryStream</code>’s <code>ReadAsync</code>/<code>WriteAsync</code> methods; see <a data-type="xref" href="ch15.html#streams_and_isoliduso">Chapter 15</a>.) Another way to achieve the same result is to use <code>Task.FromResult</code>, which returns an already-signaled task:</p>
<pre data-type="programlisting">Task&lt;string&gt; Foo() { return <strong>Task.FromResult ("abc")</strong>; }</pre>
<p>Our <code>GetWebPageAsync</code> method is implicitly thread safe if called from a UI thread, in that you could invoke it several times in succession (thereby initiating multiple concurrent downloads), and no locking is required to protect the cache. If the series of calls were to the same URI, though, we’d end up initiating multiple redundant downloads, all of which would eventually update the same cache entry (the last one winning). Although not erroneous, it would be more efficient if subsequent calls to the same URI could instead (asynchronously) wait upon the result of the in-progress request.</p>
<p>There’s an easy way to accomplish this—without resorting to locks or signaling constructs. Instead of a cache of strings, we create a cache of “futures” (<code>Task&lt;string&gt;</code>):</p>
<pre data-type="programlisting">static Dictionary&lt;string,Task&lt;string&gt;&gt; _cache = 
   new Dictionary&lt;string,Task&lt;string&gt;&gt;();

Task&lt;string&gt; GetWebPageAsync (string uri)
{
  if (_cache.TryGetValue (uri, out var downloadTask)) return downloadTask;
  return _cache [uri] = new WebClient().DownloadStringTaskAsync (uri);
}</pre>
<p>(Notice that we don’t mark the method as <code>async</code>, because we’re directly returning the task we obtain from calling <code>WebClient</code>’s method.)</p>
<p>If we call <code>GetWebPageAsync</code> repeatedly with the same URI, we’re now guaranteed to get the same <code>Task&lt;string&gt;</code> object back. (This has the additional benefit of minimizing garbage collection load.) And if the task is complete, awaiting it is cheap, thanks to the compiler optimization that we just discussed.</p>
<p>We could further extend our example to make it thread-safe without the protection of a synchronization context, by locking around the entire method body:</p>
<pre data-type="programlisting">lock (_cache)
  if (_cache.TryGetValue (uri, out var downloadTask))
    return downloadTask;
  else
    return _cache [uri] = new WebClient().DownloadStringTaskAsync (uri);
}</pre>
<p>This works because we’re not locking for the duration of downloading a page (which would hurt concurrency); we’re locking for the small duration of checking the cache, starting a new task if necessary, and updating the cache with that task.<a contenteditable="false" data-primary="" data-startref="ch14.html32" data-type="indexterm" id="id3784"/><a contenteditable="false" data-primary="" data-startref="ch14.html31" data-type="indexterm" id="id3785"/></p>
</div></section>
<section data-pdf-bookmark="ValueTask&lt;T&gt;" data-type="sect3"><div class="sect3" id="valuetaskless_thantgreater_than">
<h3>ValueTask&lt;T&gt;</h3>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p><a contenteditable="false" data-primary="ValueTask&lt;T&gt;" data-type="indexterm" id="id3786"/><code>ValueTask&lt;T&gt;</code> is intended for micro-optimization scenarios, and you might never need to write methods that return this type. However, it still pays to be aware of the precautions that we outline in the next section because some .NET methods return <code>ValueTask&lt;T&gt;</code>, and <code>IAsyncEnumerable&lt;T&gt;</code> makes use of it, too.</p>
</div>
<p>We just described how the compiler optimizes an <code>await</code> expression on a synchronously completed task—by short-circuiting the continuation and proceeding immediately to the next statement. If the synchronous completion is due to caching, we saw that caching the task itself can provide an elegant and efficient solution.</p>
<p>It’s not practical, however, to cache the task in all synchronous completion scenarios. Sometimes, a fresh task must be instantiated, and this creates a (tiny) potential inefficiency. <a contenteditable="false" data-primary="Task..." data-secondary="Task&lt;T&gt;" data-type="indexterm" id="id3787"/>This is because <code>Task</code> and <code>Task&lt;T&gt;</code> are reference types, and so instantiation requires a heap-based memory allocation and subsequent collection. An extreme form of optimization is to write code that’s allocation-free; in other words, that does not instantiate any reference types, adding no burden to garbage collection. To support this pattern, the <code>ValueTask</code> and <code>ValueTask&lt;T&gt;</code> structs have been introduced, which the compiler allows in place of <code>Task</code> and <code>Task&lt;T&gt;</code>:</p>
<pre data-type="programlisting">async <strong>ValueTask</strong>&lt;int&gt; Foo() { ... }</pre>
<p>Awaiting <code>ValueTask&lt;T&gt;</code> is allocation-free, <em>if the operation completes synchronously</em>:</p>
<pre data-type="programlisting">int answer = await Foo();   // (Potentially) allocation-free</pre>
<p>If the operation doesn’t complete synchronously, <code>ValueTask&lt;T&gt;</code> creates an ordinary <code>Task&lt;T&gt;</code> behind the scenes (to which it forwards the await), and nothing is gained.</p>
<p>You can convert a <code>ValueTask&lt;T&gt;</code> into an ordinary <code>Task&lt;T&gt;</code> by calling the <code>AsTask</code> method.</p>
<p>There’s also a nongeneric version—<code>ValueTask</code>—which is akin to <code>Task</code>.</p>
</div></section>
<section data-pdf-bookmark="Precautions when using ValueTask&lt;T&gt;" data-type="sect3"><div class="sect3" id="precautions_when_using_valuetypeless_th">
<h3>Precautions when using ValueTask&lt;T&gt;</h3>
<p><a contenteditable="false" data-primary="asynchronous functions" data-secondary="precautions when using ValueTask&lt;T&gt;" data-type="indexterm" id="id3788"/><a contenteditable="false" data-primary="asynchronous functions" data-secondary="ValueTask&lt;T&gt; and" data-type="indexterm" id="id3789"/><code>ValueTask&lt;T&gt;</code> is relatively unusual in that it’s defined as a struct <em>purely</em> for performance reasons. This means that it’s encumbered with <em>inappropriate</em> value-type semantics that can lead to surprises. To avoid incorrect behavior, you must avoid the following:</p>
<ul>
<li><p>Awaiting the same <code>ValueTask&lt;T&gt;</code> multiple times</p></li>
<li><p>Calling <code>.GetAwaiter().GetResult()</code> when the operation hasn’t completed</p></li>
</ul>
<p>If you need to perform these actions, call <code>.AsTask()</code> and operate instead on the resulting <code>Task</code>.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>The easiest way to avoid these traps is to directly await a method call, for instance:</p>
<pre data-type="programlisting">await Foo();   // Safe</pre>
<p>The door to erroneous behavior opens when you assign the (value) task to a variable:</p>
<pre data-type="programlisting">ValueTask&lt;int&gt; <strong>valueTask = Foo()</strong>;  // Caution!
// Our use of valueTask can now lead to errors.</pre>
<p>which can be mitigated by converting immediately to an ordinary task:</p>
<pre data-type="programlisting">Task&lt;int&gt; task = Foo()<strong>.AsTask()</strong>;   // Safe
// task is safe to work with.</pre>
</div>
</div></section>
<section data-pdf-bookmark="Avoiding excessive bouncing" data-type="sect3"><div class="sect3" id="avoiding_excessive_bouncing">
<h3>Avoiding excessive bouncing</h3>
<p><a contenteditable="false" data-primary="asynchronous functions" data-secondary="avoiding excessive bouncing" data-type="indexterm" id="id3790"/><a contenteditable="false" data-primary="ConfigureAwait" data-type="indexterm" id="id3791"/>For methods that are called many times in a loop, you can avoid the cost of repeatedly bouncing to a UI message loop by calling <code>ConfigureAwait</code>. This forces a task not to bounce continuations to the synchronization context, cutting the overhead closer to the cost of a context switch (or much less if the method that you’re awaiting completes synchronously):</p>
<pre data-type="programlisting">async void A() { ... await B(); ... }

async Task B()
{
  for (int i = 0; i &lt; <strong>1000</strong>; i++)
    await C()<strong>.ConfigureAwait (false)</strong>;
}

async Task C() { ... }</pre>
<p>This means that for the <code>B</code> and <code>C</code> methods, we rescind the simple thread-safety model in UI apps whereby code runs on the UI thread and can be preempted only during an <code>await</code> statement. Method <code>A</code>, however, is unaffected and will remain on a UI thread if it started on one.</p>
<p>This optimization is particularly relevant when writing libraries: you don’t need the benefit of simplified thread-safety because your code typically does not share state with the caller—and does not access UI controls. (It would also make sense, in our example, for method C to complete synchronously if it knew the operation was likely to be short-running.<a contenteditable="false" data-primary="" data-startref="ch14.html30" data-type="indexterm" id="id3792"/>)<a contenteditable="false" data-primary="" data-startref="ch14.html20" data-type="indexterm" id="id3793"/><a contenteditable="false" data-primary="" data-startref="ch14.html19" data-type="indexterm" id="id3794"/></p>
</div></section>
</div></section>
</div></section>
<section data-pdf-bookmark="Asynchronous Patterns" data-type="sect1"><div class="sect1" id="asynchronous_patterns">
<h1>Asynchronous Patterns</h1>
<section data-pdf-bookmark="Cancellation" data-type="sect2"><div class="sect2" id="cancellation">
<h2>Cancellation</h2>
<p><a contenteditable="false" data-primary="asynchronous patterns" data-type="indexterm" id="ch14.html33"/><a contenteditable="false" data-primary="asynchrony" data-secondary="asynchronous patterns" data-type="indexterm" id="ch14.html34"/>It’s <a contenteditable="false" data-primary="asynchronous patterns" data-secondary="cancellation" data-type="indexterm" id="ch14.html35"/><a contenteditable="false" data-primary="concurrent operations, canceling" data-type="indexterm" id="ch14.html36"/>often important to be able to cancel a concurrent operation after it’s started, perhaps in response to a user request. A simple way to implement this is with a cancellation flag, which we could encapsulate by writing a class like this:</p>
<pre data-type="programlisting">class CancellationToken
{
  public bool IsCancellationRequested { get; private set; }
  public void Cancel() { IsCancellationRequested = true; }
  public void ThrowIfCancellationRequested()
  {
    if (IsCancellationRequested)
      throw new OperationCanceledException();
  }
}</pre>
<p>We could then write a cancellable asynchronous method as follows:</p>
<pre data-type="programlisting">async Task Foo (CancellationToken cancellationToken)
{
  for (int i = 0; i &lt; 10; i++)
  {
    Console.WriteLine (i);
    await Task.Delay (1000);
    cancellationToken.ThrowIfCancellationRequested();
  }
}</pre>
<p>When the caller wants to cancel, it calls <code>Cancel</code> on the cancellation token that it passed into <code>Foo</code>. This sets <code>IsCancellationRequested</code> to true, which causes <code>Foo</code> to fault a short time later with an <code>OperationCanceledException</code> (a predefined exception in the <code>System</code> namespace designed for this purpose).</p>
<p>Thread-safety aside (we should be locking around reading/writing <code>IsCancellationRequested</code>), this pattern is effective, and the CLR provides a type called <code>CancellationToken</code> that is very similar to what we’ve just shown. However, it lacks a <code>Cancel</code> method; this method is instead exposed on another type called <code>CancellationTokenSource</code>. This separation provides some security: a method that has access only to a <code>CancellationToken</code> object can check for but not <em>initiate</em> cancellation.</p>
<p>To get a cancellation token, we first instantiate a <code>CancellationTokenSource</code>:</p>
<pre data-type="programlisting">var cancelSource = new CancellationTokenSource();</pre>
<p>This exposes a <code>Token</code> property, which returns a <code>CancellationToken</code>. Hence, we could call our <code>Foo</code> method, as follows:</p>
<pre data-type="programlisting">var cancelSource = new CancellationTokenSource();
Task foo = Foo (cancelSource.Token);
...
... <em>(sometime later)</em>
cancelSource.Cancel();</pre>
<p>Most asynchronous methods in the CLR support cancellation tokens, including <code>Delay</code>. If we modify <code>Foo</code> such that it passes its token into the <code>Delay</code> method, the task will end immediately upon request (rather than up to a second later):</p>
<pre data-type="programlisting">async Task Foo (CancellationToken cancellationToken)
{
  for (int i = 0; i &lt; 10; i++)
  {
    Console.WriteLine (i);
    await Task.Delay (1000, <strong>cancellationToken</strong>);
  }
}</pre>
<p>Notice that we no longer need to call <code>ThrowIfCancellationRequested</code> because <code>Task.Delay</code> is doing that for us. Cancellation tokens propagate nicely down the call stack (just as cancellation requests cascade <em>up</em> the call stack, by virtue of being exceptions).</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>UWP relies on WinRT types, whose asynchronous methods follow an inferior protocol for cancellation whereby instead of accepting a <code>CancellationToken</code>, the <code>IAsyncInfo</code> type exposes a <code>Cancel</code> method. The <code>AsTask</code> extension method is overloaded to accept a cancellation token, however, bridging the gap.</p>
</div>
<p>Synchronous methods can support cancellation, too (such as <code>Task</code>’s <code>Wait</code> method). In such cases, the instruction to cancel will need to come asynchronously (e.g., from another task). For example:</p>
<pre data-type="programlisting">var cancelSource = new CancellationTokenSource();
<strong>Task.Delay (5000).ContinueWith (ant =&gt; cancelSource.Cancel());</strong>
...</pre>
<p>In fact, you can specify a time interval when constructing <code>CancellationTokenSource</code> to initiate cancellation after a set period of time (just as we demonstrated). It’s useful for implementing timeouts, whether synchronous or asynchronous:</p>
<pre data-type="programlisting">var cancelSource = new CancellationTokenSource (5000);
try { await Foo (cancelSource.Token); }
catch (OperationCanceledException ex) { Console.WriteLine ("Cancelled"); }</pre>
<p>The <code>CancellationToken</code> struct provides a <code>Register</code> method that lets you register a callback delegate that will be fired upon cancellation; it returns an object that can be disposed to undo the registration.</p>
<p>Tasks generated by the compiler’s asynchronous functions automatically enter a “Canceled” state upon an unhandled <code>OperationCanceledException</code> (<code>IsCanceled</code> returns true, and <code>IsFaulted</code> returns false). The same goes for tasks created with <code>Task.Run</code> for which you pass the (same) <code>CancellationToken</code> to the constructor. The distinction between a faulted and a canceled task is unimportant in asynchronous scenarios, in that both throw an <code>OperationCanceledException</code> when awaited; it matters in advanced parallel programming scenarios (specifically conditional continuations). We pick up this topic in <a data-type="xref" href="ch22.html#canceling_tasks">“Canceling Tasks”</a>.<a contenteditable="false" data-primary="" data-startref="ch14.html36" data-type="indexterm" id="id3795"/><a contenteditable="false" data-primary="" data-startref="ch14.html35" data-type="indexterm" id="id3796"/></p>
</div></section>
<section data-pdf-bookmark="Progress Reporting" data-type="sect2"><div class="sect2" id="progress_reporting">
<h2>Progress Reporting</h2>
<p><a contenteditable="false" data-primary="asynchronous patterns" data-secondary="progress reporting" data-type="indexterm" id="ch14.html37"/>Sometimes, you’ll want an asynchronous operation to report back progress as it’s running. A simple solution is to pass an <code>Action</code> delegate to the asynchronous method, which the method fires whenever progress changes:</p>
<pre data-type="programlisting">Task Foo (<strong>Action&lt;int&gt; onProgressPercentChanged</strong>)
{
  return Task.Run (() =&gt;
  {
    for (int i = 0; i &lt; 1000; i++)
    {
      if (i % 10 == 0) onProgressPercentChanged (i / 10);
      // Do something compute-bound...
    }
  });
}</pre>
<p>Here’s how we could call it:</p>
<pre data-type="programlisting">Action&lt;int&gt; progress = i =&gt; Console.WriteLine (i + " %");
await Foo (progress);</pre>
<p>Although this works well in a console application, it’s not ideal in rich-client scenarios because it reports progress from a worker thread, causing potential thread-safety issues for the consumer. (In effect, we’ve allowed a side effect of concurrency to “leak” to the outside world, which is unfortunate given that the method is otherwise isolated if called from a UI thread.)</p>
<section data-pdf-bookmark="IProgress&lt;T&gt; and Progress&lt;T&gt;" data-type="sect3"><div class="sect3" id="iprogressless_thantgreater_than_and_pro">
<h3>IProgress&lt;T&gt; and Progress&lt;T&gt;</h3>
<p><a contenteditable="false" data-primary="IProgress&lt;T&gt;" data-type="indexterm" id="id3797"/><a contenteditable="false" data-primary="Progress&lt;T&gt;" data-type="indexterm" id="id3798"/>The CLR provides a pair of types to solve this problem: an interface called <span class="keep-together"><code>IProgress&lt;T&gt;</code></span> and a class that implements this interface called <code>Progress&lt;T&gt;</code>. Their purpose, in effect, is to “wrap” a delegate so that UI applications can report progress safely through the synchronization context.</p>
<p>The interface defines just one method:</p>
<pre data-type="programlisting">public interface IProgress&lt;in T&gt;
{
  void Report (T value);
}</pre>
<p>Using <code>IProgress&lt;T&gt;</code> is easy; our method hardly changes:</p>
<pre data-type="programlisting">Task Foo (<strong>IProgress&lt;int&gt;</strong> onProgressPercentChanged)
{
  return Task.Run (() =&gt;
  {
    for (int i = 0; i &lt; 1000; i++)
    {
      if (i % 10 == 0) onProgressPercentChanged<strong>.Report</strong> (i / 10);
      // Do something compute-bound...
    }
  });
}</pre>
<p>The <code>Progress&lt;T&gt;</code> class has a constructor that accepts a delegate of type <code>Action&lt;T&gt;</code> that it wraps:</p>
<pre data-type="programlisting">var progress = <strong>new Progress&lt;int&gt;</strong> (i =&gt; Console.WriteLine (i + " %"));
await Foo (progress);</pre>
<p>(<code>Progress&lt;T&gt;</code> also has a <code>ProgressChanged</code> event that you can subscribe to instead of [or in addition to] passing an action delegate to the constructor.) Upon instantiating <code>Progress&lt;int&gt;</code>, the class captures the synchronization context, if present. When <code>Foo</code> then calls <code>Report</code>, the delegate is invoked through that context.</p>
<p>Asynchronous methods can implement more elaborate progress reporting by replacing <code>int</code> with a custom type that exposes a range of properties.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>If you’re familiar with Rx, you’ll notice that <code>IProgress&lt;T&gt;</code> together with the task returned by the asynchronous function provide a feature set similar to <code>IObserver&lt;T&gt;</code>. The difference is that a task can expose a “final” return value <em>in addition</em> to (and differently typed to) the values emitted by <code>IProgress&lt;T&gt;</code>.</p>
<p>Values emitted by <code>IProgress&lt;T&gt;</code> are typically “throwaway” values (e.g., percent complete or bytes downloaded so far), whereas values pushed by <code>IObserver&lt;T&gt;</code>’s <code>OnNext</code> typically comprise the result itself and are the very reason for calling it.</p>
</div>
<p>Asynchronous methods in WinRT also offer progress reporting, although the protocol is complicated by COM’s (relatively) primitive type system. Instead of accepting an <code>IProgress&lt;T&gt;</code> object, asynchronous WinRT methods that report progress return one of the following interfaces, <a contenteditable="false" data-primary="IAsyncAction" data-type="indexterm" id="id3799"/><a contenteditable="false" data-primary="IAsyncOperation&lt;TResult&gt;" data-type="indexterm" id="id3800"/><a contenteditable="false" data-primary="IAsyncOperationWithProgress&lt;TResult&gt;" data-type="indexterm" id="id3801"/>in place of <code>IAsyncAction</code> and <code>IAsyncOperation​&lt;TRe⁠sult&gt;</code>:</p>
<pre data-type="programlisting">IAsyncActionWithProgress&lt;TProgress&gt;
IAsyncOperationWithProgress&lt;TResult, TProgress&gt;</pre>
<p>Interestingly, both are based on <code>IAsyncInfo</code> (not <code>IAsyncAction</code> and <code>IAsyncOperation&lt;TResult&gt;</code>).</p>
<p>The good news is that the <code>AsTask</code> extension method is also overloaded to accept <code>IProgress&lt;T&gt;</code> for the aforementioned interfaces, so as a .NET consumer, you can ignore the COM interfaces and do this:<a contenteditable="false" data-primary="" data-startref="ch14.html37" data-type="indexterm" id="id3802"/></p>
<pre data-type="programlisting">var progress = new Progress&lt;int&gt; (i =&gt; Console.WriteLine (i + " %"));
CancellationToken cancelToken = ...
var task = someWinRTobject.FooAsync().<strong>AsTask</strong> (cancelToken, progress);</pre>
</div></section>
</div></section>
<section class="pagebreak-before" data-pdf-bookmark="The Task-Based Asynchronous Pattern" data-type="sect2"><div class="sect2" id="the_task_based_asynchronous_pattern">
<h2 class="less_space">The Task-Based Asynchronous Pattern</h2>
<p><a contenteditable="false" data-primary="asynchronous patterns" data-secondary="task-based patterns" data-type="indexterm" id="id3803"/><a contenteditable="false" data-primary="TAP (Task-Based Asynchronous Pattern)" data-type="indexterm" id="id3804"/><a contenteditable="false" data-primary="Task-Based Asynchronous Pattern (TAP)" data-type="indexterm" id="id3805"/>.NET exposes hundreds of task-returning asynchronous methods that you can <code>await</code> (mainly related to I/O). Most of these methods (at least partly) follow a pattern called the <em>Task-Based Asynchronous Pattern</em> (TAP), which is a sensible formalization of what we have described to date. A TAP method does the following:</p>
<ul>
<li><p>Returns a “hot” (running) <code>Task</code> or <code>Task&lt;TResult&gt;</code></p></li>
<li><p>Has an “Async” suffix (except for special cases such as task combinators)</p></li>
<li><p>Is overloaded to accept a cancellation token and/or <code>IProgress&lt;T&gt;</code> if it supports cancellation and/or progress reporting</p></li>
<li><p>Returns quickly to the caller (has only a small initial <em>synchronous phase</em>)</p></li>
<li><p>Does not tie up a thread if I/O-bound</p></li>
</ul>
<p>As we’ve seen, TAP methods are easy to write with C#’s asynchronous functions.</p>
</div></section>
<section data-pdf-bookmark="Task Combinators" data-type="sect2"><div class="sect2" id="task_combinators">
<h2>Task Combinators</h2>
<p><a contenteditable="false" data-primary="asynchronous patterns" data-secondary="task combinators" data-type="indexterm" id="ch14.html38"/><a contenteditable="false" data-primary="task combinators" data-type="indexterm" id="ch14.html39"/>A nice consequence of there being a consistent protocol for asynchronous functions (whereby they consistently return tasks) is that it’s possible to use and write <em>task combinators</em>—functions that usefully combine tasks, without regard for what those specific tasks do.</p>
<p>The CLR includes two task combinators: <code>Task.WhenAny</code> and <code>Task.WhenAll</code>. In describing them, we’ll assume the following methods are defined:</p>
<pre data-type="programlisting">async Task&lt;int&gt; Delay1() { await Task.Delay (1000); return 1; }
async Task&lt;int&gt; Delay2() { await Task.Delay (2000); return 2; }
async Task&lt;int&gt; Delay3() { await Task.Delay (3000); return 3; }</pre>
<section data-pdf-bookmark="WhenAny" data-type="sect3"><div class="sect3" id="whenany">
<h3>WhenAny</h3>
<p><a contenteditable="false" data-primary="task combinators" data-secondary="WhenAny" data-type="indexterm" id="id3806"/><a contenteditable="false" data-primary="Task..." data-secondary="Task.WhenAny" data-type="indexterm" id="id3807"/><code>Task.WhenAny</code> returns a task that completes when any one of a set of tasks complete. The following completes in one second:</p>
<pre data-type="programlisting">Task&lt;int&gt; winningTask = await Task.WhenAny (Delay1(), Delay2(), Delay3());
Console.WriteLine ("Done");
Console.WriteLine (winningTask.Result);   // 1</pre>
<p>Because <code>Task.WhenAny</code> itself returns a task, we await it, which returns the task that finished first. Our example is entirely nonblocking—including the last line when we access the <code>Result</code> property (because <code>winningTask</code> will already have finished). Nonetheless, it’s usually better to <code>await</code> the <code>winningTask</code>:</p>
<pre data-type="programlisting">Console.WriteLine (await winningTask);   // 1</pre>
<p><a contenteditable="false" data-primary="AggregateException class" data-type="indexterm" id="id3808"/>because any exceptions are then rethrown without an <code>AggregateException</code> wrapping. In fact, we can perform both <code>await</code>s in one step:</p>
<pre data-type="programlisting">int answer = await await Task.WhenAny (Delay1(), Delay2(), Delay3());</pre>
<p>If a nonwinning task subsequently faults, the exception will go unobserved unless you subsequently await the task (or query its <code>Exception</code> property).</p>
<p><code>WhenAny</code> is useful for applying timeouts or cancellation to operations that don’t otherwise support it:</p>
<pre data-type="programlisting">Task&lt;string&gt; task = SomeAsyncFunc();
Task winner = await (Task.WhenAny (task, Task.Delay(5000)));
if (winner != task) throw new TimeoutException();
string result = await task;   // Unwrap result/re-throw</pre>
<p>Notice that because in this case we’re calling <code>WhenAny</code> with differently typed tasks, the winner is reported as a plain <code>Task</code> (rather than a <code>Task&lt;string&gt;</code>).</p>
</div></section>
<section data-pdf-bookmark="WhenAll" data-type="sect3"><div class="sect3" id="whenall">
<h3>WhenAll</h3>
<p><a contenteditable="false" data-primary="task combinators" data-secondary="WhenAll" data-type="indexterm" id="id3809"/><a contenteditable="false" data-primary="Task..." data-secondary="Task.WhenAll" data-type="indexterm" id="id3810"/><code>Task.WhenAll</code> returns a task that completes when <em>all</em> of the tasks that you pass to it complete. The following completes after three seconds (and demonstrates the <em>fork/join</em> pattern):</p>
<pre data-type="programlisting">await Task.WhenAll (Delay1(), Delay2(), Delay3());</pre>
<p>We could get a similar result by awaiting <code>task1</code>, <code>task2</code>, and <code>task3</code> in turn rather than using <code>WhenAll</code>:</p>
<pre data-type="programlisting">Task task1 = Delay1(), task2 = Delay2(), task3 = Delay3();
await task1; await task2; await task3;</pre>
<p>The difference (apart from it being less efficient by virtue of requiring three awaits rather than one) is that should <code>task1</code> fault, we’ll never get to await <code>task2</code>/<code>task3</code>, and any of their exceptions will go unobserved.</p>
<p>In contrast, <code>Task.WhenAll</code> doesn’t complete until all tasks have completed—even when there’s a fault. And if there are multiple faults, their exceptions are combined into the task’s <code>AggregateException</code> (this is when <code>AggregateException</code> actually becomes useful—should you be interested in all the exceptions, that is). Awaiting the combined task, however, throws only the first exception, so to see all the exceptions, you need to do this:</p>
<pre data-type="programlisting">Task task1 = Task.Run (() =&gt; { throw null; } );
Task task2 = Task.Run (() =&gt; { throw null; } );
Task all = Task.WhenAll (task1, task2);
try { await all; }
catch
{
  Console.WriteLine (all.Exception.InnerExceptions.Count);   // 2 
}   </pre>
<p>Calling <code>WhenAll</code> with tasks of type <code>Task&lt;TResult&gt;</code> returns a <code>Task&lt;TResult[]&gt;</code>, giving the combined results of all the tasks. This reduces to a <code>TResult[]</code> when awaited:</p>
<pre data-type="programlisting">Task&lt;int&gt; task1 = Task.Run (() =&gt; 1);
Task&lt;int&gt; task2 = Task.Run (() =&gt; 2);
int[] results = await Task.WhenAll (task1, task2);   // { 1, 2 }</pre>
<p>To give a practical example, the following downloads URIs in parallel and sums their total length:</p>
<pre data-type="programlisting">async Task&lt;int&gt; GetTotalSize (string[] uris)
{
  IEnumerable&lt;Task&lt;byte[]&gt;&gt; downloadTasks = uris.Select (uri =&gt; 
    new WebClient().DownloadDataTaskAsync (uri));
        
  byte[][] contents = await Task.WhenAll (downloadTasks);
  return contents.Sum (c =&gt; c.Length);
}</pre>
<p>There’s a slight inefficiency here, though, in that we’re unnecessarily hanging onto the byte arrays that we download until every task is complete. It would be more efficient if we collapsed byte arrays into their lengths immediately after downloading them. This is where an asynchronous lambda comes in handy because we need to feed an <code>await</code> expression into LINQ’s <code>Select</code> query operator:</p>
<pre data-type="programlisting">async Task&lt;int&gt; GetTotalSize (string[] uris)
{
  IEnumerable&lt;Task&lt;<strong>int</strong>&gt;&gt; downloadTasks = uris.Select (<strong>async</strong> uri =&gt;
    (<strong>await</strong> new WebClient().DownloadDataTaskAsync (uri)).<strong>Length</strong>);
        
  <strong>int[]</strong> contentLengths = await Task.WhenAll (downloadTasks);
  return contentLengths.<strong>Sum()</strong>;
}</pre>
</div></section>
<section data-pdf-bookmark="Custom combinators" data-type="sect3"><div class="sect3" id="custom_combinators">
<h3>Custom combinators</h3>
<p><a contenteditable="false" data-primary="task combinators" data-secondary="custom combinators" data-type="indexterm" id="id3811"/>It can be useful to write your own task combinators. The simplest “combinator” accepts a single task, such as the following, which lets you await any task with a timeout:</p>
<pre data-type="programlisting">async static Task&lt;TResult&gt; WithTimeout&lt;TResult&gt; (this Task&lt;TResult&gt; task,
                                                 TimeSpan timeout)
{
  Task winner = await Task.WhenAny (task, Task.Delay (timeout))
                          .ConfigureAwait (false);
  if (winner != task) throw new TimeoutException();
  return await task.ConfigureAwait (false);   // Unwrap result/re-throw
}</pre>
<p>Because this is very much a “library method” that doesn’t access external shared state, we use <code>ConfigureAwait(false)</code> when awaiting to avoid potentially bouncing to a UI synchronization context. We can further improve efficiency by canceling the <code>Task.Delay</code> when the task completes on time (this avoids the small overhead of a timer hanging around):</p>
<pre data-type="programlisting">async static Task&lt;TResult&gt; WithTimeout&lt;TResult&gt; (this Task&lt;TResult&gt; task,
                                                 TimeSpan timeout)
{
  var cancelSource = new CancellationTokenSource();
  var delay = Task.Delay (timeout, cancelSource.Token);
  Task winner = await Task.WhenAny (task, delay).ConfigureAwait (false);
  if (winner == task)
    cancelSource.Cancel();
  else
    throw new TimeoutException();
  return await task.ConfigureAwait (false);   // Unwrap result/re-throw
}</pre>
<p>The following lets you “abandon” a task via a <code>CancellationToken</code>:</p>
<pre data-type="programlisting">static Task&lt;TResult&gt; WithCancellation&lt;TResult&gt; (this Task&lt;TResult&gt; task,
                                          CancellationToken cancelToken)
{
  var tcs = new TaskCompletionSource&lt;TResult&gt;();
  var reg = cancelToken.Register (() =&gt; tcs.TrySetCanceled ());
  task.ContinueWith (ant =&gt; 
  {
    reg.Dispose();
    if (ant.IsCanceled)
      tcs.TrySetCanceled();
    else if (ant.IsFaulted)
      tcs.TrySetException (ant.Exception.InnerExceptions);
    else
      tcs.TrySetResult (ant.Result);
  });
  return tcs.Task;
}</pre>
<p>Task combinators can be complex to write, sometimes requiring the use of signaling constructs, which we cover in <a data-type="xref" href="ch21.html#advanced_threadin">Chapter 21</a>. This is actually a good thing, because it keeps concurrency-related complexity out of your business logic and into reusable methods that can be tested in isolation.</p>
<p>The next combinator works like <code>WhenAll</code>, except that if any of the tasks fault, the resultant task faults immediately:</p>
<pre data-type="programlisting">async Task&lt;TResult[]&gt; WhenAllOrError&lt;TResult&gt; 
  (params Task&lt;TResult&gt;[] tasks)
{
  var killJoy = new TaskCompletionSource&lt;TResult[]&gt;();
  foreach (var task in tasks)
    task.ContinueWith (ant =&gt;
    {
      if (ant.IsCanceled) 
        killJoy.TrySetCanceled();
      else if (ant.IsFaulted)
        killJoy.TrySetException (ant.Exception.InnerExceptions);
    });
  return await await Task.WhenAny (killJoy.Task, Task.WhenAll (tasks))
                         .ConfigureAwait (false);
}</pre>
<p class="pagebreak-before">We begin by creating a <code>TaskCompletionSource</code> whose sole job is to end the party if a task faults. Hence, we never call its <code>SetResult</code> method, only its <code>TrySetCanceled</code> and <code>TrySetException</code> methods. In this case, <code>ContinueWith</code> is more convenient than <code>GetAwaiter().OnCompleted</code> because we’re not accessing the tasks’ results and wouldn’t want to bounce to a UI thread at that point.<a contenteditable="false" data-primary="" data-startref="ch14.html39" data-type="indexterm" id="id3812"/><a contenteditable="false" data-primary="" data-startref="ch14.html38" data-type="indexterm" id="id3813"/></p>
</div></section>
</div></section>
<section data-pdf-bookmark="Asynchronous Locking" data-type="sect2"><div class="sect2" id="asynchronous_locking">
<h2>Asynchronous Locking</h2>
<p>In <a data-type="xref" href="ch21.html#asynchronous_semaphores_and_locks">“Asynchronous semaphores and locks”</a>, we describe how to use <code>SemaphoreSlim</code> to lock or limit concurrency asynchronously.<a contenteditable="false" data-primary="" data-startref="ch14.html34" data-type="indexterm" id="id3814"/><a contenteditable="false" data-primary="" data-startref="ch14.html33" data-type="indexterm" id="id3815"/></p>
</div></section>
</div></section>
<section data-pdf-bookmark="Obsolete Patterns" data-type="sect1"><div class="sect1" id="obsolete_patterns">
<h1>Obsolete Patterns</h1>
<p><a contenteditable="false" data-primary="asynchronous patterns" data-secondary="obsolete patterns" data-type="indexterm" id="ch14.html40"/>.NET employs other patterns for asynchrony, which precede tasks and asynchronous functions. These are rarely required now that task-based asynchrony has become the dominant pattern.</p>
<section data-pdf-bookmark="Asynchronous Programming Model" data-type="sect2"><div class="sect2" id="asynchronous_programming_model">
<h2>Asynchronous Programming Model</h2>
<p><a contenteditable="false" data-primary="APM (Asynchronous Programming Model)" data-type="indexterm" id="id3816"/><a contenteditable="false" data-primary="asynchronous patterns" data-secondary="Asynchronous Programming Model (APM)" data-type="indexterm" id="id3817"/><a contenteditable="false" data-primary="Asynchronous Programming Model (APM)" data-type="indexterm" id="id3818"/><a contenteditable="false" data-primary="IAsyncResult" data-type="indexterm" id="id3819"/>The oldest pattern is called the <em>Asynchronous Programming Model</em> (APM) and uses a pair of methods starting in “Begin” and “End” and an interface called <code>IAsyncResult</code>. To illustrate, let’s take the <code>Stream</code> class in <code>System.IO</code> and look at its <code>Read</code> method. First, the synchronous version:</p>
<pre data-type="programlisting">public int Read (byte[] buffer, int offset, int size);</pre>
<p>You can probably predict what the <em>task</em>-based asynchronous version looks like:</p>
<pre data-type="programlisting">public <strong>Task&lt;</strong>int<strong>&gt;</strong> Read<strong>Async</strong> (byte[] buffer, int offset, int size);</pre>
<p>Now let’s examine the APM version:</p>
<pre data-type="programlisting">public <strong>IAsyncResult Begin</strong>Read (byte[] buffer, int offset, int size,
                               <strong>AsyncCallback callback, object state</strong>);
<strong>public int EndRead (IAsyncResult asyncResult);</strong></pre>
<p>Calling the <code>Begin*</code> method initiates the operation, returning an <code>IAsyncResult</code> object that acts as a token for the asynchronous operation. When the operation completes (or faults), the <code>AsyncCallback</code> delegate fires:</p>
<pre data-type="programlisting">public delegate void AsyncCallback (IAsyncResult ar);</pre>
<p>Whoever handles this delegate then calls the <code>End*</code> method, which provides the operation’s return value as well as rethrowing an exception if the operation faulted.</p>
<p>The APM is not only awkward to use but is surprisingly difficult to implement correctly. The easiest way to deal with APM methods is to call the <code>Task.Factory.From​Async</code> adapter method, which converts an APM method pair into a <code>Task</code>. Internally, it uses a <code>TaskCompletionSource</code> to give you a task that’s signaled when an APM operation completes or faults.</p>
<p class="pagebreak-before">The <code>FromAsync</code> method requires the following parameters:</p>
<ul>
<li><p>A delegate specifying a <code>Begin<em>XXX</em></code> method</p></li>
<li><p>A delegate specifying an <code>End<em>XXX</em></code> method</p></li>
<li><p>Additional arguments that will get passed to these methods</p></li>
</ul>
<p><code>FromAsync</code> is overloaded to accept delegate types and arguments that match nearly all the asynchronous method signatures found in .NET. For instance, assuming <code>stream</code> is a <code>Stream</code> and <code>buffer</code> is a <code>byte[]</code>, we could do this:</p>
<pre data-type="programlisting"><strong>Task&lt;int&gt; readChunk = Task&lt;int&gt;.Factory.FromAsync (</strong>
  <strong>stream.BeginRead, stream.EndRead</strong>, buffer, 0, 1000, null);</pre>
</div></section>
<section data-pdf-bookmark="Event-Based Asynchronous Pattern" data-type="sect2"><div class="sect2" id="event_based_asynchronous_pattern">
<h2>Event-Based Asynchronous Pattern</h2>
<p><a contenteditable="false" data-primary="asynchronous patterns" data-secondary="Event-Based Asynchronous Pattern" data-type="indexterm" id="id3820"/><a contenteditable="false" data-primary="EAP (Event-Based Asynchronous Pattern)" data-type="indexterm" id="id3821"/><a contenteditable="false" data-primary="Event-Based Asynchronous Pattern (EAP)" data-type="indexterm" id="id3822"/>The <em>Event-Based Asynchronous Pattern</em> (EAP) was introduced in 2005 to provide a simpler alternative to the APM, particularly in UI scenarios. It was implemented in only a handful of types, however, most notably <code>WebClient</code> in <code>System.Net</code>. The EAP is just a pattern; no types are provided to assist. Essentially the pattern is this: a class offers a family of members that internally manage concurrency, similar to the <span class="keep-together">following</span>:</p>
<pre data-type="programlisting">// These members are from the WebClient class:

public byte[] DownloadData (Uri address);    // Synchronous version
public void DownloadData<strong>Async</strong> (Uri address);
public void DownloadData<strong>Async</strong> (Uri address, <strong>object userToken</strong>);
public event DownloadData<strong>CompletedEventHandler</strong> DownloadData<strong>Completed</strong>;

<strong>public void CancelAsync (object userState);  // Cancels an operation</strong>
<strong>public bool IsBusy { get; }                  // Indicates if still running</strong></pre>
<p>The <code>*Async</code> methods initiate an operation asynchronously. When the operation completes, the <code><em>*</em>Completed</code> event fires (automatically posting to the captured synchronization context if present). This event passes back an event arguments object that contains the following:</p>
<ul>
<li><p>A flag indicating whether the operation was canceled (by the consumer calling <code>CancelAsync</code>)</p></li>
<li><p>An <code>Error</code> object indicating an exception that was thrown (if any)</p></li>
<li><p>The <code>userToken</code> object if supplied when calling the <code>Async</code> method</p></li>
</ul>
<p>EAP types can also expose a progress reporting event, which fires whenever progress changes (also posted through the synchronization context):</p>
<pre data-type="programlisting">public event DownloadProgressChangedEventHandler DownloadProgressChanged;</pre>
<p>Implementing the EAP requires a large amount of boilerplate code, making the pattern poorly compositional.</p>
</div></section>
<section data-pdf-bookmark="BackgroundWorker" data-type="sect2"><div class="sect2" id="backgroundworker">
<h2>BackgroundWorker</h2>
<p><a contenteditable="false" data-primary="asynchronous patterns" data-secondary="BackgroundWorker class" data-type="indexterm" id="id3823"/><a contenteditable="false" data-primary="BackgroundWorker class" data-type="indexterm" id="id3824"/><a contenteditable="false" data-primary="System..." data-secondary="System.ComponentModel" data-type="indexterm" id="id3825"/><code>BackgroundWorker</code> in <code>System.ComponentModel</code> is a general-purpose implementation of the EAP. It allows rich-client apps to start a worker thread and report completion and percentage-based progress without needing to explicitly capture synchronization context. Here’s an example:</p>
<pre data-type="programlisting">var worker = new BackgroundWorker { WorkerSupportsCancellation = true };
worker.DoWork += (sender, args) =&gt;
{                                      // This runs on a worker thread
  if (args.Cancel) return;
  Thread.Sleep(1000); 
  args.Result = 123;
};
worker.RunWorkerCompleted += (sender, args) =&gt;    
{                                                  // Runs on UI thread
  // We can safely update UI controls here...
  if (args.Cancelled)
    Console.WriteLine ("Cancelled");
  else if (args.Error != null)
    Console.WriteLine ("Error: " + args.Error.Message);
  else
    Console.WriteLine ("Result is: " + args.Result);
};
worker.RunWorkerAsync();   // Captures sync context and starts operation</pre>
<p><code>RunWorkerAsync</code> starts the operation, firing the <code>DoWork</code> event on a pooled worker thread. It also captures the synchronization context, and when the operation completes (or faults), the <code>RunWorkerCompleted</code> event is invoked through that synchronization context (like a continuation).</p>
<p><code>BackgroundWorker</code> creates coarse-grained concurrency, in that the <code>DoWork</code> event runs entirely on a worker thread. If you need to update UI controls in that event handler (other than posting a percentage-complete message), you must use <code>Dispatcher.BeginInvoke</code> or similar).</p>
<p>We describe <code>BackgroundWorker</code> in more detail at <a href="http://albahari.com/threading"><em class="hyperlink">http://albahari.com/threading</em></a><a contenteditable="false" data-primary="" data-startref="ch14.html40" data-type="indexterm" id="id3826"/>.<a contenteditable="false" data-primary="" data-startref="ch14.html0" data-type="indexterm" id="id3827"/></p>
</div></section>
</div></section>
<div data-type="footnotes"><p data-type="footnote" id="ch01fn14"><sup><a href="ch14.html#ch01fn14-marker">1</a></sup> The CLR creates other threads behind the scenes for garbage collection and finalization.</p></div></div></section></body></html>