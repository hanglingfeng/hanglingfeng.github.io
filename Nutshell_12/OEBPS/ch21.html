<html xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops"><head><title>Advanced Threading</title><link href="epub.css" rel="stylesheet" type="text/css"/>
<meta content="urn:uuid:3330d66d-9080-4595-aa6c-b8113bd76e5a" name="Adept.expected.resource"/></head><body data-type="book"><section data-nutshell-tab="Advanced Threading" data-pdf-bookmark="Chapter 21. Advanced Threading" data-type="chapter" epub:type="chapter"><div class="chapter" id="advanced_threadin">
<h1><span class="label">Chapter 21. </span>Advanced Threading</h1>
<p><a contenteditable="false" data-primary="threading" data-type="indexterm" id="ch21.html0"/><a contenteditable="false" data-primary="threading" data-secondary="advanced topics" data-type="indexterm" id="ch21.html1"/>We started <a data-type="xref" href="ch14.html#concurrency_and_asynchron">Chapter 14</a> with the basics of threading as a precursor to tasks and asynchrony. Specifically, we showed how to start and configure a thread, and covered essential concepts such as thread pooling, blocking, spinning, and synchronization contexts. We also introduced locking and thread safety, and demonstrated the simplest signaling construct, <code>ManualResetEvent</code>.</p>
<p>This chapter picks up where <a data-type="xref" href="ch14.html#concurrency_and_asynchron">Chapter 14</a> left off on the topic of threading. In the first three sections, we flesh out synchronization, locking, and thread safety in greater detail. We then cover:</p>
<ul>
<li><p>Nonexclusive locking (<code>Semaphore</code> and reader/writer locks)</p></li>
<li><p>All signaling constructs (<code>AutoResetEvent</code>, <code>ManualResetEvent</code>, <code>Countdow⁠n​Event</code>, and <code>Barrier</code>)</p></li>
<li><p>Lazy initialization (<code>Lazy&lt;T&gt;</code> and <code>LazyInitializer</code>)</p></li>
<li><p>Thread-local storage (<code>ThreadStaticAttribute</code>, <code>ThreadLocal&lt;T&gt;</code>, and <code>GetData</code>/<code>SetData</code>)</p></li>
<li><p>Timers</p></li>
</ul>
<p>Threading is such a vast topic that we’ve put additional material online to complete the picture. Visit <a href="http://albahari.com/threading"><em>http://albahari.com/threading</em></a> for a discussion on the following, more arcane, topics:</p>
<ul>
<li><p><code>Monitor.Wait</code> and <code>Monitor.Pulse</code> for specialized signaling scenarios</p></li>
<li><p>Nonblocking synchronization techniques for micro-optimization (<span class="keep-together"><code>Interlocked</code></span>, memory barriers, <code>volatile</code>)</p></li>
<li><p><code>SpinLock</code> and <code>SpinWait</code> for high-concurrency scenarios</p></li>
</ul>
<section data-pdf-bookmark="Synchronization Overview" data-type="sect1"><div class="sect1" id="synchronization_overview">
<h1>Synchronization Overview</h1>
<p><a contenteditable="false" data-primary="threading" data-secondary="synchronization overview" data-type="indexterm" id="id4333"/><em>Synchronization</em> is the act of coordinating concurrent actions for a predictable outcome. Synchronization is particularly important when multiple threads access the same data; it’s surprisingly easy to run aground in this area.</p>
<p>The simplest and most useful synchronization tools are arguably the continuations and task combinators described in <a data-type="xref" href="ch14.html#concurrency_and_asynchron">Chapter 14</a>. By formulating concurrent programs into asynchronous operations strung together with continuations and combinators, you lessen the need for locking and signaling. However, there are still times when the lower-level constructs come into play.</p>
<p>The synchronization constructs can be divided into three categories:</p>
<dl>
<dt>Exclusive locking</dt>
<dd>Exclusive locking constructs allow just one thread to perform some activity or execute a section of code at a time. Their primary purpose is to let threads access shared writing state without interfering with one another. The exclusive locking constructs are <code>lock</code>, <code>Mutex</code>, and <code>SpinLock</code>.</dd>
<dt>Nonexclusive locking</dt>
<dd>Nonexclusive locking lets you <em>limit</em> concurrency. The nonexclusive locking constructs are <code>Semaphore</code>(<code>Slim</code>) and <code>ReaderWriterLock</code>(<code>Slim</code>).</dd>
<dt>Signaling</dt>
<dd>These allow a thread to block until receiving one or more notifications from other thread(s). The signaling constructs include <code>ManualResetEvent</code>(<code>Slim</code>), <code>AutoResetEvent</code>, <code>CountdownEvent</code>, and <code>Barrier</code>. The former three are referred to as <em>event wait handles</em>.</dd>
</dl>
<p>It’s also possible (and tricky) to perform certain concurrent operations on shared state without locking through the use of <em>nonblocking synchronization constructs</em>. These are <code>Thread.MemoryBarrier</code>, <code>Thread.VolatileRead</code>, <code>Thread.VolatileWrite</code>, the <code>volatile</code> keyword, and the <code>Interlocked</code> class. We <a href="http://albahari.com/threading">cover this topic online</a>, along with <code>Monitor</code>’s <code>Wait</code>/<code>Pulse</code> methods, which you can use to write custom signaling logic.</p>
</div></section>
<section data-pdf-bookmark="Exclusive Locking" data-type="sect1"><div class="sect1" id="exclusive_locking">
<h1>Exclusive Locking</h1>
<p><a contenteditable="false" data-primary="exclusive locking" data-type="indexterm" id="ch21.html2"/><a contenteditable="false" data-primary="threading" data-secondary="exclusive locking" data-type="indexterm" id="ch21.html3"/>There are three exclusive locking constructs: the <code>lock</code> statement, <code>Mutex</code>, and <span class="keep-together"><code>SpinLock</code></span>. The <code>lock</code> construct is the most convenient and widely used, whereas the other two target niche scenarios:</p>
<ul>
<li><p><code>Mutex</code> lets you span multiple processes (computer-wide locks).</p></li>
<li><p><code>SpinLock</code> implements a micro-optimization that can lessen context switches in high-concurrency scenarios (see <a href="http://albahari.com/threading"><em>http://albahari.com/threading</em></a>).</p></li>
</ul>
<section data-pdf-bookmark="The lock Statement" data-type="sect2"><div class="sect2" id="the_lock_statement">
<h2>The lock Statement</h2>
<p><a contenteditable="false" data-primary="exclusive locking" data-secondary="lock statement" data-type="indexterm" id="id4334"/><a contenteditable="false" data-primary="lock statement" data-type="indexterm" id="id4335"/>To illustrate the need for locking, consider the following class:</p>
<pre data-type="programlisting">class ThreadUnsafe
{
  static int _val1 = 1, _val2 = 1;

  static void Go()
  {
    if (_val2 != 0) Console.WriteLine (_val1 / _val2);
    _val2 = 0;
  }
}</pre>
<p>This class is not thread-safe: if <code>Go</code> were called by two threads simultaneously, it would be possible to get a division-by-zero error because <code>_val2</code> could be set to zero in one thread right as the other thread was in between executing the <code>if</code> statement and <code>Console.WriteLine</code>. Here’s how <code>lock</code> fixes the problem:</p>
<pre data-type="programlisting">class ThreadSafe
{
  static readonly object _locker = new object();
  static int _val1 = 1, _val2 = 1;

  static void Go()
  {
    <strong>lock (_locker)</strong>
    {
      if (_val2 != 0) Console.WriteLine (_val1 / _val2);
      _val2 = 0;
    }
  }
}</pre>
<p>Only one thread can lock the synchronizing object (in this case, <code>_locker</code>) at a time, and any contending threads are blocked until the lock is released. If more than one thread contends the lock, they are queued on a “ready queue” and granted the lock on a first-come, first-served basis.<sup><a data-type="noteref" href="ch21.html#ch01fn15" id="ch01fn15-marker">1</a></sup> Exclusive locks are sometimes said to enforce <em>serialized</em> access to whatever’s protected by the lock because one thread’s access cannot overlap with that of another. In this case, we’re protecting the logic inside the <code>Go</code> method as well as the fields <code>_val1</code> and <code>_val2</code>.</p>
</div></section>
<section data-pdf-bookmark="Monitor.Enter and Monitor.Exit" data-type="sect2"><div class="sect2" id="monitordotenter_and_monitordotexit">
<h2>Monitor.Enter and Monitor.Exit</h2>
<p><a contenteditable="false" data-primary="exclusive locking" data-secondary="Monitor.Enter and Monitor.Exit" data-type="indexterm" id="id4336"/><a contenteditable="false" data-primary="Monitor.Enter" data-type="indexterm" id="id4337"/><a contenteditable="false" data-primary="Monitor.Exit" data-type="indexterm" id="id4338"/>C#’s <code>lock</code> statement is in fact a syntactic shortcut for a call to the methods <code>Monitor.Enter</code> and <code>Monitor.Exit</code>, with a <code>try</code>/<code>finally</code> block. Here’s (a simplified version of) what’s actually happening within the <code>Go</code> method of the preceding example:</p>
<pre data-type="programlisting"><strong>Monitor.Enter (_locker);</strong>
try
{
  if (_val2 != 0) Console.WriteLine (_val1 / _val2);
  _val2 = 0;
}
finally { <strong>Monitor.Exit (_locker);</strong> }</pre>
<p>Calling <code>Monitor.Exit</code> without first calling <code>Monitor.Enter</code> on the same object throws an exception.</p>
<section data-pdf-bookmark="The lockTaken overloads" data-type="sect3"><div class="sect3" id="the_locktaken_overloads">
<h3>The lockTaken overloads</h3>
<p><a contenteditable="false" data-primary="exclusive locking" data-secondary="lockTaken overloads" data-type="indexterm" id="id4339"/><a contenteditable="false" data-primary="lockTaken overloads" data-type="indexterm" id="id4340"/><a contenteditable="false" data-primary="overloading" data-secondary="lockTaken overloads" data-type="indexterm" id="id4341"/>The code that we just demonstrated has a subtle vulnerability. Consider the (unlikely) event of an exception being thrown between the call to <code>Monitor.Enter</code> and the <code>try</code> block (due, perhaps, to an <code>OutOfMemoryException</code> or, in .NET Framework, if the thread is aborted). In such a scenario, the lock might or might not be taken. If the lock <em>is</em> taken, it won’t be released—because we’ll never enter the <span class="keep-together"><code>try</code>/<code>finally</code></span> block. This will result in a leaked lock. To avoid this danger, <span class="keep-together"><code>Monitor.Enter</code></span> defines the following overload:</p>
<pre data-type="programlisting">public static void Enter (object obj, <strong>ref bool lockTaken</strong>);</pre>
<p><code>lockTaken</code> is false after this method if (and only if) the <code>Enter</code> method throws an exception and the lock was not taken.</p>
<p>Here’s the more robust pattern of use (which is exactly how C# translates a <code>lock</code> statement):</p>
<pre data-type="programlisting"><strong>bool lockTaken = false;</strong>
try
{
  Monitor.Enter (_locker, <strong>ref lockTaken</strong>);
  // Do your stuff...
}
finally { if <strong>(lockTaken)</strong> Monitor.Exit (_locker); }</pre>
</div></section>
<section data-pdf-bookmark="TryEnter" data-type="sect3"><div class="sect3" id="tryenter">
<h3>TryEnter</h3>
<p><a contenteditable="false" data-primary="exclusive locking" data-secondary="TryEnter method" data-type="indexterm" id="id4342"/><a contenteditable="false" data-primary="TryEnter method" data-type="indexterm" id="id4343"/><code>Monitor</code> also provides a <code>TryEnter</code> method that allows a timeout to be specified, either in milliseconds or as a <code>TimeSpan</code>. The method then returns <code>true</code> if a lock was obtained, or <code>false</code> if no lock was obtained because the method timed out. <code>TryEnter</code> can also be called with no argument, which “tests” the lock, timing out immediately if the lock can’t be obtained immediately. As with the <code>Enter</code> method, <code>TryEnter</code> is overloaded to accept a <code>lockTaken</code> argument.</p>
</div></section>
</div></section>
<section data-pdf-bookmark="Choosing the Synchronization Object" data-type="sect2"><div class="sect2" id="choosing_the_synchronization_object">
<h2>Choosing the Synchronization Object</h2>
<p><a contenteditable="false" data-primary="exclusive locking" data-secondary="choosing the synchronization object" data-type="indexterm" id="id4344"/><a contenteditable="false" data-primary="synchronization object" data-type="indexterm" id="id4345"/>You can use any object visible to each of the partaking threads as a synchronizing object, subject to one hard rule: it must be a reference type. The synchronizing object is typically private (because this helps to encapsulate the locking logic) and is typically an instance or static field. The synchronizing object can double as the object it’s protecting, as the <code>_list</code> field does in the following example:</p>
<pre data-type="programlisting">class ThreadSafe
{
  List &lt;string&gt; _list = new List &lt;string&gt;();

  void Test()
  {
    lock (_list)
    {
      _list.Add ("Item 1");
      ...</pre>
<p>A field dedicated for the purpose of locking (such as <code>_locker</code>, in the example prior) allows precise control over the scope and granularity of the lock. You can also use the containing object (<code>this</code>) as a synchronization object:</p>
<pre data-type="programlisting">lock (this) { ... }</pre>
<p>Or even its type:</p>
<pre data-type="programlisting">lock (typeof (Widget)) { ... }    // For protecting access to statics</pre>
<p>The disadvantage of locking in this way is that you’re not encapsulating the locking logic, so it becomes more difficult to prevent deadlocking and excessive blocking.</p>
<p>You can also lock on local variables captured by lambda expressions or anonymous methods.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>Locking doesn’t restrict access to the synchronizing object itself in any way. In other words, <code>x.ToString()</code> will not block because another thread has called <code>lock(x)</code>; both threads must call <code>lock(x)</code> in order for blocking to occur.</p>
</div>
</div></section>
<section data-pdf-bookmark="When to Lock" data-type="sect2"><div class="sect2" id="when_to_lock">
<h2>When to Lock</h2>
<p><a contenteditable="false" data-primary="exclusive locking" data-secondary="when to lock" data-type="indexterm" id="id4346"/>As a basic rule, you need to lock around accessing <em>any writable shared field</em>. Even in the simplest case—an assignment operation on a single field—you must consider synchronization. In the following class, neither the <code>Increment</code> nor the <code>Assign</code> method is thread-safe:</p>
<pre data-type="programlisting">class ThreadUnsafe
{
  static int _x;
  static void Increment() { _x++; }
  static void Assign()    { _x = 123; }
}</pre>
<p>Here are thread-safe versions of <code>Increment</code> and <code>Assign</code>:</p>
<pre data-type="programlisting">static readonly object _locker = new object();
static int _x;

static void Increment() { lock (_locker) _x++; }
static void Assign()    { lock (_locker) _x = 123; }</pre>
<p>Without locks, two problems can arise:</p>
<ul>
<li><p>Operations such as incrementing a variable (or even reading/writing a variable, under certain conditions) are not atomic.</p></li>
<li><p>The compiler, CLR, and processor are entitled to reorder instructions and <span class="keep-together">cache variables</span> in CPU registers to improve performance—as long as such optimizations don’t change the behavior of a <em>single</em>-threaded program (or a multithreaded program that uses locks).</p></li>
</ul>
<p><a contenteditable="false" data-primary="memory barrier" data-type="indexterm" id="id4347"/>Locking mitigates the second problem because it creates a <em>memory barrier</em> before and after the lock. A memory barrier is a “fence” through which the effects of reordering and caching cannot penetrate.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>This applies not just to locks but to all synchronization constructs. So, if your use of a <em>signaling</em> construct, for instance, ensures that just one thread reads/writes a variable at a time, you don’t need to lock. Hence, the following code is thread-safe without locking around <code>x</code>:</p>
<pre data-type="programlisting">var signal = new ManualResetEvent (false);
int x = 0;
new Thread (() =&gt; { x++; signal.Set(); }).Start();
signal.WaitOne();
Console.WriteLine (x);    // 1 <em>(always)</em></pre>
</div>
<p>In <a href="http://albahari.com/threading">“Nonblocking Synchronization”</a>, we explain how this need arises and how the memory barriers and the <code>Interlocked</code> class can provide alternatives to locking in these situations.</p>
</div></section>
<section data-pdf-bookmark="Locking and Atomicity" data-type="sect2"><div class="sect2" id="locking_and_atomicity">
<h2>Locking and Atomicity</h2>
<p><a contenteditable="false" data-primary="atomicity, locking and" data-type="indexterm" id="id4348"/><a contenteditable="false" data-primary="exclusive locking" data-secondary="locking and atomicity" data-type="indexterm" id="id4349"/>If a group of variables are always read and written within the same lock, you can say that the variables are read and written <em>atomically</em>. Let’s suppose that fields <code>x</code> and <code>y</code> are always read and assigned within a <code>lock</code> on object <code>locker</code>:</p>
<pre data-type="programlisting">lock (locker) { if (x != 0) y /= x; }</pre>
<p>We can say that <code>x</code> and <code>y</code> are accessed atomically because the code block cannot be divided or preempted by the actions of another thread in such a way that it will change <code>x</code> or <code>y</code> and <em>invalidate its outcome</em>. You’ll never get a division-by-zero error, provided that <code>x</code> and <code>y</code> are always accessed within this same exclusive lock.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>The atomicity provided by a lock is violated if an exception is thrown within a <code>lock</code> block (whether or not multithreading is involved). For example, consider the following:</p>
<pre data-type="programlisting">decimal _savingsBalance, _checkBalance;

void Transfer (decimal amount)
{
  lock (_locker)
  {
    _savingsBalance += amount;
    _checkBalance -= amount + GetBankFee();
  }
}</pre>
<p>If an exception were thrown by <code>GetBankFee()</code>, the bank would lose money. In this case, we could avoid the problem by calling <code>GetBankFee</code> earlier. A solution for more complex cases is to implement “rollback” logic within a <code>catch</code> or <code>finally</code> block.</p>
</div>
<p><a contenteditable="false" data-primary="instruction atomicity" data-type="indexterm" id="id4350"/><em>Instruction</em> atomicity is a different, albeit analogous, concept: an instruction is atomic if it executes indivisibly on the underlying processor.</p>
</div></section>
<section data-pdf-bookmark="Nested Locking" data-type="sect2"><div class="sect2" id="nested_locking">
<h2>Nested Locking</h2>
<p><a contenteditable="false" data-primary="exclusive locking" data-secondary="nested locking" data-type="indexterm" id="id4351"/><a contenteditable="false" data-primary="nested locking" data-type="indexterm" id="id4352"/>A thread can repeatedly lock the same object in a nested (<em>reentrant</em>) fashion:</p>
<pre data-type="programlisting">lock (locker)
  lock (locker)
    lock (locker)
    {
       // Do something...
    }</pre>
<p>Alternatively:</p>
<pre data-type="programlisting">Monitor.Enter (locker); Monitor.Enter (locker);  Monitor.Enter (locker); 
// Do something...
Monitor.Exit (locker);  Monitor.Exit (locker);   Monitor.Exit (locker);</pre>
<p>In these scenarios, the object is unlocked only when the outermost <code>lock</code> statement has exited—or a matching number of <code>Monitor.Exit</code> statements have executed.</p>
<p>Nested locking is useful when one method calls another from within a lock:</p>
<pre data-type="programlisting">object locker = new object();

<strong>lock (locker)</strong>
{
  AnotherMethod();
  // We still have the lock - because locks are reentrant.
}

void AnotherMethod()
{
  <strong>lock (locker)</strong> { Console.WriteLine ("Another method"); }
}</pre>
<p>A thread can block on only the first (outermost) lock.</p>
</div></section>
<section data-pdf-bookmark="Deadlocks" data-type="sect2"><div class="sect2" id="deadlocks">
<h2>Deadlocks</h2>
<p><a contenteditable="false" data-primary="exclusive locking" data-secondary="deadlocks" data-type="indexterm" id="id4353"/>A deadlock happens when two threads each wait for a resource held by the other, so neither can proceed. The easiest way to illustrate this is with two locks:</p>
<pre data-type="programlisting">object locker1 = new object();
object locker2 = new object();

new Thread (() =&gt; {
                    lock (locker1)
                    {
                      Thread.Sleep (1000);
                      <strong>lock (locker2);      // Deadlock</strong>
                    }
                  }).Start();
lock (locker2)
{
  Thread.Sleep (1000);
  <strong>lock (locker1);                          // Deadlock</strong>
}</pre>
<p>You can create more elaborate deadlocking chains with three or more threads.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p><a contenteditable="false" data-primary="CLR (Common Language Runtime)" data-secondary="deadlocks and" data-type="indexterm" id="id4354"/>The CLR, in a standard hosting environment, is not like SQL Server and does not automatically detect and resolve deadlocks by terminating one of the offenders. A threading deadlock causes participating threads to block indefinitely, unless you’ve specified a locking timeout. (Under the SQL CLR integration host, however, deadlocks <em>are</em> automatically detected, and a [catchable] exception is thrown on one of the threads.)</p>
</div>
<p>Deadlocking is one of the most difficult problems in multithreading—especially when there are many interrelated objects. Fundamentally, the hard problem is that you can’t be sure what locks your <em>caller</em> has taken out.</p>
<p>So, you might lock private field <code>a</code> within your class <code>x</code>, unaware that your caller (or caller’s caller) has already locked field <code>b</code> within class <code>y</code>. Meanwhile, another thread is doing the reverse—creating a deadlock. Ironically, the problem is exacerbated by (good) object-oriented design patterns, because such patterns create call chains that are not determined until runtime.</p>
<p>The popular advice “lock objects in a consistent order to prevent deadlocks,” although helpful in our initial example, is difficult to apply to the scenario just described. A better strategy is to be wary of locking around calls to methods in objects that might have references back to your own object. Also, consider whether you really need to lock around calls to methods in other classes (often you do—as you’ll see in <a data-type="xref" href="#locking_and_thread_safet">“Locking and Thread Safety”</a>—but sometimes there are other options). Relying more on higher-level synchronization options such as task continuations/combinators, data parallelism and immutable types (later in this chapter) can lessen the need for locking.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>Here is an alternative way to perceive the problem: when you call out to other code while holding a lock, the encapsulation of that lock subtly <em>leaks</em>. This is not a fault in the CLR; it’s a fundamental limitation of locking in general. The problems of locking are being addressed in various research projects, including <em>Software Transactional Memory</em>.</p>
</div>
<p>Another deadlocking scenario arises when calling <code>Dispatcher.Invoke</code> (in a WPF application) or <code>Control.Invoke</code> (in a Windows Forms application) while in possession of a lock. If the user interface happens to be running another method that’s waiting on the same lock, a deadlock will happen right there. You often can fix this simply by calling <code>BeginInvoke</code> instead of <code>Invoke</code> (or relying on asynchronous functions that do this implicitly when a synchronization context is present). Alternatively, you can release your lock before calling <code>Invoke</code>, although this won’t work if your <em>caller</em> took out the lock.</p>
</div></section>
<section data-pdf-bookmark="Performance" data-type="sect2"><div class="sect2" id="performance">
<h2>Performance</h2>
<p><a contenteditable="false" data-primary="exclusive locking" data-secondary="performance" data-type="indexterm" id="id4355"/>Locking is fast: you can expect to acquire and release a lock in less than 20 nanoseconds on a 2020-era computer if the lock is uncontended. If it is contended, the consequential context switch moves the overhead closer to the microsecond region, although it can be longer before the thread is actually rescheduled.</p>
</div></section>
<section data-pdf-bookmark="Mutex" data-type="sect2"><div class="sect2" id="mutex">
<h2>Mutex</h2>
<p><a contenteditable="false" data-primary="exclusive locking" data-secondary="Mutex" data-type="indexterm" id="id4356"/><a contenteditable="false" data-primary="Mutex" data-type="indexterm" id="id4357"/>A <code>Mutex</code> is like a C# <code>lock</code>, but it can work across multiple processes. In other words, <code>Mutex</code> can be <em>computer-wide</em> as well as <em>application-wide</em>. Acquiring and releasing an uncontended <code>Mutex</code> takes around half a microsecond—more than 20 times slower than a <code>lock</code>.</p>
<p>With a <code>Mutex</code> class, you call the <code>WaitOne</code> method to lock and <code>ReleaseMutex</code> to unlock. Just as with the <code>lock</code> statement, a <code>Mutex</code> can be released only from the same thread that obtained it.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>If you forget to call <code>ReleaseMutex</code> and simply call <code>Close</code> or <code>Dispose</code>, an <code>AbandonedMutexException</code> will be thrown upon anyone else waiting upon that mutex.</p>
</div>
<p>A common use for a cross-process <code>Mutex</code> is to ensure that only one instance of a program can run at a time. Here’s how it’s done:</p>
<pre data-type="programlisting">// Naming a Mutex makes it available computer-wide. Use a name that's
// unique to your company and application (e.g., include your URL).

using var mutex = new Mutex (true, @"Global\oreilly.com OneAtATimeDemo");
// Wait a few seconds if contended, in case another instance
// of the program is still in the process of shutting down.

if (!mutex.WaitOne (TimeSpan.FromSeconds (3), false))
{
  Console.WriteLine ("Another instance of the app is running. Bye!");
  return;
}
try { RunProgram(); }
finally { mutex.ReleaseMutex (); }

void RunProgram()
{
  Console.WriteLine ("Running. Press Enter to exit");
  Console.ReadLine();
}</pre>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>If you’re running under Terminal Services or in separate Unix consoles, a computer-wide <code>Mutex</code> is ordinarily visible only to applications in the same session. To make it visible to all terminal server sessions, prefix its name with <em>Global\</em>, as shown in the example.<a contenteditable="false" data-primary="" data-startref="ch21.html3" data-type="indexterm" id="id4358"/><a contenteditable="false" data-primary="" data-startref="ch21.html2" data-type="indexterm" id="id4359"/></p>
</div>
</div></section>
</div></section>
<section data-pdf-bookmark="Locking and Thread Safety" data-type="sect1"><div class="sect1" id="locking_and_thread_safet">
<h1>Locking and Thread Safety</h1>
<p><a contenteditable="false" data-primary="locking" data-secondary="thread safety and" data-type="indexterm" id="ch21.html4"/><a contenteditable="false" data-primary="threading" data-secondary="locking and thread safety" data-type="indexterm" id="ch21.html5"/>A program or method is thread-safe if it can work correctly in any multithreading scenario. Thread safety is achieved primarily with locking and by reducing the possibilities for thread interaction.</p>
<p>General-purpose types are rarely thread-safe in their entirety, for the following <span class="keep-together">reasons</span>:</p>
<ul>
<li><p>The development burden in full thread safety can be significant, particularly if a type has many fields (each field is a potential for interaction in an arbitrarily multithreaded context).</p></li>
<li><p>Thread safety can entail a performance cost (payable, in part, whether or not the type is actually used by multiple threads).</p></li>
<li><p>A thread-safe type does not necessarily make the program using it thread-safe, and often the work involved in the latter makes the former redundant.</p></li>
</ul>
<p>Thread safety is thus usually implemented just where it needs to be in order to handle a specific multithreading scenario.</p>
<p>There are, however, a few ways to “cheat” and have large and complex classes run safely in a multithreaded environment. One is to sacrifice granularity by wrapping large sections of code—even access to an entire object—within a single exclusive lock, enforcing serialized access at a high level. This tactic is, in fact, essential if you want to use thread-unsafe third-party code (or most .NET types, for that matter) in a multithreaded context. The trick is simply to use the same exclusive lock to protect access to all properties, methods, and fields on the thread-unsafe object. The solution works well if the object’s methods all execute quickly (otherwise, there will be a lot of blocking).</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>Primitive types aside, few .NET types, when instantiated, are thread-safe for anything more than concurrent read-only access. The onus is on the developer to superimpose thread safety, typically with exclusive locks. (The collections in <span class="keep-together"><code>System.Collections.Concurrent</code></span> that we cover in <a data-type="xref" href="ch22.html#parallel_programming-id00071">Chapter 22</a> are an exception.)</p>
</div>
<p>Another way to cheat is to minimize thread interaction by minimizing shared data. This is an excellent approach and is used implicitly in “stateless” middle-tier application and web-page servers. Because multiple client requests can arrive simultaneously, the server methods they call must be thread-safe. A stateless design (popular for reasons of scalability) intrinsically limits the possibility of interaction because classes do not save data between requests. Thread interaction is then limited just to the static fields that you might choose to create, for such purposes as caching commonly used data in memory and in providing infrastructure services such as authentication and auditing.</p>
<p>Yet another solution (in rich-client applications) is to run code that accesses shared state on the UI thread. As we saw in <a data-type="xref" href="ch14.html#concurrency_and_asynchron">Chapter 14</a>, asynchronous functions make this easy.</p> 
<section data-pdf-bookmark="Thread Safety and .NET Types" data-type="sect2"><div class="sect2" id="thread_safety_and_dotnet_types">
<h2>Thread Safety and .NET Types</h2>
<p><a contenteditable="false" data-primary="locking" data-secondary="thread safety and .NET Core types" data-type="indexterm" id="ch21.html6"/>You can use locking to convert thread-unsafe code into thread-safe code. A good application of this is .NET: nearly all of its nonprimitive types are not thread-safe (for anything more than read-only access) when instantiated, and yet you can use them in multithreaded code if all access to any given object is protected via a lock. Here’s an example in which two threads simultaneously add an item to the same <code>List</code> collection and then enumerate the list:</p>
<pre data-type="programlisting">class ThreadSafe
{
  static List &lt;string&gt; _list = new List &lt;string&gt;();

  static void Main()
  {
    new Thread (AddItem).Start();
    new Thread (AddItem).Start();
  }

  static void AddItem()
  {
    lock (_list) _list.Add ("Item " + _list.Count);

    string[] items;
    lock (_list) items = _list.ToArray();
    foreach (string s in items) Console.WriteLine (s);
  }
}</pre>
<p>In this case, we’re locking on the <code>_list</code> object itself. If we had two interrelated lists, we would need to choose a common object upon which to lock (we could nominate one of the lists, or better: use an independent field).</p>
<p>Enumerating .NET collections is also thread-unsafe in the sense that an exception is thrown if the list is modified during enumeration. Rather than locking for the duration of enumeration, in this example, we first copy the items to an array. This avoids holding the lock excessively if what we’re doing during enumeration is potentially time-consuming. (Another solution is to use a reader/writer lock; see <a data-type="xref" href="#readersoliduswriter_locks">“Reader/Writer Locks”</a>.)</p>
<section data-pdf-bookmark="Locking around thread-safe objects" data-type="sect3"><div class="sect3" id="locking_around_thread_safe_objects">
<h3>Locking around thread-safe objects</h3>
<p><a contenteditable="false" data-primary="locking" data-secondary="locking around thread-safe objects" data-type="indexterm" id="id4360"/><a contenteditable="false" data-primary="thread-safe objects" data-type="indexterm" id="id4361"/>Sometimes, you also need to lock around accessing thread-safe objects. To illustrate, imagine that .NET’s <code>List</code> class was, indeed, thread-safe, and we want to add an item to a list:</p>
<pre data-type="programlisting">if (!_list.Contains (newItem)) _list.Add (newItem);</pre>
<p>Regardless of whether the list was thread-safe, this statement is certainly not! The whole <code>if</code> statement would need to be wrapped in a lock to prevent preemption in between testing for containership and adding the new item. This same lock would then need to be used everywhere we modified that list. For instance, the following statement would also need to be wrapped in the identical lock to ensure that it did not preempt the former statement:</p>
<pre data-type="programlisting">_list.Clear();</pre>
<p>In other words, we would need to lock exactly as with our thread-unsafe collection classes (making the <code>List</code> class’s hypothetical thread safety redundant).</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>Locking around accessing a collection can cause excessive blocking in highly concurrent environments. To this end, .NET provides a thread-safe queue, stack, and dictionary, which we discuss in <a data-type="xref" href="ch22.html#parallel_programming-id00071">Chapter 22</a>.</p>
</div>
</div></section>
<section data-pdf-bookmark="Static members" data-type="sect3"><div class="sect3" id="static_members">
<h3>Static members</h3>
<p><a contenteditable="false" data-primary="locking" data-secondary="static members" data-type="indexterm" id="id4362"/><a contenteditable="false" data-primary="static members" data-secondary="locking" data-type="indexterm" id="id4363"/>Wrapping access to an object around a custom lock works only if all concurrent threads are aware of—and use—the lock. This might not be the case if the object is widely scoped. The worst case is with static members in a public type. For instance, imagine if the static property on the <code>DateTime</code> struct, <code>DateTime.Now</code>, was not thread-safe and that two concurrent calls could result in garbled output or an exception. The only way to remedy this with external locking might be to lock the type itself—<code>lock(typeof(DateTime))</code>—before calling <code>DateTime.Now</code>. This would work only if all programmers agreed to do this (which is unlikely). Furthermore, locking a type creates problems of its own.</p>
<p>For this reason, static members on the <code>DateTime</code> struct have been carefully programmed to be thread-safe. This is a common pattern throughout .NET: <em>static members are thread-safe; instance members are not.</em> Following this pattern also makes sense when writing types for public consumption, so as not to create impossible thread-safety conundrums. In other words, by making static methods thread-safe, you’re programming so as not to <em>preclude</em> thread safety for consumers of that type.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>Thread safety in static methods is something that you must explicitly code: it doesn’t happen automatically by virtue of the method being static!</p>
</div>
</div></section>
<section data-pdf-bookmark="Read-only thread safety" data-type="sect3"><div class="sect3" id="read_only_thread_safety">
<h3>Read-only thread safety</h3>
<p><a contenteditable="false" data-primary="locking" data-secondary="read-only thread safety" data-type="indexterm" id="id4364"/>Making types thread-safe for concurrent read-only access (where possible) is advantageous because it means that consumers can avoid excessive locking. Many .NET types follow this principle: collections, for instance, are thread-safe for concurrent readers.</p>
<p>Following this principle yourself is simple: if you document a type as being thread-safe for concurrent read-only access, don’t write to fields within methods that a consumer would expect to be read-only (or lock around doing so). For instance, in implementing a <code>ToArray()</code> method in a collection, you might begin by compacting the collection’s internal structure. However, this would make it thread-unsafe for consumers that expected this to be read-only.</p>
<p>Read-only thread safety is one of the reasons that enumerators are separate from “enumerables”: two threads can simultaneously enumerate over a collection because each gets a separate enumerator object.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>In the absence of documentation, it pays to be cautious in assuming whether a method is read-only in nature. A good example is the <code>Random</code> class: when you call <code>Random.Next()</code>, its internal implementation requires that it update private seed values. Therefore, you must either lock around using the <code>Random</code> class or maintain a separate instance per thread.<a contenteditable="false" data-primary="" data-startref="ch21.html6" data-type="indexterm" id="id4365"/></p>
</div>
</div></section>
</div></section>
<section data-pdf-bookmark="Thread Safety in Application Servers" data-type="sect2"><div class="sect2" id="thread_safety_in_application_servers">
<h2>Thread Safety in Application Servers</h2>
<p><a contenteditable="false" data-primary="application servers" data-type="indexterm" id="id4366"/><a contenteditable="false" data-primary="locking" data-secondary="thread safety in application servers" data-type="indexterm" id="id4367"/>Application servers need to be multithreaded to handle simultaneous client requests. ASP.NET Core and Web API applications are implicitly multithreaded. This means that when writing code on the server side, you must consider thread safety if there’s any possibility of interaction among the threads processing client requests. Fortunately, such a possibility is rare; a typical server class is either stateless (no fields) or has an activation model that creates a separate object instance for each client or each request. Interaction usually arises only through static fields, sometimes used for caching in memory parts of a database to improve performance.</p>
<p>For example, suppose that you have a <code>RetrieveUser</code> method that queries a database:</p>
<pre data-type="programlisting">// User is a custom class with fields for user data
internal User RetrieveUser (int id) { ... }</pre>
<p>If this method were called frequently, you could improve performance by caching the results in a static <code>Dictionary</code>. Here’s a conceptually simple solution that takes thread safety into account:</p>
<pre data-type="programlisting">static class UserCache
{
  static Dictionary &lt;int, User&gt; _users = new Dictionary &lt;int, User&gt;();

  internal static User GetUser (int id)
  {
    User u = null;

    lock (_users)
      if (_users.TryGetValue (id, out u))
        return u;

    u = RetrieveUser (id);           // Method to retrieve from database;
    lock (_users) _users [id] = u;
    return u;
  }
}</pre>
<p>We must, at a minimum, lock around reading and updating the dictionary to ensure thread safety. In this example, we choose a practical compromise between simplicity and performance in locking. Our design creates a small potential for inefficiency: if two threads simultaneously called this method with the same previously unretrieved <code>id</code>, the <code>RetrieveUser</code> method would be called twice—and the dictionary would be updated unnecessarily. Locking once across the whole method would prevent this, but it would create a worse inefficiency: the entire cache would be locked up for the duration of calling <code>RetrieveUser</code>, during which time other threads would be blocked in retrieving <em>any</em> user.</p>
<p>For an ideal solution, we need to use the strategy we described in <a data-type="xref" href="ch14.html#completing_synchronously">“Completing synchronously”</a>. Instead of caching <code>User</code>, we cache <code>Task&lt;User&gt;</code>, which the caller then awaits:</p>
<pre data-type="programlisting">static class UserCache
{
  static Dictionary &lt;int, <strong>Task&lt;User&gt;</strong>&gt; _userTasks = 
     new Dictionary &lt;int, Task&lt;User&gt;&gt;();
  
  internal static <strong>Task&lt;User&gt;</strong> GetUserAsync (int id)
  {
    lock (_userTasks)
      if (_userTasks.TryGetValue (id, out var userTask))
        return userTask;
      else
        return <strong>_userTasks [id] = Task.Run (() =&gt; RetrieveUser (id))</strong>;
  }
}</pre>
<p>Notice that we now have a single lock that covers the entire method’s logic. We can do this without hurting concurrency because all we’re doing inside the lock is accessing the dictionary and (potentially) <em>initiating</em> an asynchronous operation (by calling <code>Task.Run</code>). Should two threads call this method at the same time with the same ID, they’ll both end up awaiting the <em>same task</em>, which is exactly the outcome we want.</p>
</div></section>
<section data-pdf-bookmark="Immutable Objects" data-type="sect2"><div class="sect2" id="immutable_objects">
<h2>Immutable Objects</h2>
<p><a contenteditable="false" data-primary="immutable objects" data-type="indexterm" id="id4368"/><a contenteditable="false" data-primary="locking" data-secondary="immutable objects" data-type="indexterm" id="id4369"/>An immutable object is one whose state cannot be altered—externally or internally. The fields in an immutable object are typically declared read-only and are fully initialized during construction.</p>
<p>Immutability is a hallmark of functional programming—where instead of <em>mutating</em> an object, you create a new object with different properties. LINQ follows this paradigm. Immutability is also valuable in multithreading in that it avoids the problem of shared writable state—by eliminating (or minimizing) the writable.</p>
<p>One pattern is to use immutable objects to encapsulate a group of related fields, to minimize lock durations. To take a very simple example, suppose that we had two fields, as follows:</p>
<pre data-type="programlisting">int _percentComplete;
string _statusMessage;</pre>
<p>Now let’s assume that we want to read and write them atomically. Rather than locking around these fields, we could define the following immutable class:</p>
<pre data-type="programlisting">class ProgressStatus    // Represents progress of some activity
{
  public <strong>readonly</strong> int PercentComplete;
  public <strong>readonly</strong> string StatusMessage;

  // This class might have many more fields...

  public ProgressStatus (int percentComplete, string statusMessage)
  {
    PercentComplete = percentComplete;
    StatusMessage = statusMessage;
  }
}</pre>
<p>Then we could define a single field of that type, along with a locking object:</p>
<pre data-type="programlisting">readonly object _statusLocker = new object();
ProgressStatus _status;</pre>
<p>We can now read and write values of that type without holding a lock for more than a single assignment:<a contenteditable="false" data-primary="" data-startref="ch21.html5" data-type="indexterm" id="id4370"/><a contenteditable="false" data-primary="" data-startref="ch21.html4" data-type="indexterm" id="id4371"/></p>
<pre data-type="programlisting">var status = new ProgressStatus (50, "Working on it");
// Imagine we were assigning many more fields...
// ...
<strong>lock (_statusLocker) _status = status;    // Very brief lock</strong></pre>
<p>To read the object, we first obtain a copy of the object reference (within a lock). Then, we can read its values without needing to hold onto the lock:</p>
<pre data-type="programlisting">ProgressStatus status;
<strong>lock (_statusLocker) status = _status;   // Again, a brief lock</strong>
int pc = status.PercentComplete;
string msg = status.StatusMessage;
...</pre>
</div></section>
</div></section>
<section data-pdf-bookmark="Nonexclusive Locking" data-type="sect1"><div class="sect1" id="nonexclusive_locking">
<h1>Nonexclusive Locking</h1>
<p><a contenteditable="false" data-primary="nonexclusive locking" data-type="indexterm" id="ch21.html7"/><a contenteditable="false" data-primary="threading" data-secondary="nonexclusive locking" data-type="indexterm" id="ch21.html8"/>The nonexclusive locking constructs serve to <em>limit</em> concurrency. In this section, we cover semaphores and read/writer locks, and also illustrate how the <code>SemaphoreSlim</code> class can limit concurrency with asynchronous operations.</p>
<section data-pdf-bookmark="Semaphore" data-type="sect2"><div class="sect2" id="semaphore">
<h2>Semaphore</h2>

<p><a contenteditable="false" data-primary="nonexclusive locking" data-secondary="semaphore" data-type="indexterm" id="ch21.html9"/><a contenteditable="false" data-primary="semaphore" data-type="indexterm" id="ch21.html10"/>A semaphore is like a nightclub with a limited capacity, enforced by a bouncer. When the club is full, no more people can enter, and a queue builds up outside.</p>

<p>A semaphore’s <em>count</em> corresponds to the number of spaces in the nightclub. <em>Releasing</em> a semaphore <em>increases</em> the count; this typically happens when somebody leaves the club (corresponding to a resource being released), and also when the semaphore is initialized (to set its starting capacity). You can also call <code>Release</code> at any time to increase capacity.</p>

<p>Waiting on a semaphore <em>decrements</em> the count, and typically occurs prior to a resource being obtained. Calling <code>Wait</code> on a semaphore whose current count is greater than <code>0</code> completes immediately.</p>

<p>A semaphore can optionally have a maximum count that serves as a hard limit. Increasing the count beyond this limit throws an exception. When constructing a semaphore, you specify the initial count (starting capacity), and optionally, a maximum limit.</p>


<p>A semaphore with an initial count of one is similar to a <code>Mutex</code> or <code>lock</code>, except that the semaphore has no “owner”—it’s <em>thread agnostic</em>. Any thread can call <code>Release</code> on a <code>Semaphore</code>, whereas with <code>Mutex</code> and <code>lock</code>, only the thread that obtained the lock can release it.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>There are two functionally similar versions of this class: <code>Semaphore</code> and <code>SemaphoreSlim</code>. The latter has been optimized to meet the low-latency demands of parallel programming. <a contenteditable="false" data-primary="cancellation tokens" data-type="indexterm" id="id4372"/>It’s also useful in traditional multithreading because it lets you specify a cancellation token when waiting (see <a data-type="xref" href="ch14.html#cancellation">“Cancellation”</a>), and it exposes a <code>WaitAsync</code> method for asynchronous programming. You cannot use it, however, for interprocess signaling.</p>
<p><code>Semaphore</code> incurs about one microsecond in calling <code>WaitOne</code> and <code>Release</code>; <code>SemaphoreSlim</code> incurs about one-tenth of that.</p>
</div>
<p>Semaphores can be useful in limiting concurrency—preventing too many threads from executing a particular piece of code at once. In the following example, five threads try to enter a nightclub that allows only three threads in at once:</p>
<pre data-type="programlisting">class TheClub      // No door lists!
{
  static SemaphoreSlim _sem = new SemaphoreSlim (3);    // Capacity of 3
 
  static void Main()
  {
    for (int i = 1; i &lt;= 5; i++) new Thread (Enter).Start (i);
  }

  static void Enter (object id)
  {
    Console.WriteLine (id + " wants to enter");
    <strong>_sem.Wait();</strong>
    Console.WriteLine (id + " is in!");           // Only three threads
    Thread.Sleep (1000 * (int) id);               // can be here at
    Console.WriteLine (id + " is leaving");       // a time.
    <strong>_sem.Release();</strong>
  }
}

1 wants to enter
1 is in!
2 wants to enter
2 is in!
3 wants to enter
3 is in!
4 wants to enter
5 wants to enter
1 is leaving
4 is in!
2 is leaving
5 is in!</pre>

<p>It’s also legal to instantiate a semaphore with an initial count (capacity) of 0 and then call <code>Release</code> to increase its count. The following two semaphores are <span class="keep-together">equivalent</span>:</p>

<pre data-type="programlisting">var semaphore1 = new SemaphoreSlim (3);
var semaphore2 = new SemaphoreSlim (0); semaphore2.Release (3);</pre>


<p>A <code>Semaphore</code>, if named, can span processes in the same way as a <code>Mutex</code> (named <code>Semaphore</code>s are available only on Windows, whereas named <code>Mutex</code> also work on Unix platforms).</p>
<section class="pagebreak-before" data-pdf-bookmark="Asynchronous semaphores and locks" data-type="sect3"><div class="sect3" id="asynchronous_semaphores_and_locks">
<h3 class="less_space">Asynchronous semaphores and locks</h3>
<p><a contenteditable="false" data-primary="await expressions" data-secondary="locking and" data-type="indexterm" id="id4373"/><a contenteditable="false" data-primary="semaphore" data-secondary="asynchronous semaphores and locks" data-type="indexterm" id="id4374"/>It is illegal to lock across an <code>await</code> statement:</p>
<pre data-type="programlisting">lock (_locker)
{
  await Task.Delay (1000);    // Compilation error
  ...
}</pre>
<p>Doing so would make no sense, because locks are held by a thread, which typically changes when returning from an await. Locking also <em>blocks</em>, and blocking for a potentially long period of time is exactly what you’re <em>not</em> trying to achieve with asynchronous functions.</p>
<p>It’s still sometimes desirable, however, to make asynchronous operations execute sequentially—or limit the parallelism such that not more than <em>n</em> operations execute at once. For example, consider a web browser: it needs to perform asynchronous downloads in parallel, but it might want to impose a limit such that a maximum of 10 downloads happen at a time. We can achieve this by using a <code>SemaphoreSlim</code>:</p>
<pre data-type="programlisting">SemaphoreSlim _semaphore = new SemaphoreSlim (10);

async Task&lt;byte[]&gt; DownloadWithSemaphoreAsync (string uri)
{
    await <strong>_semaphore.WaitAsync()</strong>;
    try { return await new WebClient().DownloadDataTaskAsync (uri); }
    finally { <strong>_semaphore.Release();</strong> }
}</pre>
<p>Reducing the semaphore’s <code>initialCount</code> to <code>1</code> reduces the maximum parallelism to 1, turning this into an asynchronous lock.</p>
</div></section>
<section data-pdf-bookmark="Writing an EnterAsync extension method" data-type="sect3"><div class="sect3" id="writing_an_enterasync_extension_method">
<h3>Writing an EnterAsync extension method</h3>
<p><a contenteditable="false" data-primary="EnterAsync extension method" data-type="indexterm" id="id4375"/><a contenteditable="false" data-primary="extension methods" data-secondary="EnterAsync" data-type="indexterm" id="id4376"/><a contenteditable="false" data-primary="semaphore" data-secondary="writing an EnterAsync extension method" data-type="indexterm" id="id4377"/>The following extension method simplifies the asynchronous use of <code>SemaphoreSlim</code> by using the <code>Disposable</code> class that we wrote in <a data-type="xref" href="ch12.html#anonymous_disposal">“Anonymous Disposal”</a>:<a contenteditable="false" data-primary="" data-startref="ch21.html10" data-type="indexterm" id="id4378"/><a contenteditable="false" data-primary="" data-startref="ch21.html9" data-type="indexterm" id="id4379"/></p>
<pre data-type="programlisting">public static async Task&lt;IDisposable&gt; EnterAsync (this SemaphoreSlim ss)
{
  await ss.WaitAsync().ConfigureAwait (false);
  return Disposable.Create (() =&gt; ss.Release());
}</pre>
<p>With this method, we can rewrite our <code>DownloadWithSemaphoreAsync</code> method as <span class="keep-together">follows</span>:</p>
<pre data-type="programlisting">async Task&lt;byte[]&gt; DownloadWithSemaphoreAsync (string uri)
{
  using (await _semaphore.EnterAsync())
    return await new WebClient().DownloadDataTaskAsync (uri);
}</pre>
</div></section>
<section data-pdf-bookmark="Parallel.ForEachAsync" data-type="sect3"><div class="sect3" id="ParallelForEachAsync">
<h3>Parallel.ForEachAsync</h3>

<p>From .NET 6, another approach to limit asynchronous concurrency is to use the <code>Parallel.ForEachAsync</code> method. Assuming <code>uris</code> in an array of URIs that you wish to download, here’s how to download them in parallel, while limiting the concurrency to a maximum of 10 parallel downloads:</p>

<pre data-type="programlisting">await Parallel.ForEachAsync (uris,
  new ParallelOptions { MaxDegreeOfParallelism = 10 },
  async (uri, cancelToken) =&gt;
   {
    var download = await new HttpClient().GetByteArrayAsync (uri);
    Console.WriteLine ($"Downloaded {download.Length} bytes");
  });</pre>
  
<p>The other methods in the Parallel class are intended for (compute-bound) parallel programming scenarios, which we describe in <a data-type="xref" href="ch22.html#parallel_programming-id00071">Chapter 22</a>.</p>

</div></section>
</div></section>
<section data-pdf-bookmark="Reader/Writer Locks" data-type="sect2"><div class="sect2" id="readersoliduswriter_locks">
<h2>Reader/Writer Locks</h2>
<p><a contenteditable="false" data-primary="ReaderWriterLockSlim" data-type="indexterm" id="ch21.html11"/>Quite <a contenteditable="false" data-primary="nonexclusive locking" data-secondary="reader/writer locks" data-type="indexterm" id="ch21.html12"/><a contenteditable="false" data-primary="read locks" data-type="indexterm" id="ch21.html13"/><a contenteditable="false" data-primary="write locks" data-type="indexterm" id="ch21.html14"/>often, instances of a type are thread-safe for concurrent read operations, but not for concurrent updates (nor for a concurrent read and update). This can also be true with resources such as a file. Although protecting instances of such types with a simple exclusive lock for all modes of access usually does the trick, it can unreasonably restrict concurrency if there are many readers and just occasional updates. An example of where this could occur is in a business application server, for which commonly used data is cached for fast retrieval in static fields. The <code>ReaderWriterLockSlim</code> class is designed to provide maximum-availability locking in just this <span class="keep-together">scenario</span>.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p><code>ReaderWriterLockSlim</code> is a replacement for the older “fat” <code>ReaderWriterLock</code> class. The latter is similar in functionality, but it is several times slower and has an inherent design fault in its mechanism for handling lock upgrades.</p>
<p>When compared to an ordinary <code>lock</code> (<code>Monitor.Enter</code>/<code>Exit</code>), <code>ReaderWriterLockSlim</code> is still twice as slow, though. The trade-off is less contention (when there’s a lot of reading and minimal writing).</p>
</div>
<p>With both classes, there are two basic kinds of lock—a read lock and a write lock:</p>
<ul>
<li><p>A write lock is universally exclusive.</p></li>
<li><p>A read lock is compatible with other read locks.</p></li>
</ul>
<p>So, a thread holding a write lock blocks all other threads trying to obtain a read <em>or</em> write lock (and vice versa). But if no thread holds a write lock, any number of threads may concurrently obtain a read lock.</p>
<p class="pagebreak-before"><code>ReaderWriterLockSlim</code> defines the following methods for obtaining and releasing read/write locks:</p>
<pre data-type="programlisting">public void EnterReadLock();
public void ExitReadLock();
public void EnterWriteLock();
public void ExitWriteLock();</pre>
<p>Additionally, there are “Try” versions of all <code>Enter<em>XXX</em></code> methods that accept timeout arguments in the style of <code>Monitor.TryEnter</code> (timeouts can occur quite easily if the resource is heavily contended). <code>ReaderWriterLock</code> provides similar methods, named <code>Acquire<em>XXX</em></code> and <code>Release<em>XXX</em></code>. These throw an <code>ApplicationException</code> if a timeout occurs, rather than returning <code>false</code>.</p>
<p>The following program demonstrates <code>ReaderWriterLockSlim</code>. Three threads continually enumerate a list, while two further threads append a random number to the list every 100 ms. A read lock protects the list readers, and a write lock protects the list writers:</p>
<pre data-type="programlisting">class SlimDemo
{
  <strong>static ReaderWriterLockSlim _rw = new ReaderWriterLockSlim();</strong>
  static List&lt;int&gt; _items = new List&lt;int&gt;();
  static Random _rand = new Random();

  static void Main()
  {
    new Thread (Read).Start();
    new Thread (Read).Start();
    new Thread (Read).Start();

    new Thread (Write).Start ("A");
    new Thread (Write).Start ("B");
  }

  static void Read()
  {
    while (true)
    {
      <strong>_rw.EnterReadLock();</strong>
      foreach (int i in _items) Thread.Sleep (10);
      <strong>_rw.ExitReadLock();</strong>
    }
  }

  static void Write (object threadID)
  {
    while (true)
    {
      int newNumber = GetRandNum (100);
      <strong>_rw.EnterWriteLock();</strong>
      _items.Add (newNumber);
      <strong>_rw.ExitWriteLock();</strong>
      Console.WriteLine ("Thread " + threadID + " added " + newNumber);
      Thread.Sleep (100);
    }
  }

  static int GetRandNum (int max) { lock (_rand) return _rand.Next(max); }
}</pre>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>In production code, you’d typically add <code>try</code>/<code>finally</code> blocks to ensure that locks were released if an exception were thrown.</p>
</div>
<p>Here’s the result:</p>
<pre data-type="programlisting">Thread B added 61
Thread A added 83
Thread B added 55
Thread A added 33
...</pre>
<p><code>ReaderWriterLockSlim</code> allows more concurrent <code>Read</code> activity than a simple lock. We can illustrate this by inserting the following line in the <code>Write</code> method, at the start of the <code>while</code> loop:</p>
<pre data-type="programlisting">Console.WriteLine (_rw.CurrentReadCount + " concurrent readers");</pre>
<p>This nearly always prints “3 concurrent readers” (the <code>Read</code> methods spend most of their time inside the <code>foreach</code> loops). As well as <code>CurrentReadCount</code>, <code>ReaderWriterLockSlim</code> provides the following properties for monitoring locks:</p>
<pre data-type="programlisting">public bool IsReadLockHeld            { get; }
public bool IsUpgradeableReadLockHeld { get; }
public bool IsWriteLockHeld           { get; }

public int  WaitingReadCount          { get; }
public int  WaitingUpgradeCount       { get; }
public int  WaitingWriteCount         { get; }

public int  RecursiveReadCount        { get; }
public int  RecursiveUpgradeCount     { get; }
public int  RecursiveWriteCount       { get; }</pre>
<section data-pdf-bookmark="Upgradeable locks" data-type="sect3"><div class="sect3" id="upgradeable_locks">
<h3>Upgradeable locks</h3>
<p><a contenteditable="false" data-primary="nonexclusive locking" data-secondary="upgradeable locks" data-type="indexterm" id="ch21.html15"/><a contenteditable="false" data-primary="upgradeable locks" data-type="indexterm" id="ch21.html16"/>Sometimes, it’s useful to swap a read lock for a write lock in a single atomic operation. For instance, suppose that you want to add an item to a list only if the item wasn’t already present. Ideally, you’d want to minimize the time spent holding the (exclusive) write lock, so you might proceed as follows:</p>
<ol>
<li><p>Obtain a read lock.</p></li>
<li><p>Test whether the item is already present in the list; if so, release the lock and <code>return</code>.</p></li>
<li><p>Release the read lock.</p></li>
<li><p>Obtain a write lock.</p></li>
<li><p>Add the item.</p></li>
</ol>
<p>The problem is that another thread could sneak in and modify the list (e.g., adding the same item) between Steps 3 and 4. <code>ReaderWriterLockSlim</code> addresses this through a third kind of lock called an <em>upgradeable lock</em>. An upgradeable lock is like a read lock except that it can later be promoted to a write lock in an atomic operation. Here’s how you use it:</p>
<ol>
<li><p>Call <code>EnterUpgradeableReadLock</code>.</p></li>
<li><p>Perform read-based activities (e.g., test whether the item is already present in the list).</p></li>
<li><p>Call <code>EnterWriteLock</code> (this converts the upgradeable lock to a write lock).</p></li>
<li><p>Perform write-based activities (e.g., add the item to the list).</p></li>
<li><p>Call <code>ExitWriteLock</code> (this converts the write lock back to an upgradeable lock).</p></li>
<li><p>Perform any other read-based activities.</p></li>
<li><p>Call <code>ExitUpgradeableReadLock</code>.</p></li>
</ol>
<p>From the caller’s perspective, it’s rather like nested or recursive locking. Functionally, though, in Step 3, <code>ReaderWriterLockSlim</code> releases your read lock and obtains a fresh write lock, atomically.</p>
<p>There’s another important difference between upgradeable locks and read locks. Although an upgradeable lock can coexist with any number of <em>read</em> locks, only one upgradeable lock can itself be taken out at a time. This prevents conversion deadlocks by <em>serializing</em> competing conversions—just as update locks do in SQL Server:</p>
<table class="border">
<thead>
<tr>
<th>SQL Server</th>
<th>ReaderWriterLockSlim</th>
</tr>
</thead>
<tbody>
<tr>
<td>Share lock</td>
<td>Read lock</td>
</tr>
<tr>
<td>Exclusive lock</td>
<td>Write lock</td>
</tr>
<tr>
<td>Update lock</td>
<td>Upgradeable lock</td>
</tr>
</tbody>
</table>
<p>We can demonstrate an upgradeable lock by changing the <code>Write</code> method in the preceding example such that it adds a number to the list only if it’s not already present:</p>
<pre data-type="programlisting">while (true)
{
  int newNumber = GetRandNum (100);
  <strong>_rw.EnterUpgradeableReadLock();</strong>
  if (!_items.Contains (newNumber))
  {
    <strong>_rw.EnterWriteLock();</strong>
    _items.Add (newNumber);
    <strong>_rw.ExitWriteLock();</strong>
    Console.WriteLine ("Thread " + threadID + " added " + newNumber);
  }
  <strong>_rw.ExitUpgradeableReadLock();</strong>
  Thread.Sleep (100);
}</pre>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p><code>ReaderWriterLock</code> can also do lock conversions—but unreliably because it doesn’t support the concept of upgradeable locks. This is why the designers of <code>ReaderWriterLockSlim</code> had to start afresh with a new class.</p>
</div>
</div></section>
<section data-pdf-bookmark="Lock recursion" data-type="sect3"><div class="sect3" id="lock_recursion">
<h3>Lock recursion</h3>
<p><a contenteditable="false" data-primary="nonexclusive locking" data-secondary="lock recursion" data-type="indexterm" id="id4380"/><a contenteditable="false" data-primary="recursive locking" data-type="indexterm" id="id4381"/>Ordinarily, nested or recursive locking is prohibited with <code>ReaderWriterLockSlim</code>. Hence, the following throws an exception:</p>
<pre data-type="programlisting">var rw = new ReaderWriterLockSlim();
rw.EnterReadLock();
rw.EnterReadLock();
rw.ExitReadLock();
rw.ExitReadLock();</pre>
<p>It runs without error, however, if you construct <code>ReaderWriterLockSlim</code> as follows:</p>
<pre data-type="programlisting">var rw = new ReaderWriterLockSlim (<strong>LockRecursionPolicy.SupportsRecursion</strong>);</pre>
<p>This ensures that recursive locking can happen only if you plan for it. Recursive locking can create undesired complexity because it’s possible to acquire more than one kind of lock:</p>
<pre data-type="programlisting">rw.EnterWriteLock();
rw.EnterReadLock();
Console.WriteLine (rw.IsReadLockHeld);     // True
Console.WriteLine (rw.IsWriteLockHeld);    // True
rw.ExitReadLock();
rw.ExitWriteLock();</pre>
<p>The basic rule is that after you’ve acquired a lock, subsequent recursive locks can be less, but not greater, on the following scale:</p>
<blockquote>
<p>Read Lock→Upgradeable Lock→Write Lock</p>
</blockquote>
<p>A request to promote an upgradeable lock to a write lock, however, is always<a contenteditable="false" data-primary="" data-startref="ch21.html15" data-type="indexterm" id="id4382"/><a contenteditable="false" data-primary="" data-startref="ch21.html14" data-type="indexterm" id="id4383"/> legal<a contenteditable="false" data-primary="" data-startref="ch21.html13" data-type="indexterm" id="id4384"/><a contenteditable="false" data-primary="" data-startref="ch21.html12" data-type="indexterm" id="id4385"/><a contenteditable="false" data-primary="" data-startref="ch21.html11" data-type="indexterm" id="id4386"/>.<a contenteditable="false" data-primary="" data-startref="ch21.html8" data-type="indexterm" id="id4387"/><a contenteditable="false" data-primary="" data-startref="ch21.html7" data-type="indexterm" id="id4388"/></p>
</div></section>
</div></section>
</div></section>
<section data-pdf-bookmark="Signaling with Event Wait Handles" data-type="sect1"><div class="sect1" id="signaling_with_event_wait_handles">
<h1>Signaling with Event Wait Handles</h1>
<p><a contenteditable="false" data-primary="event wait handles" data-type="indexterm" id="ch21.html17"/><a contenteditable="false" data-primary="event wait handles" data-secondary="signaling with" data-type="indexterm" id="ch21.html18"/><a contenteditable="false" data-primary="signaling" data-secondary="event wait handles for" data-type="indexterm" id="ch21.html19"/><a contenteditable="false" data-primary="threading" data-secondary="signaling with event wait handles" data-type="indexterm" id="ch21.html20"/>The simplest kind of signaling constructs are called <em>event wait handles</em> (unrelated to C# events). Event wait handles come in three flavors: <code>AutoResetEvent</code>, <code>Manual​Re⁠setEvent</code>(<code>Slim</code>), and <code>CountdownEvent</code>. The former two are based on the common <code>EventWaitHandle</code> class from which they derive all their functionality.</p>
<section data-pdf-bookmark="AutoResetEvent" data-type="sect2"><div class="sect2" id="autoresetevent">
<h2>AutoResetEvent</h2>
<p><a contenteditable="false" data-primary="AutoResetEvent" data-type="indexterm" id="ch21.html21"/><a contenteditable="false" data-primary="event wait handles" data-secondary="AutoResetEvent" data-type="indexterm" id="ch21.html22"/>An <code>AutoResetEvent</code> is like a ticket turnstile: inserting a ticket lets exactly one person through. The “auto” in the class’s name refers to the fact that an open turnstile automatically closes or “resets” after someone steps through. A thread waits, or blocks, at the turnstile by calling <code>WaitOne</code> (wait at this “one” turnstile until it opens), and a ticket is inserted by calling the <code>Set</code> method. If a number of threads call <code>WaitOne</code>, a queue<sup><a data-type="noteref" href="ch21.html#ch01fn16" id="ch01fn16-marker">2</a></sup> builds up behind the turnstile. A ticket can come from any thread; in other words, any (unblocked) thread with access to the <code>AutoResetEvent</code> object can call <code>Set</code> on it to release one blocked thread.</p>
<p>You can create an <code>AutoResetEvent</code> in two ways. The first is via its constructor:</p>
<pre data-type="programlisting">var auto = new AutoResetEvent (false);</pre>
<p>(Passing <code>true</code> into the constructor is equivalent to immediately calling <code>Set</code> upon it.) The second way to create an <code>AutoResetEvent</code> is as follows:</p>
<pre data-type="programlisting">var auto = new EventWaitHandle (false, EventResetMode.AutoReset);</pre>
<p>In the following example, a thread is started whose job is simply to wait until signaled by another thread (see <a data-type="xref" href="#signaling_with_an_eventwaithandle">Figure 21-1</a>):</p>
<pre data-type="programlisting">class BasicWaitHandle
{
  static EventWaitHandle _waitHandle = new AutoResetEvent (false);

  static void Main()
  {
    new Thread (Waiter).Start();
    Thread.Sleep (1000);                  // Pause for a second...
    _waitHandle.Set();                    // Wake up the Waiter.
  }

  static void Waiter()
  {
    Console.WriteLine ("Waiting...");
    _waitHandle.WaitOne();                // Wait for notification
    Console.WriteLine ("Notified");
  }
}

// Output:
Waiting... <em>(pause)</em> Notified.</pre>
<figure><div class="figure" id="signaling_with_an_eventwaithandle">
<img alt="Signaling with an EventWaitHandle" src="assets/cn10_2101.png"/>
<h6><span class="label">Figure 21-1. </span>Signaling with an <code>EventWaitHandle</code></h6>
</div></figure>
<p>If <code>Set</code> is called when no thread is waiting, the handle stays open for as long as it takes until some thread calls <code>WaitOne</code>. This behavior helps prevent a race between a thread heading for the turnstile and a thread inserting a ticket (“Oops, inserted the ticket a microsecond too soon; now you’ll have to wait indefinitely!”). However, calling <code>Set</code> repeatedly on a turnstile at which no one is waiting doesn’t allow an entire party through when they arrive: only the next single person is let through, and the extra tickets are “wasted.”</p>
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="disposing_wait_handles">
<h1>Disposing Wait Handles</h1>
<p><a contenteditable="false" data-primary="disposal" data-secondary="wait handles" data-type="indexterm" id="id4389"/><a contenteditable="false" data-primary="event wait handles" data-secondary="disposal" data-type="indexterm" id="id4390"/>After you’ve finished with a wait handle, you can call its <code>Close</code> method to release the OS resource. Alternatively, you can simply drop all references to the wait handle and allow the garbage collector to do the job for you sometime later (wait handles implement the disposal pattern whereby the finalizer calls <code>Close</code>). This is one of the few scenarios for which relying on this backup is (arguably) acceptable, because wait handles have a light OS burden.</p>
<p>Wait handles are released automatically when a process exits.</p>
</div></aside>
<p>Calling <code>Reset</code> on an <code>AutoResetEvent</code> closes the turnstile (should it be open) without waiting or blocking.</p>
<p><code>WaitOne</code> accepts an optional timeout parameter, returning <code>false</code> if the wait ended because of a timeout rather than obtaining the signal.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>Calling <code>WaitOne</code> with a timeout of <code>0</code> tests whether a wait handle is “open,” without blocking the caller. Keep in mind, though, that doing this resets the <code>AutoResetEvent</code> if it’s open.</p>
</div>
<section class="pagebreak-before" data-pdf-bookmark="Two-way signaling" data-type="sect3"><div class="sect3" id="two_way_signaling-id00120">
<h3 class="less_space">Two-way signaling</h3>
<p><a contenteditable="false" data-primary="signaling" data-secondary="two-way" data-type="indexterm" id="id4391"/>Suppose that we want the main thread to signal a worker thread three times in a row. If the main thread simply calls <code>Set</code> on a wait handle several times in rapid succession, the second or third signal can become lost because the worker might take time to process each signal.</p>
<p>The solution is for the main thread to wait until the worker’s ready before signaling it. We can do this by using another <code>AutoResetEvent</code>, as follows:</p>
<pre data-type="programlisting">class TwoWaySignaling
{
  static EventWaitHandle _ready = new AutoResetEvent (false);
  static EventWaitHandle _go = new AutoResetEvent (false);
  static readonly object _locker = new object();
  static string _message;

  static void Main()
  {
    new Thread (Work).Start();

    <strong>_ready.WaitOne();</strong>                  // First wait until worker is ready
    lock (_locker) _message = "ooo";
    <strong>_go.Set();</strong>                         // Tell worker to go

<strong>    _ready.WaitOne();</strong>
    lock (_locker) _message = "ahhh";  // Give the worker another message
<strong>    _go.Set();</strong>

<strong>    _ready.WaitOne();</strong>
    lock (_locker) _message = null;    // Signal the worker to exit
<strong>    _go.Set();</strong>
  }

  static void Work()
  {
    while (true)
    {
      <strong>_ready.Set();</strong>                          // Indicate that we're ready
      <strong>_go.WaitOne();</strong>                         // Wait to be kicked off...
      lock (_locker)
      {
        if (_message == null) return;        // Gracefully exit
        Console.WriteLine (_message);
      }
    }
  }
}

// Output:
ooo
ahhh</pre>
<p><a data-type="xref" href="#two_way_signaling">Figure 21-2</a> shows this process.</p>
<figure><div class="figure" id="two_way_signaling">
<img alt="Two-way signaling" src="assets/cn10_2102.png"/>
<h6><span class="label">Figure 21-2. </span>Two-way signaling</h6>
</div></figure>
<p>Here, we’re using a null message to indicate that the worker should end. With threads that run indefinitely, it’s important to have an exit strategy!<a contenteditable="false" data-primary="" data-startref="ch21.html22" data-type="indexterm" id="id4392"/><a contenteditable="false" data-primary="" data-startref="ch21.html21" data-type="indexterm" id="id4393"/></p>
</div></section>
</div></section>
<section data-pdf-bookmark="ManualResetEvent" data-type="sect2"><div class="sect2" id="manualresetevent">
<h2>ManualResetEvent</h2>
<p><a contenteditable="false" data-primary="event wait handles" data-secondary="ManualResetEvent" data-type="indexterm" id="id4394"/><a contenteditable="false" data-primary="ManualResetEvent" data-type="indexterm" id="id4395"/>As we described in <a data-type="xref" href="ch14.html#concurrency_and_asynchron">Chapter 14</a>, a <code>ManualResetEvent</code> functions like a simple gate. Calling <code>Set</code> opens the gate, allowing <em>any</em> number of threads calling <code>WaitOne</code> to be let through. Calling <code>Reset</code> closes the gate. Threads that call <code>WaitOne</code> on a closed gate will block; when the gate is next opened, they will be released all at once. Apart from these differences, a <code>ManualResetEvent</code> functions like an <code>AutoResetEvent</code>.</p>
<p>As with <code>AutoResetEvent</code>, you can construct a <code>ManualResetEvent</code> in two ways:</p>
<pre data-type="programlisting">var manual1 = new ManualResetEvent (false);
var manual2 = new EventWaitHandle (false, EventResetMode.ManualReset);</pre>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p><a contenteditable="false" data-primary="ManualResetEventSlim" data-type="indexterm" id="id4396"/>There’s another version of <code>ManualResetEvent</code> called <code>ManualResetEventSlim</code>. The latter is optimized for short waiting times—with the ability to opt into spinning for a set number of iterations. It also has a more efficient managed implementation and allows a <code>Wait</code> to be canceled via a <code>CancellationToken</code>.  <code>ManualResetEventSlim</code> doesn’t subclass <code>WaitHandle</code>; however, it exposes a <code>WaitHandle</code> property that returns a <code>WaitHandle</code>-based object when called (with the performance profile of a traditional wait handle).</p>
</div>
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="signaling_constructs_and_performance">
<h1>Signaling Constructs and Performance</h1>
<p><a contenteditable="false" data-primary="signaling" data-secondary="constructs/performance" data-type="indexterm" id="id4397"/>Waiting or signaling an <code>AutoResetEvent</code> or <code>ManualResetEvent</code> takes about one microsecond (assuming no blocking).</p>
<p><code>ManualResetEventSlim</code> and <code>CountdownEvent</code> can be up to 50 times faster in short-wait scenarios because of their nonreliance on the OS and judicious use of spinning constructs. In most scenarios, however, the overhead of the signaling classes themselves doesn’t create a bottleneck; thus, it is rarely a consideration.</p>
</div></aside>
<p>A <code>ManualResetEvent</code> is useful in allowing one thread to unblock many other threads. The reverse scenario is covered by <code>CountdownEvent</code>.</p>
</div></section>
<section data-pdf-bookmark="CountdownEvent" data-type="sect2"><div class="sect2" id="countdownevent">
<h2>CountdownEvent</h2>
<p><a contenteditable="false" data-primary="CountdownEvent" data-type="indexterm" id="id4398"/><a contenteditable="false" data-primary="event wait handles" data-secondary="CountdownEvent" data-type="indexterm" id="id4399"/><code>CountdownEvent</code> lets you wait on more than one thread. The class has an efficient, fully managed implementation. To use the class, instantiate it with the number of threads, or “counts,” that you want to wait on:</p>
<pre data-type="programlisting">var countdown = new CountdownEvent (3);  // Initialize with "count" of 3.</pre>
<p>Calling <code>Signal</code> decrements the “count”; calling <code>Wait</code> blocks until the count goes down to zero:</p>
<pre data-type="programlisting">new Thread (SaySomething).Start ("I am thread 1");
new Thread (SaySomething).Start ("I am thread 2");
new Thread (SaySomething).Start ("I am thread 3");

<strong>countdown.Wait();   // Blocks until Signal has been called 3 times</strong>
Console.WriteLine ("All threads have finished speaking!");

void SaySomething (object thing)
{
  Thread.Sleep (1000);
  Console.WriteLine (thing);
  <strong>countdown.Signal();</strong>
}</pre>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>You can sometimes more easily solve problems for which <code>CountdownEvent</code> is effective by using the <em>structured parallelism</em> constructs that we describe in <a data-type="xref" href="ch22.html#parallel_programming-id00071">Chapter 22</a> (PLINQ and the <code>Parallel</code> class).</p>
</div>
<p>You can reincrement a <code>CountdownEvent</code>’s count by calling <code>AddCount</code>. However, if it has already reached zero, this throws an exception: you can’t “unsignal” a <code>CountdownEvent</code> by calling <code>AddCount</code>. To prevent the possibility of an exception being thrown, you can instead call <code>TryAddCount</code>, which returns <code>false</code> if the countdown is zero.</p>
<p>To unsignal a countdown event, call <code>Reset</code>: this both unsignals the construct and resets its count to the original value.</p>
<p>Like <code>ManualResetEventSlim</code>, <code>CountdownEvent</code> exposes a <code>WaitHandle</code> property for scenarios in which some other class or method expects an object based on <span class="keep-together"><code>WaitHandle</code></span>.</p>
</div></section>
<section data-pdf-bookmark="Creating a Cross-Process EventWaitHandle" data-type="sect2"><div class="sect2" id="creating_a_cross_process_eventwaithandl">
<h2>Creating a Cross-Process EventWaitHandle</h2>
<p><a contenteditable="false" data-primary="cross-process EventWaitHandle" data-type="indexterm" id="id4400"/><a contenteditable="false" data-primary="event wait handles" data-secondary="cross-process" data-type="indexterm" id="id4401"/><code>EventWaitHandle</code>’s constructor allows a “named” <code>EventWaitHandle</code> to be created, capable of operating across multiple processes. The name is simply a string, and it can be any value that doesn’t unintentionally conflict with someone else’s! If the name is already in use on the computer, you get a reference to the same underlying <code>EventWaitHandle</code>; otherwise, the OS creates a new one. Here’s an example:</p>
<pre data-type="programlisting">EventWaitHandle wh = new EventWaitHandle (false, EventResetMode.AutoReset,
                                      @"Global\MyCompany.MyApp.SomeName");</pre>
<p>If two applications each ran this code, they would be able to signal each other: the wait handle would work across all threads in both processes.</p>
<p>Named event wait handles are available only on Windows.</p>
</div></section>
<section data-pdf-bookmark="Wait Handles and Continuations" data-type="sect2"><div class="sect2" id="wait_handles_and_continuations">
<h2>Wait Handles and Continuations</h2>
<p><a contenteditable="false" data-primary="continuations" data-secondary="event wait handles and" data-type="indexterm" id="id4402"/><a contenteditable="false" data-primary="event wait handles" data-secondary="continuations and" data-type="indexterm" id="id4403"/><a contenteditable="false" data-primary="Thread..." data-secondary="ThreadPool.RegisterWaitForSingleObject" data-type="indexterm" id="id4404"/>Rather than waiting on a wait handle (and blocking your thread), you can attach a “continuation” to it by calling <code>ThreadPool.RegisterWaitForSingleObject</code>. This method accepts a delegate that is executed when a wait handle is signaled:</p>
<pre data-type="programlisting">var starter = new ManualResetEvent (false);

<strong>RegisteredWaitHandle reg = ThreadPool.RegisterWaitForSingleObject</strong>
 <strong>(starter, Go, "Some Data", -1, true);</strong>

Thread.Sleep (5000);
Console.WriteLine ("Signaling worker...");
starter.Set();
Console.ReadLine();
<strong>reg.Unregister (starter);</strong>    // Clean up when we’re done.

void Go (object data, bool timedOut)
{
  Console.WriteLine ("Started - " + data);
  // Perform task...
}

// Output:
(5 second delay)
Signaling worker...
Started - Some Data</pre>
<p>When the wait handle is signaled (or a timeout elapses), the delegate runs on a pooled thread. You are then supposed to call <code>Unregister</code> to release the unmanaged handle to the callback.</p>
<p><a contenteditable="false" data-primary="RegisterWaitForSingleObject" data-type="indexterm" id="id4405"/>In addition to the wait handle and delegate, <code>RegisterWaitForSingleObject</code> accepts a “black box” object that it passes to your delegate method (rather like <code>ParameterizedThreadStart</code>) as well as a timeout in milliseconds (<code>-1</code> meaning no timeout) and a Boolean flag indicating whether the request is a one-off rather than recurring.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>You can reliably call <code>RegisterWaitForSingleObject</code> only once per wait handle. Calling this method again on the same wait handle causes an intermittent failure, whereby an unsignaled wait handle fires a callback as though it were <span class="keep-together">signaled</span>.</p>
<p>This limitation makes (the nonslim) wait handles poorly suited to asynchronous programming.</p>
</div>
</div></section>
<section data-pdf-bookmark="WaitAny, WaitAll, and SignalAndWait" data-type="sect2"><div class="sect2" id="waitanycomma_waitallcomma_and_signaland">
<h2>WaitAny, WaitAll, and SignalAndWait</h2>
<p><a contenteditable="false" data-primary="event wait handles" data-secondary="WaitAny, WaitAll, and SignalAndWait" data-type="indexterm" id="id4406"/>In addition to the <code>Set</code>, <code>WaitOne</code>, and <code>Reset</code> methods, there are static methods on the <code>WaitHandle</code> class to crack more complex synchronization nuts. The <code>WaitAny</code>, <span class="keep-together"><code>WaitAll</code>,</span> and <code>SignalAndWait</code> methods perform signaling and waiting operations on multiple handles. The wait handles can be of differing types (including <code>Mutex</code> and <code>Semaphore</code> given that these also derive from the abstract <code>WaitHandle</code> class). <code>ManualResetEventSlim</code> and <code>CountdownEvent</code> can also partake in these methods via their <code>WaitHandle</code> properties.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p><a contenteditable="false" data-primary="WaitAll method" data-type="indexterm" id="id4407"/><code>WaitAll</code> and <code>SignalAndWait</code> have a weird connection to the legacy COM architecture: these methods require that the caller be in a multithreaded apartment, the model least suitable for interoperability. The main thread of a WPF or Windows Forms application, for example, is unable to interact with the clipboard in this mode. We discuss alternatives shortly.</p>
</div>
<p><code>WaitHandle.WaitAny</code> waits for any one of an array of wait handles; <code>Wait​Han⁠dle.Wait​All</code> waits on all of the given handles, atomically. This means that if you wait on two <code>AutoResetEvents</code>:</p>
<ul>
<li><p><a contenteditable="false" data-primary="WaitAny method" data-type="indexterm" id="id4408"/><code>WaitAny</code> will never end up “latching” both events.</p></li>
<li><p><code>WaitAll</code> will never end up “latching” only one event.</p></li>
</ul>
<p><a contenteditable="false" data-primary="SignalAndWait method" data-type="indexterm" id="id4409"/><code>SignalAndWait</code> calls <code>Set</code> on one <code>WaitHandle</code> and then calls <code>WaitOne</code> on another <span class="keep-together"><code>WaitHandle</code></span>. After signaling the first handle, it will jump to the head of the queue in waiting on the second handle; this helps it succeed (although the operation is not truly atomic). You can think of this method as “swapping” one signal for another, and use it on a pair of <code>EventWaitHandle</code>s to set up two threads to rendezvous, or “meet,” at the same point in time. Either <code>AutoResetEvent</code> or <code>ManualResetEvent</code> will do the trick. The first thread executes the following:</p>
<pre data-type="programlisting">WaitHandle.SignalAndWait (wh1, wh2);</pre>
<p>The second thread does the opposite:</p>
<pre data-type="programlisting">WaitHandle.SignalAndWait (wh2, wh1);</pre>
<section data-pdf-bookmark="Alternatives to WaitAll and SignalAndWait" data-type="sect3"><div class="sect3" id="alternatives_to_waitall_and_signalandwa">
<h3>Alternatives to WaitAll and SignalAndWait</h3>
<p><code>WaitAll</code> and <code>SignalAndWait</code> won’t run in a single-threaded apartment. Fortunately, there are alternatives. In the case of <code>SignalAndWait</code>, it’s rare that you need its queue-jumping semantics: in our rendezvous example, for instance, it would be valid simply to call <code>Set</code> on the first wait handle, and then <code>WaitOne</code> on the other, if wait handles were used solely for that rendezvous. In the following section, we explore yet another option for implementing a thread rendezvous.</p>
<p>In the case of <code>WaitAny</code> and <code>WaitAll</code>, if you don’t need atomicity, you can use the code we wrote in the previous section to convert the wait handles to tasks and then use <code>Task.WhenAny</code> and <code>Task.WhenAll</code> (<a data-type="xref" href="ch14.html#concurrency_and_asynchron">Chapter 14</a>).</p>
<p>If you need atomicity, you can take the lowest-level approach to signaling and write the logic yourself with <code>Monitor</code>’s <code>Wait</code> and <code>Pulse</code> methods. We describe <code>Wait</code> and <code>Pulse</code> in detail in <a href="http://albahari.com/threading"><em class="hyperlink">http://albahari.com/threading</em></a>.<a contenteditable="false" data-primary="" data-startref="ch21.html20" data-type="indexterm" id="id4410"/><a contenteditable="false" data-primary="" data-startref="ch21.html19" data-type="indexterm" id="id4411"/><a contenteditable="false" data-primary="" data-startref="ch21.html18" data-type="indexterm" id="id4412"/><a contenteditable="false" data-primary="" data-startref="ch21.html17" data-type="indexterm" id="id4413"/></p>
</div></section>
</div></section>
</div></section>
<section data-pdf-bookmark="The Barrier Class" data-type="sect1"><div class="sect1" id="the_barrier_class">
<h1>The Barrier Class</h1>
<p><a contenteditable="false" data-primary="Barrier class" data-type="indexterm" id="ch21.html23"/><a contenteditable="false" data-primary="threading" data-secondary="Barrier class" data-type="indexterm" id="ch21.html24"/>The <code>Barrier</code> class implements a <a contenteditable="false" data-primary="thread execution barrier" data-type="indexterm" id="id4414"/><em>thread execution barrier</em>, allowing many threads to rendezvous at a point in time (not to be confused with <code>Thread.MemoryBarrier</code>). The class is very fast and efficient, and is built upon <code>Wait</code>, <code>Pulse</code>, and spinlocks.</p>
<p>To use this class:</p>
<ol>
<li><p>Instantiate it, specifying how many threads should partake in the rendezvous (you can change this later by calling <code>AddParticipants</code>/<code>RemoveParticipants</code>).</p></li>
<li><p>Have each thread call <code>SignalAndWait</code> when it wants to rendezvous.</p></li>
</ol>
<p>Instantiating <code>Barrier</code> with a value of <code>3</code> causes <code>SignalAndWait</code> to block until that method has been called three times. It then starts over: calling <code>SignalAndWait</code> again blocks until called another three times. This keeps each thread “in step” with every other thread.</p>
<p>In the following example, each of three threads writes the numbers 0 through 4 while keeping in step with the other threads:</p>
<pre data-type="programlisting">var barrier = <strong>new Barrier (3);</strong>

new Thread (Speak).Start();
new Thread (Speak).Start();
new Thread (Speak).Start();

void Speak()
{
  for (int i = 0; i &lt; 5; i++)
  {
    Console.Write (i + " ");
    <strong>barrier.SignalAndWait();</strong>
  }
}

OUTPUT:  0 0 0 1 1 1 2 2 2 3 3 3 4 4 4</pre>
<p><a contenteditable="false" data-primary="post-phase action" data-type="indexterm" id="id4415"/>A really useful feature of <code>Barrier</code> is that you can also specify a <em>post-phase action</em> when constructing it. This is a delegate that runs after <code>SignalAndWait</code> has been called <em>n</em> times, but <em>before</em> the threads are unblocked (as shown in the shaded area in <a data-type="xref" href="#barrier">Figure 21-3</a>). In our example, if we instantiate our barrier as follows:</p>
<pre data-type="programlisting">static Barrier _barrier = new Barrier (3, <strong>barrier =&gt; Console.WriteLine()</strong>);</pre>
<p>the output is this:</p>
<pre data-type="programlisting">0 0 0 
1 1 1 
2 2 2 
3 3 3 
4 4 4</pre>
<figure><div class="figure" id="barrier">
<img alt="Barrier" src="assets/cn10_2103.png"/>
<h6><span class="label">Figure 21-3. </span>Barrier</h6>
</div></figure>
<p>A post-phase action can be useful for coalescing data from each of the worker threads. It doesn’t need to worry about preemption, because all workers are blocked while it does its thing.<a contenteditable="false" data-primary="" data-startref="ch21.html24" data-type="indexterm" id="id4416"/><a contenteditable="false" data-primary="" data-startref="ch21.html23" data-type="indexterm" id="id4417"/></p>
</div></section>
<section data-pdf-bookmark="Lazy Initialization" data-type="sect1"><div class="sect1" id="lazy_initialization">
<h1>Lazy Initialization</h1>
<p><a contenteditable="false" data-primary="lazy initialization" data-type="indexterm" id="ch21.html25"/><a contenteditable="false" data-primary="threading" data-secondary="lazy initialization" data-type="indexterm" id="ch21.html26"/>A frequent problem in threading is how to lazily initialize a shared field in a thread-safe fashion. The need arises when you have a field of a type that’s expensive to <span class="keep-together">construct</span>:</p>
<pre data-type="programlisting">class Foo
{
  <strong>public readonly Expensive Expensive = new Expensive();</strong>
  <strong>...</strong>
}
class Expensive {  /* Suppose this is expensive to construct */  }</pre>
<p>The problem with this code is that instantiating <code>Foo</code> incurs the performance cost of instantiating <code>Expensive</code>—regardless of whether the <code>Expensive</code> field is ever accessed. The obvious answer is to construct the instance <em>on demand</em>:</p>
<pre data-type="programlisting">class Foo
{
  Expensive _expensive;
  public Expensive Expensive         // <em>Lazily</em> instantiate Expensive
  {
    get
    {
      if (_expensive == null) _expensive = new Expensive();
      return _expensive;
    }
  }
  ...
}</pre>
<p>The question then arises, is this thread-safe? Aside from the fact that we’re accessing <code>_expensive</code> outside a lock without a memory barrier, consider what would happen if two threads accessed this property at once. They could both satisfy the <code>if</code> statement’s predicate and each thread end up with a <em>different</em> instance of <code>Expensive</code>. Because this can lead to subtle errors, we would say, in general, that this code is not thread-safe.</p>
<p>The solution to the problem is to lock around checking and initializing the object:</p>
<pre data-type="programlisting">Expensive _expensive;
readonly object <strong>_expenseLock</strong> = new object();

public Expensive Expensive
{
  get
  {
    <strong>lock (_expenseLock)</strong>
    {
      if (_expensive == null) _expensive = new Expensive();
      return _expensive;
    }
  }
}</pre>
<section data-pdf-bookmark="Lazy&lt;T&gt;" data-type="sect2"><div class="sect2" id="lazyless_thantgreater_than">
<h2>Lazy&lt;T&gt;</h2>
<p><a contenteditable="false" data-primary="lazy initialization" data-secondary="Lazy&lt;T&gt; class" data-type="indexterm" id="id4418"/><a contenteditable="false" data-primary="Lazy&lt;T&gt; class" data-type="indexterm" id="id4419"/>The <code>Lazy&lt;T&gt;</code> class is available to help with lazy initialization. If instantiated with an argument of <code>true</code>, it implements the thread-safe initialization pattern just described.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p><a contenteditable="false" data-primary="double-checked locking" data-type="indexterm" id="id4420"/><code>Lazy&lt;T&gt;</code> actually implements a micro-optimized version of this pattern, called <em>double-checked locking</em>. Double-checked locking performs an additional volatile read to avoid the cost of obtaining a lock if the object is already initialized.</p>
</div>
<p>To use <code>Lazy&lt;T&gt;</code>, instantiate the class with a value factory delegate that tells it how to initialize a new value, and the argument <code>true</code>. Then, access its value via the <code>Value</code> property:</p>
<pre data-type="programlisting">Lazy&lt;Expensive&gt; _expensive = new Lazy&lt;Expensive&gt;
  (() =&gt; new Expensive(), true);

public Expensive Expensive { get { return _expensive.<strong>Value</strong>; } }</pre>
<p>If you pass <code>false</code> into <code>Lazy&lt;T&gt;</code>’s constructor, it implements the thread-unsafe lazy initialization pattern that we described at the beginning of this section—this makes sense when you want to use <code>Lazy&lt;T&gt;</code> in a single-threaded context.</p>
</div></section>
<section data-pdf-bookmark="LazyInitializer" data-type="sect2"><div class="sect2" id="lazyinitializer">
<h2>LazyInitializer</h2>
<p><a contenteditable="false" data-primary="lazy initialization" data-secondary="LazyInitializer class" data-type="indexterm" id="id4421"/><a contenteditable="false" data-primary="LazyInitializer class" data-type="indexterm" id="id4422"/><code>LazyInitializer</code> is a static class that works exactly like <code>Lazy&lt;T&gt;</code> except:</p>
<ul>
<li><p>Its functionality is exposed through a static method that operates directly on a field in your own type. This prevents a level of indirection, improving performance in cases where you need extreme optimization.</p></li>
<li><p>It offers another mode of initialization in which multiple threads can race to initialize.</p></li>
</ul>
<p>To use <code>LazyInitializer</code>, call <code>EnsureInitialized</code> before accessing the field, passing a reference to the field and the factory delegate:</p>
<pre data-type="programlisting">Expensive _expensive;
public Expensive Expensive
{ 
  get          // Implement double-checked locking
  { 
    LazyInitializer.EnsureInitialized (ref _expensive,
                                      () =&gt; new Expensive());
    return _expensive;
  }
}</pre>
<p>You can also pass in another argument to request that competing threads <em>race</em> to initialize. This sounds similar to our original thread-unsafe example except that the first thread to finish always wins—and so you end up with only one instance. The advantage of this technique is that it’s even faster (on multicores) than double-checked locking because it can be implemented entirely without locks using advanced techniques that we describe in “Nonblocking Synchronization” and “Lazy Initialization” at <a href="http://albahari.com/threading"><em>http://albahari.com/threading</em></a>. This is an extreme (and rarely needed) optimization that comes at a cost:</p>
<ul>
<li><p>It’s slower when more threads race to initialize than you have cores.</p></li>
<li><p>It potentially wastes CPU resources performing redundant initialization.</p></li>
<li class="pagebreak-before"><p>The initialization logic must be thread-safe (in this case, it would be thread-unsafe if <code>Expensive</code>’s constructor wrote to static fields, for instance).</p></li>
<li><p>If the initializer instantiates an object requiring disposal, the “wasted” object won’t be disposed without additional logic.<a contenteditable="false" data-primary="" data-startref="ch21.html26" data-type="indexterm" id="id4423"/><a contenteditable="false" data-primary="" data-startref="ch21.html25" data-type="indexterm" id="id4424"/></p></li>
</ul>
</div></section>
</div></section>
<section data-pdf-bookmark="Thread-Local Storage" data-type="sect1"><div class="sect1" id="thread_local_storage">
<h1>Thread-Local Storage</h1>
<p><a contenteditable="false" data-primary="thread-local storage" data-type="indexterm" id="ch21.html27"/><a contenteditable="false" data-primary="threading" data-secondary="thread-local storage" data-type="indexterm" id="ch21.html28"/>Much of this chapter has focused on synchronization constructs and the issues arising from having threads concurrently access the same data. Sometimes, however, you want to keep data isolated, ensuring that each thread has a separate copy. Local variables achieve exactly this, but they are useful only with transient data.</p>
<p>The solution is <em>thread-local storage</em>. You might be hard-pressed to think of a requirement: data you’d want to keep isolated to a thread tends to be transient by nature. Its main application is for storing “out-of-band” data—that which supports the execution path’s infrastructure, such as messaging, transaction, and security tokens. Passing such data around in method parameters can be clumsy and can alienate all but your own methods; storing such information in ordinary static fields means sharing it among all threads.</p>
<p>Thread-local storage can also be useful in optimizing parallel code. It allows each thread to exclusively access its own version of a thread-unsafe object without needing locks—and without needing to reconstruct that object between method calls.</p>
<p>There are four ways to implement thread-local storage. We take a look at them in the following subsections.</p>
<section data-pdf-bookmark="[ThreadStatic]" data-type="sect2"><div class="sect2" id="left_square_bracketthreadstaticright_sq">
<h2>[ThreadStatic]</h2>
<p><a contenteditable="false" data-primary="thread-local storage" data-secondary="ThreadStatic attribute" data-type="indexterm" id="id4425"/><a contenteditable="false" data-primary="Thread..." data-secondary="ThreadStatic attribute" data-type="indexterm" id="id4426"/>The easiest approach to thread-local storage is to mark a static field with the <code>ThreadStatic</code> attribute:</p>
<pre data-type="programlisting">[ThreadStatic] static int _x;</pre>
<p>Each thread then sees a separate copy of <code>_x</code>.</p>
<p>Unfortunately, <code>[ThreadStatic]</code> doesn’t work with instance fields (it simply does nothing); nor does it play well with field initializers—they execute only <em>once</em> on the thread that’s running when the static constructor executes. If you need to work with instance fields—or start with a nondefault value—<code>ThreadLocal&lt;T&gt;</code> provides a better option.</p>
</div></section>
<section data-pdf-bookmark="ThreadLocal&lt;T&gt;" data-type="sect2"><div class="sect2" id="threadlocalless_thantgreater_than">
<h2>ThreadLocal&lt;T&gt;</h2>
<p><a contenteditable="false" data-primary="thread-local storage" data-secondary="ThreadLocal&lt;T&gt;" data-type="indexterm" id="id4427"/><a contenteditable="false" data-primary="Thread..." data-secondary="ThreadLocal&lt;T&gt;" data-type="indexterm" id="id4428"/><code>ThreadLocal&lt;T&gt;</code> provides thread-local storage for both static and instance fields, and allows you to specify default values.</p>
<p>Here’s how to create a <code>ThreadLocal&lt;int&gt;</code> with a default value of <code>3</code> for each thread:</p>
<pre data-type="programlisting">static ThreadLocal&lt;int&gt; _x = new ThreadLocal&lt;int&gt; (() =&gt; 3);</pre>
<p>You then use <code>_x</code>’s <code>Value</code> property to get or set its thread-local value. A bonus of using <code>ThreadLocal</code> is that values are lazily evaluated: the factory function evaluates on the first call (for each thread).</p>
<section data-pdf-bookmark="ThreadLocal&lt;T&gt; and instance fields" data-type="sect3"><div class="sect3" id="threadlocalless_thantgreater_than_and_i">
<h3>ThreadLocal&lt;T&gt; and instance fields</h3>
<p><a contenteditable="false" data-primary="instance fields, ThreadLocal&lt;T&gt; and" data-type="indexterm" id="id4429"/><code>ThreadLocal&lt;T&gt;</code> is also useful with instance fields and captured local variables. For example, consider the problem of generating random numbers in a multithreaded environment. The <code>Random</code> class is not thread-safe, so we have to either lock around using <code>Random</code> (limiting concurrency) or generate a separate <code>Random</code> object for each thread. <code>ThreadLocal&lt;T&gt;</code> makes the latter easy:</p>
<pre data-type="programlisting">var localRandom = <strong>new ThreadLocal&lt;Random&gt;(() =&gt; new Random())</strong>;
Console.WriteLine (localRandom.Value.Next());</pre>
<p>Our factory function for creating the <code>Random</code> object is a bit simplistic, though, in that <code>Random</code>’s parameterless constructor relies on the system clock for a random number seed. This may be the same for two <code>Random</code> objects created within ~10 ms of each other. Here’s one way to fix it:</p>
<pre data-type="programlisting">var localRandom = new ThreadLocal&lt;Random&gt;
 ( () =&gt; new Random (Guid.NewGuid().GetHashCode()) );</pre>
<p>We use this in <a data-type="xref" href="ch22.html#parallel_programming-id00071">Chapter 22</a> (see the parallel spellchecking example in <a data-type="xref" href="ch22.html#plinq">“PLINQ”</a>).</p>
</div></section>
</div></section>
<section data-pdf-bookmark="GetData and SetData" data-type="sect2"><div class="sect2" id="getdata_and_setdata">
<h2>GetData and SetData</h2>
<p><a contenteditable="false" data-primary="Get..." data-secondary="GetData method" data-type="indexterm" id="id4430"/><a contenteditable="false" data-primary="SetData method" data-type="indexterm" id="id4431"/><a contenteditable="false" data-primary="thread-local storage" data-secondary="GetData and SetData" data-type="indexterm" id="id4432"/>The third approach is to use two methods in the <code>Thread</code> class: <code>GetData</code> and <code>SetData</code>. These store data in thread-specific “slots.” <code>Thread.GetData</code> reads from a thread’s isolated data store; <code>Thread.SetData</code> writes to it. Both methods require a <code>Local​DataStoreSlot</code> object to identify the slot. You can use the same slot across all threads and they’ll still get separate values. Here’s an example:</p>
<pre data-type="programlisting">class Test
{
  // The same LocalDataStoreSlot object can be used across all threads.
  LocalDataStoreSlot _secSlot = Thread.GetNamedDataSlot ("securityLevel");

  // This property has a separate value on each thread.
  int SecurityLevel
  {
    get
    {
      object data = Thread.GetData (_secSlot);
      return data == null ? 0 : (int) data;    // null == uninitialized
    }
    set { Thread.SetData (_secSlot, value); }
  }
  ...</pre>
<p>In this instance, we called <code>Thread.GetNamedDataSlot</code>, which creates a named slot—this allows sharing of that slot across the application. Alternatively, you can control a slot’s scope yourself with an unnamed slot, obtained by calling <code>Thread.AllocateDataSlot</code>:</p>
<pre data-type="programlisting">class Test
{
  LocalDataStoreSlot _secSlot = Thread.AllocateDataSlot();
  ...</pre>
<p><code>Thread.FreeNamedDataSlot</code> will release a named data slot across all threads, but only once all references to that <code>LocalDataStoreSlot</code> have dropped out of scope and have been garbage-collected. This ensures that threads don’t have data slots pulled out from under their feet, as long as they keep a reference to the appropriate <code>LocalDataStoreSlot</code> object while the slot is needed.</p>
</div></section>
<section data-pdf-bookmark="AsyncLocal&lt;T&gt;" data-type="sect2"><div class="sect2" id="asynclocalless_thantgreater_than">
<h2>AsyncLocal&lt;T&gt;</h2>
<p><a contenteditable="false" data-primary="AsyncLocal&lt;T&gt;" data-type="indexterm" id="id4433"/><a contenteditable="false" data-primary="thread-local storage" data-secondary="AsyncLocal&lt;T&gt;" data-type="indexterm" id="id4434"/>The approaches to thread-local storage that we’ve discussed so far are incompatible with asynchronous functions, because after an <code>await</code>, execution can resume on a different thread. The <code>AsyncLocal&lt;T&gt;</code> class solves this by preserving its value across an <code>await</code>:</p>
<pre data-type="programlisting">static <strong>AsyncLocal&lt;string&gt;</strong> _asyncLocalTest = <strong>new AsyncLocal&lt;string&gt;()</strong>;

async void Main()
{
  <strong>_asyncLocalTest.Value</strong> = "test";  
  <strong>await</strong> Task.Delay (1000);  
  // The following works even if we come back on another thread:
  Console.WriteLine (<strong>_asyncLocalTest.Value</strong>);   // test
}</pre>
<p><code>AsyncLocal&lt;T&gt;</code> is still able to keep operations started on separate threads apart, whether initiated by <code>Thread</code>.<code>Start</code> or <code>Task</code>.<code>Run</code>. The following writes “one one” and “two two”:</p>
<pre data-type="programlisting">static AsyncLocal&lt;string&gt; _asyncLocalTest = new AsyncLocal&lt;string&gt;();

void Main()
{
  // Call Test twice on two concurrent threads:
  new Thread (() =&gt; Test ("one")).Start();
  new Thread (() =&gt; Test ("two")).Start();
}

async void Test (string value)
{
  _asyncLocalTest.Value = value;
  await Task.Delay (1000);
  Console.WriteLine (value + " " + _asyncLocalTest.Value);
}</pre>
<p><code>AsyncLocal&lt;T&gt;</code> has an interesting and unique nuance: if an <code>AsyncLocal&lt;T&gt;</code> object already has a value when a thread is started, the new thread will “inherit” that value:</p>
<pre data-type="programlisting">static AsyncLocal&lt;string&gt; _asyncLocalTest = new AsyncLocal&lt;string&gt;();

void Main()
{
  _asyncLocalTest.Value = "<strong>test</strong>";
  new Thread (AnotherMethod).Start();
}

void AnotherMethod() =&gt; Console.WriteLine (_asyncLocalTest.Value);  // <strong>test</strong></pre>
<p>The new thread, however, gets a <em>copy</em> of the value, so any changes that it makes will not affect the original:</p>
<pre data-type="programlisting">static AsyncLocal&lt;string&gt; _asyncLocalTest = new AsyncLocal&lt;string&gt;();

void Main()
{
  _asyncLocalTest.Value = "<strong>test</strong>";
  var t = new Thread (AnotherMethod);
  t.Start(); t.Join();
  Console.WriteLine (_asyncLocalTest.Value);   // <strong>test</strong>  (not ha-ha!)
}

void AnotherMethod() =&gt; _asyncLocalTest.Value = "<strong>ha-ha!</strong>";</pre>
<p>Keep in mind that the new thread gets a <em>shallow</em> copy of the value. So, if you were to replace <code>Async&lt;string&gt;</code> with <code>Async&lt;StringBuilder&gt;</code> or <code>Async&lt;List&lt;string&gt;&gt;</code>, the new thread could clear the <code>StringBuilder</code> or add/remove items to the <code>List&lt;string&gt;</code>, and this would affect the original.<a contenteditable="false" data-primary="" data-startref="ch21.html28" data-type="indexterm" id="id4435"/><a contenteditable="false" data-primary="" data-startref="ch21.html27" data-type="indexterm" id="id4436"/></p>
</div></section>
</div></section>
<section data-pdf-bookmark="Timers" data-type="sect1"><div class="sect1" id="timers-id00112">
<h1>Timers</h1>
<p><a contenteditable="false" data-primary="threading" data-secondary="timers" data-type="indexterm" id="ch21.html29"/><a contenteditable="false" data-primary="timers" data-type="indexterm" id="ch21.html30"/>If you need to execute some method repeatedly at regular intervals, the easiest way is with a <em>timer</em>. Timers are convenient and efficient in their use of memory and resources—compared with techniques such as the following:</p>
<pre data-type="programlisting">new Thread (delegate() {
                         while (<em>enabled</em>)
                         {
                           <em>DoSomeAction</em>();
                           Thread.Sleep (TimeSpan.FromHours (24));
                         }
                       }).Start();</pre>
<p>Not only does this permanently tie up a thread resource, but without additional coding, <code>DoSomeAction</code> will happen at a later time each day. Timers solve these <span class="keep-together">problems</span>.</p>
<p class="pagebreak-before">.NET provides five timers. Two of these are general-purpose multithreaded timers:</p>
<ul>
<li><p><code>System.Threading.Timer</code></p></li>
<li><p><code>System.Timers.Timer</code></p></li>
</ul>
<p>The other two are special-purpose single-threaded timers:</p>
<ul>
<li><p><a contenteditable="false" data-primary="System..." data-secondary="System.Windows.Forms.Timer" data-type="indexterm" id="id4437"/><code>System.Windows.Forms.Timer</code> (Windows Forms timer)</p></li>
<li><p><a contenteditable="false" data-primary="System..." data-secondary="System.Windows.Threading.DispatcherTimer" data-type="indexterm" id="id4438"/><code>System.Windows.Threading.DispatcherTimer</code> (WPF timer)</p></li>
</ul>
<p>The multithreaded timers are more powerful, accurate, and flexible; the single-threaded timers are safer and more convenient for running simple tasks that update Windows Forms controls or WPF elements.</p>

<p>Finally, from .NET 6, there’s the <code>PeriodicTimer</code>, which we will cover first.</p>

<section data-pdf-bookmark="PeriodicTimer" data-type="sect2"><div class="sect2" id="periodictimer">
<h2>PeriodicTimer</h2>

<p><code>PeriodicTimer</code> is not really a timer; it’s a class to help with asynchronous looping. It’s important to consider that since the advent of <code>async</code> and <code>await</code>, traditional timers are not usually necessary. Instead, the following pattern works nicely:</p>

<pre data-type="programlisting">StartPeriodicOperation();

async void StartPeriodicOperation()
{
  while (true)
  {
    await Task.Delay (1000);
    Console.WriteLine ("Tick");   // Do some action
  }
 }</pre>

<div data-type="note" epub:type="note"><h6>Note</h6>
<p>If you call <code>StartPeriodicOperation</code> from a UI thread, it will behave as a single-threaded timer, because the await will always return on the same synchronization context.</p>

<p>You can make it behave as a multithreaded timer simply by adding <code>.ConfigureAwait(false)</code> to the await.</p>
</div>

<p><code>PeriodicTimer</code> is a class to simplify this pattern:</p>

<pre data-type="programlisting">var timer = new PeriodicTimer (TimeSpan.FromSeconds (1));
StartPeriodicOperation();
// Optionally dispose timer when you want to stop looping.

async void StartPeriodicOperation()
{
  while (await timer.WaitForNextTickAsync())
    Console.WriteLine ("Tick");    // Do some action
}</pre>

<p>PeriodicTimer also allows you to stop the timer by disposing the timer instance. This results in WaitForNextTickAsync returning false, allowing the loop to end.</p>

</div></section>

<section data-pdf-bookmark="Multithreaded Timers" data-type="sect2"><div class="sect2" id="multithreaded_timers">
<h2>Multithreaded Timers</h2>
<p><a contenteditable="false" data-primary="multithreaded timers" data-type="indexterm" id="ch21.html31"/><a contenteditable="false" data-primary="timers" data-secondary="multithreaded" data-type="indexterm" id="ch21.html32"/><code>System.Threading.Timer</code> <a contenteditable="false" data-primary="System..." data-secondary="System.Threading.Timer" data-type="indexterm" id="id4439"/>is the simplest multithreaded timer: it has just a constructor and two methods (a delight for minimalists, as well as book authors!). In the following example, a timer calls the <code>Tick</code> method, which writes “tick...” after five seconds have elapsed, and then every second after that, until the user presses Enter:</p>
<pre data-type="programlisting">using System;
using System.Threading;

// First interval = 5000ms; subsequent intervals = 1000ms
<strong>Timer tmr = new Timer (Tick, "tick...", 5000, 1000);</strong>
Console.ReadLine();
tmr.Dispose();         // This both stops the timer and cleans up.

void Tick (object data)
{
  // This runs on a pooled thread
  Console.WriteLine (data);          // Writes "tick..."
}</pre>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>See <a data-type="xref" href="ch12.html#timers-id00111">“Timers”</a> for a discussion on disposing multithreaded timers.</p>
</div>
<p>You can change a timer’s interval later by calling its <code>Change</code> method. If you want a timer to fire just once, specify <code>Timeout.Infinite</code> in the constructor’s last argument.</p>
<p>.NET provides another timer class of the same name in the <a contenteditable="false" data-primary="System..." data-secondary="System.Timers" data-type="indexterm" id="id4440"/><code>System.Timers</code> namespace. This simply wraps the <code>System.Threading.Timer</code>, providing additional convenience while using the identical underlying engine. Here’s a summary of its added features:</p>
<ul>
<li><p>An <code>IComponent</code> implementation, allowing it to be sited in Visual Studio’s Designer’s component tray</p></li>
<li><p>An <code>Interval</code> property instead of a <code>Change</code> method</p></li>
<li><p>An <code>Elapsed</code> <em>event</em> instead of a callback delegate</p></li>
<li><p>An <code>Enabled</code> property to start and stop the timer (its default value being <code>false</code>)</p></li>
<li><p><code>Start</code> and <code>Stop</code> methods in case you’re confused by <code>Enabled</code></p></li>
<li><p>An <code>AutoReset</code> flag for indicating a recurring event (default value is <code>true</code>)</p></li>
<li><p>A <code>SynchronizingObject</code> property with <code>Invoke</code> and <code>BeginInvoke</code> methods for safely calling methods on WPF elements and Windows Forms controls</p></li>
</ul>
<p class="pagebreak-before">Here’s an example:</p>
<pre data-type="programlisting">using System;
using System.Timers;          // Timers namespace rather than Threading

var tmr = new Timer();        // Doesn't require any args
tmr.Interval = 500;
tmr.Elapsed += tmr_Elapsed;   // Uses an event instead of a delegate
tmr.Start();                  // Start the timer
Console.ReadLine();
tmr.Stop();                   // Stop the timer
Console.ReadLine();
tmr.Start();                  // Restart the timer
Console.ReadLine();
tmr.Dispose();                // Permanently stop the timer

void tmr_Elapsed (object sender, EventArgs e)
  =&gt; Console.WriteLine ("Tick");</pre>
<p>Multithreaded timers use the thread pool to allow a few threads to serve many timers. This means that the callback method or <code>Elapsed</code> event can fire on a different thread each time it is called. Furthermore, the <code>Elapsed</code> event always fires (approximately) on time—regardless of whether the previous <code>Elapsed</code> event finished executing. Hence, callbacks or event handlers must be thread-safe.</p>
<p>The precision of multithreaded timers depends on the OS, and is typically in the 10- to 20-millisecond region. If you need greater precision, you can use native interop and call the Windows multimedia timer. This has precision down to one millisecond, and it is defined in <em>winmm.dll</em>. First call <code>timeBeginPeriod</code> to inform the OS that you need high timing precision, and then call <code>timeSetEvent</code> to start a multimedia timer. When you’re done, call <code>timeKillEvent</code> to stop the timer and <code>timeEndPeriod</code> to inform the OS that you no longer need high timing precision. <a data-type="xref" href="ch24.html#native_and_com_interoperabilit">Chapter 24</a> demonstrates calling external methods with P/Invoke. You can find complete examples on the internet that use the multimedia timer by searching for the keywords <em>dllimport winmm.dll timesetevent</em>.<a contenteditable="false" data-primary="" data-startref="ch21.html32" data-type="indexterm" id="id4441"/><a contenteditable="false" data-primary="" data-startref="ch21.html31" data-type="indexterm" id="id4442"/></p>
</div></section>
<section data-pdf-bookmark="Single-Threaded Timers" data-type="sect2"><div class="sect2" id="single_threaded_timers">
<h2>Single-Threaded Timers</h2>
<p><a contenteditable="false" data-primary="single-threaded timers" data-type="indexterm" id="id4443"/><a contenteditable="false" data-primary="timers" data-secondary="single-threaded" data-type="indexterm" id="id4444"/>.NET provides timers designed to eliminate thread-safety issues for WPF and Windows Forms applications:</p>
<ul>
<li><p><code>System.Windows.Threading.DispatcherTimer</code> (WPF)</p></li>
<li><p><code>System.Windows.Forms.Timer</code> (Windows Forms)</p></li>
</ul>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>The single-threaded timers are not designed to work outside their respective environments. If you use a Windows Forms timer in a Windows Service application, for instance, the <code>Timer</code> event won’t fire!</p>
</div>
<p>Both are like <code>System.Timers.Timer</code> in the members that they expose—<code>Interval</code>, <code>Start</code>, and <code>Stop</code> (and <code>Tick</code>, which is equivalent to <code>Elapsed</code>)—and are used in a similar manner. However, they differ in how they work internally. Instead of firing timer events on pooled threads, they post the events to the WPF or Windows Forms message loop. This means that the <code>Tick</code> event always fires on the same thread that originally created the timer—which, in a normal application, is the same thread used to manage all user interface elements and controls. This has a number of <span class="keep-together">benefits</span>:</p>
<ul>
<li><p>You can forget about thread safety.</p></li>
<li><p>A fresh <code>Tick</code> will never fire until the previous <code>Tick</code> has finished processing.</p></li>
<li><p>You can update user interface elements and controls directly from <code>Tick</code> event handling code without calling <code>Control.BeginInvoke</code> or <code>Dispatcher.Begin​Invoke</code>.</p></li>
</ul>
<p>Thus, a program employing these timers is not really multithreaded: you end up with the same kind of pseudo-concurrency that’s described in <a data-type="xref" href="ch14.html#concurrency_and_asynchron">Chapter 14</a> with asynchronous functions that execute on a UI thread. One thread serves all timers as well as the processing UI events, which means that the <code>Tick</code> event handler must execute quickly, otherwise the UI becomes unresponsive.</p>
<p>This makes the WPF and Windows Forms timers suitable for small jobs, typically updating some aspect of the UI (e.g., a clock or countdown display).</p>
<p>In terms of precision, the single-threaded timers are similar to the multithreaded timers (tens of milliseconds), although they are typically less <em>accurate</em> because they can be delayed while other UI requests (or other timer events) are processed<a contenteditable="false" data-primary="" data-startref="ch21.html30" data-type="indexterm" id="id4445"/><a contenteditable="false" data-primary="" data-startref="ch21.html29" data-type="indexterm" id="id4446"/>.<a contenteditable="false" data-primary="" data-startref="ch21.html1" data-type="indexterm" id="id4447"/><a contenteditable="false" data-primary="" data-startref="ch21.html0" data-type="indexterm" id="id4448"/></p>
</div></section>
</div></section>
<div data-type="footnotes"><p data-type="footnote" id="ch01fn15"><sup><a href="ch21.html#ch01fn15-marker">1</a></sup> Nuances in the behavior of Windows and the CLR mean that the fairness of the queue can sometimes be violated.</p><p data-type="footnote" id="ch01fn16"><sup><a href="ch21.html#ch01fn16-marker">2</a></sup> As with locks, the fairness of the queue can sometimes be violated due to nuances in the operating system.</p></div></div></section></body></html>